<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo_1.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo_1.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo_1.png">
  <link rel="mask-icon" href="/images/logo_1.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-pace-theme-center-circle.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"buttons","active":"valine","storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1. 分布式和集群的区别是什么？  分布式：侧重于将任务分拆多个子任务，部署在不同的服务器上，解决计算能力的问题 集群：侧重同一个业务，部署在多个服务器上，提高系统可用性和性能。  分布式是一个为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段。它的核心概念是将一个业务拆分成不同的子业务，并部署在不同的机器上执行，服务之间通过远程调用协同工作，对外提供服务。这种拆分和部署的方式可以">
<meta property="og:type" content="article">
<meta property="og:title" content="分布式">
<meta property="og:url" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/index.html">
<meta property="og:site_name" content="Trluper">
<meta property="og:description" content="1. 分布式和集群的区别是什么？  分布式：侧重于将任务分拆多个子任务，部署在不同的服务器上，解决计算能力的问题 集群：侧重同一个业务，部署在多个服务器上，提高系统可用性和性能。  分布式是一个为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段。它的核心概念是将一个业务拆分成不同的子业务，并部署在不同的机器上执行，服务之间通过远程调用协同工作，对外提供服务。这种拆分和部署的方式可以">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/CAP定理.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/base理论三要素.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/两段式提交第一阶段.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/两段式提交第二阶段.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/分布式事务提交成功场景.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/分布式事务回滚场景.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程1.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程2.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程3.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程4.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程5.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程6.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/MQ事务消息.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/MQ事务消息2.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/分布式算法—复制状态机.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft任期.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft状态转换.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志格式.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-1.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-2.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-3.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-4.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-5.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-6.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-7.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft-leader和follower日志不一致的情况.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft提交限制.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft集群成员变更-1.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/不相交多数派.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/三个阶段.png">
<meta property="og:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志快照.png">
<meta property="article:published_time" content="2024-03-10T02:25:32.000Z">
<meta property="article:modified_time" content="2024-03-24T07:43:23.323Z">
<meta property="article:author" content="trluper">
<meta property="article:tag" content="面试">
<meta property="article:tag" content="分布式">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/CAP定理.png">

<link rel="canonical" href="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>分布式 | Trluper</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Trluper</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/trluper" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://example.com/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="trluper">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Trluper">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          分布式
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-10 10:25:32" itemprop="dateCreated datePublished" datetime="2024-03-10T10:25:32+08:00">2024-03-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-24 15:43:23" itemprop="dateModified" datetime="2024-03-24T15:43:23+08:00">2024-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">面试</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>31k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>28 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="分布式和集群的区别是什么">1. 分布式和集群的区别是什么？</h2>
<ul>
<li><strong>分布式</strong>：侧重于将任务分拆多个子任务，部署在不同的服务器上，解决计算能力的问题</li>
<li><strong>集群</strong>：侧重同一个业务，部署在多个服务器上，提高系统可用性和性能。</li>
</ul>
<p><strong>分布式是一个为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段。它的核心概念是将一个业务拆分成不同的子业务，并部署在不同的机器上执行，服务之间通过远程调用协同工作，对外提供服务。这种拆分和部署的方式可以大大提高系统的可扩展性、可靠性和性能。</strong></p>
<blockquote>
<p>分布式涉及多个技术领域，包括但不限于分布式计算、分布式存储、分布式数据库、分布式文件系统等。这些技术各自有不同的应用场景和优势，如分布式计算可以处理巨量的数据和复杂的计算任务，分布式存储可以实现数据的高可用性和容错性，分布式数据库可以支持大规模并发访问和数据处理等。</p>
</blockquote>
<span id="more"></span>
<h2 id="cap定理">2. CAP定理</h2>
<p><img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/CAP定理.png" width="500"> CAP定义，又称为布鲁尔定理，它指对于一个分布式计算系统来说，不可能同时满足以下三点：</p>
<ul>
<li><strong>一致性（Consistence）：</strong>系统在执行过某项操作后仍然处于一致的状态。在分布式系统中，更新操作执行成功后所有的用户都应该读到最新的值，这样的系统被认为是具有强一致性的。 等同于所有节点访问同一份最新的数据副本（CAP中的一致性是强一致性）</li>
<li><strong>可用性（Availability）</strong>：每一个操作总是能够在一定的时间内返回结果，这里需要注意的是”一定时间内”和”返回结果”。一定时间指的是，在可以容忍的范围内返回结果，结果可以是成功或者失败。对数据更新具备高可用性。每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据</li>
<li><strong>分区容错性（Partition tolerance）</strong>：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性<strong>或</strong>可用性的服务。这里的网络分区是指由于某种原因，网络被分成若干个孤立的区域，而区域之间互不相通导致一些共享的数据副本无法及时保证一致性。</li>
</ul>
<p>CAP仅适用于原子读写的NOSQL场景中，并不适合数据库系统。现在的分布式系统具有更多特性比如扩展性、可用性等等，在进行系统设计和开发时，可以不仅仅局限在CAP问题上。</p>
<p><strong>当发生网络分区的时候，如果要继续服务，那么强一致性和可用性只能2选1。也就是说当网络分区之后P是前提，决定了P之后才有C和A的选择。也就是说分区容错性（Partition tolerance）是必须要实现的。</strong></p>
<blockquote>
<ul>
<li>保证P和C：在发送网络分区时，因为保证了分区容错性P，那么如果选择一致性，那么对于客户端的这个请求就会阻塞直到网络恢复，节点之前恢复正常通信得到一致性数据，此时阻塞就牺牲了可用性。</li>
<li>保证P和A：因为是保证A，客户段请求总是能在一定时间得到响应，此时节点之间可能网络还是故障，数据一致性未能得到保证，就是牺牲了一致性。</li>
</ul>
</blockquote>
<h2 id="base理论">3. BASE理论</h2>
<p>BASE 是 Basically Available（基本可用）、Soft-state（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。BASE 理论是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，它大大降低了对系统的要求。</p>
<h3 id="核心思想">。1核心思想</h3>
<p>即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。</p>
<p>针对数据库领域，BASE思想的主要实现是对业务数据进行拆分，让不同的数据分布在不同的机器上，以提升系统的可用性，当前主要有以下两种做法：</p>
<ul>
<li>按功能划分数据库</li>
<li>分片（如开源的Mycat、Amoeba等）。</li>
</ul>
<h3 id="base-理论三要素">3.2 BASE 理论三要素</h3>
<p><img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/base理论三要素.png" width="500"></p>
<h4 id="基本可用">1.基本可用</h4>
<p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这不等价于系统不可用。例如：</p>
<ul>
<li><strong>响应时间上的损失</strong>：正常情况下，一个在线搜索引擎需要在0.5秒内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加1-2秒</li>
<li><strong>系统功能上的损失</strong>：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。</li>
</ul>
<h4 id="软状态">2. 软状态</h4>
<p>软状态是指允许系统中的数据存在中间状态，并认为该中间状体的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<h4 id="最终一致性">3. 最终一致性</h4>
<p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一直，而不需要实时保证系统数据的强一致性。</p>
<h2 id="分布式系统设计的两大思路">4. 分布式系统设计的两大思路</h2>
<p>分布式系统设计的两大思路：中心化和去中心化</p>
<p>分布式系统设计的两大思路：中心化和去中心化</p>
<h3 id="中心化设计">4.1 中心化设计</h3>
<ul>
<li><strong>两个角色：</strong>中心化的设计思想很简单，分布式集群中的节点机器按照角色分工，大体上分为两种角色：“领导”和“干活的”</li>
<li><strong>角色职责</strong>：“领导”通常负责分发任务并监督“干活的”，发现谁空闲或者相对太闲，就想方设法给其安排新任务，确保没有一个“干活的”能够偷懒，如果“领导”发现某个“干活的”崩溃了，会直接将其踢除，然后把它的任务分给其他人。</li>
<li><strong>中心化设计的问题：</strong>
<ol type="1">
<li>中心化的设计存在的最大问题就是“领导”的安危问题，如果“领导”出了问题，则群龙无首，整个集群就崩溃了，但是难以同时安排两个“领导”以避免单点问题。</li>
<li>中心化设计还存在的另一个潜在的问题：即“领导”的能力问题：可以领导10个人高效工作并不意味着可以领到100个人高效工作，如果系统设计和实现不好，问题就会卡在“领导”身上。</li>
</ol>
<ul>
<li><strong>领导安危问题解决方法：大多数中心化系统都采用了主备两个“领导”的设计方案，可以是热备或者冷备，也可以是自动切换或者手动切换，而且越来越多的新系统都开始具备自动选取切换“领导”的能力，以提升系统的可用性。</strong></li>
</ul></li>
</ul>
<h3 id="去中心化设计">4.2 去中心化设计</h3>
<ul>
<li><strong>众生地位平等</strong>：在去中心化的设计里，通常没有“领导”和“干活的”这两种角色的区分，大家的角色都是一样的，地位是平等的，全球互联网就是一个典型的去中心化的分布式系统，联网的任意节点设备宕机，都只会影响很小范围的功能。</li>
<li><strong>“去中心化”不是不要中心，而是由节点来自由选择中心</strong>：集群的成员会自发的举行“会议”选举新的“领导”主持工作。最典型的案例就是ZooKeeper及Go语言实现的Etcd</li>
<li><strong>去中心化设计的问题</strong>：去中心化设计里最难解决的一个问题是<strong>脑裂</strong>问题，这种情况的发生概率很低，但影响很大。脑裂指一个集群由于网络的故障，被分为至少两个彼此无法通信的单独集群，此时如果两个集群都各自工作，则可能会产生严重的数据冲突和错误。一般的设计思路是，当集群判断发生了脑裂问题时，规模较小的集群就“自杀”或者拒绝服务。</li>
</ul>
<h2 id="分布式事务">5. 分布式事务</h2>
<p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p>
<h3 id="分布式事务和分布式锁的区别">5.1 分布式事务和分布式锁的区别</h3>
<p>分布式锁和分布式事务区别：</p>
<ul>
<li>锁问题的关键在于进程操作的互斥关系，例如多个进程同时修改账户的余额，如果没有互斥关系则会导致该账户的余额不正确。</li>
<li>而事务问题的关键则在于事务涉及的一系列操作需要满足 ACID 特性，例如要满足原子性操作则需要这些操作要么都执行，要么都不执行。</li>
</ul>
<h3 id="分布式事务产生的原因">5.2 分布式事务产生的原因</h3>
<ul>
<li><strong>数据库分库分表</strong>：当数据库单表一年产生的数据超过1000W时，就需要考虑分库分表，就是说将原来的数据库变成多个数据库。这时候，如果一个操作既访问01库，又访问02库，而且还要保证数据的一致性，那么就需要用到分布式事务。</li>
<li><strong>应用SOA化：</strong>所谓的SOA化，就是业务的服务化。比如原来单机支撑了整个电商网站，现在对整个网站进行拆解，分离出了订单中心、用户中心、库存中心。对于订单中心，有专门的数据库存储订单信息，用户中心也有专门的数据库存储用户信息，库存中心也会有专门的数据库存储库存信息。这时候如果要同时对订单和库存进行操作，那么就会涉及到订单数据库和库存数据库，为了保证数据一致性，就需要用到分布式事务。</li>
</ul>
<h3 id="常见的分布式事务解决方案">5.3 常见的分布式事务解决方案</h3>
<p>基于数据库资源层面实现方案，由于存在多个事务，需要存在一个角色管理各个事务的状态。<strong>我们将这个角色称为协调者，事务参与者称为参与者</strong>。参与者与协调者一般会基于某种特定协议，目前比较有名的为 XA 接口协议。基于协调者与参与者的思想设定，分别提出了 2PC 与 3PC 实现XA 分布式事务。</p>
<h4 id="基于xa协议的两阶段提交2pc">5.3.1 基于XA协议的两阶段提交（2PC）</h4>
<p>XA 是一个分布式事务协议，XA中大致分为两部分：事务管理器（协调者）和本地资源管理器。其中本地资源管理器往往由数据库实现，比如 Oracle、DB2 这些商业数据库都实现了 XA 接口，而<strong>事务管理器作为全局的协调者，负责各个本地资源的提交和回滚</strong>。主要过程如下：</p>
<h5 id="第一阶段准备阶段">第一阶段：准备阶段</h5>
<p><img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/两段式提交第一阶段.png" width="500"> 应用程序调用了事务管理器的提交方法，此后第一阶段分为两个步骤：</p>
<ul>
<li>事务管理器通知参与该事务的各个资源管理器，通知他们准备事务</li>
<li>资源管理器接收到消息后开始准备阶段，写好 Undo 和 Redo 事务日志并执行事务，但不提交，然后将是否就绪的消息返回给事务管理器（此时已经将事务的大部分事情做完，以后的内容耗时极小）。</li>
</ul>
<h5 id="第二阶段提交阶段">第二阶段：提交阶段</h5>
<p><img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/两段式提交第二阶段.png" width="500"> 第二阶段也分为两个步骤：</p>
<ul>
<li>事务管理器在接收各个消息后，开始分析，如果有任意其一失败，则发送回滚命令，否则发送提交命令。</li>
<li>各个资源管理器接收到命令后，执行（耗时很少），并将提交信息返回给事务管理器。</li>
</ul>
<p>一下是成功和回滚两种场景示例： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/分布式事务提交成功场景.png" width="600"> <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/分布式事务回滚场景.png" width="600"></p>
<blockquote>
<p><strong>为什么要分两步执行?</strong></p>
<ul>
<li>二阶段提交协议保证事务的一致性，二阶段提交将分布式分为了准备阶段和提交阶段，那么在提交阶段前其他服务器的真棒阶段失败了，可以通过undo日志记录执行回滚</li>
</ul>
</blockquote>
<p>XA 也有致命的缺点，那就是性能不理想，特别是在交易下单链路，往往并发量很高，XA无法满足高并发场景。XA 目前在商业数据库支持的比较理想，在 mysql 数据库中支持的不太理想，mysql 的 XA 实现，没有记录 prepare 阶段日志，主备切换回导致主库与备库数据不一致。许多 nosql 也没有支持 XA，这让 XA 的应用场景变得非常狭隘。具有如下问题：（mysql的redo log和binlog使用了两阶段提交）：</p>
<ul>
<li><strong>同步阻塞：</strong>从上面的描述可以看出，对于任何一次指令必须收到明确的响应，才会继续做下一步，否则处于阻塞状态，占用的资源被一直锁定，不会被释放。</li>
<li><strong>单点故障：</strong>如果事务管理器宕机，资源管理器没有了事务管理器指挥，会一直阻塞；尽管可以通过选举新的事务管理器替代原有协调者，但是如果之前事务管理器在发送一个提交指令后宕机，而提交指令仅仅被一个资源管理器接收，并且参与接收后资源管理器也宕机，新上任的事务管理器因为没有接收到任何一个资源管理器的提交判断信息即是否OK，是否成功提交还是回滚就不确定了，无法处理这种情况。</li>
<li><strong>脑裂</strong>：事务管理器发送提交指令，有的资源管理器接收后执行了事务，有的参与者没有接收到事务，就没有执行事务，多个参与者之间是不一致的。</li>
</ul>
<h4 id="基于xa协议的三阶段提交3pc">5.3.2 基于XA协议的三阶段提交（3PC）</h4>
<p>三阶段提交，在两阶段提交的基础下，改进两阶段。三阶段步骤如下。</p>
<ol type="1">
<li><p>阶段一<code>CanCommit</code>：协调者询问参与者是否可以进行事务提交。</p></li>
<li>阶段二PreCommit：若所有参与者<code>CanCommit</code>都回ok可以进行事务提交，协调者下达 <code>PreCommit</code> 命令，参与者锁定资源，并等待最终提交命令。
<ul>
<li>所有参与者对<code>PreCommit</code>返回确认信息，协调者向各个事务下发事务执行通知，锁定资源，并将执行情况返回。</li>
<li>部分参与者对<code>PreCommit</code>返回否认信息或<strong>协调者等待超时</strong>。这种情况，协调者认为事务无法正常执行，下发中断指令，各个参与者退出预备状态</li>
</ul></li>
<li><p>阶段三<code>Do Commit</code>：若第二阶段全部回应 ack，则下达 <code>Do Commit</code> ，进行事务最终提交，否则下达中断事务命令，所有参与者进行事务回滚。</p></li>
</ol>
<ul>
<li><strong>三阶段提交对比两阶段，引入超时机制减少事务阻塞，解决单点故障</strong>。</li>
<li><strong>在第三阶段，一旦参与者无法接受到协调者信号时，等待超时之后，参与者默认执行 commit，释放资源。</strong> &gt;这里之所以这么设计，其实是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了 PreCommit 请求，那么协调者产生 PreCommit 请求的前提条件是他在第二阶段开始之前，收到所有参与者的 CanCommit 响应都是 Yes。（一旦参与者收到了 PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到 <code>commit</code> 或者 <code>abort</code> 响应，但是他有理由相信：成功提交的几率很大。</li>
</ul>
<p><strong>三阶段仍然不能解决数据一致性问题。若协调者发出回滚命令，但是由于网络问题，参与者在等待时间内都无法接收到，这时参与者默认提交事务，而其他事务进行了回滚，造成事务不一致。</strong></p>
<h4 id="补偿事务tcc">5.3.3 补偿事务（TCC）</h4>
<p>TCC 其实就是采用的补偿机制，<strong>其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作</strong>。它分为三个阶段：</p>
<ul>
<li>Try 阶段主要是对业务系统做检测及资源预留，完成所有业务检查(一致性），预留必须业务资源(准隔离性)</li>
<li>Confirm 阶段主要是对业务系统做确认提交,Try 阶段执行成功并开始执行 Confirm 阶段时，默认 Confirm 阶段是不会出错的。即：只要 Try 成功，Confirm 一定成功。</li>
<li>Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。</li>
</ul>
<p>比如执行如下事务： <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">A</span>:-<span class="number">100</span>(补偿为 A:+<span class="number">100</span>)</span><br><span class="line"><span class="attribute">B</span>:+<span class="number">100</span></span><br></pre></td></tr></table></figure> 那么如果 B:+100 失败后就需要执行 A:+100。</p>
<p><strong>TCC 与阶段提交对比</strong></p>
<ul>
<li><p>使用 2PC 或 3PC 实现的分布式框架，业务应用层无需改动，接入较简单。但是相对应能较低，数据资源锁定较长。不太适合互联网等高并发业务场景。</p></li>
<li><p>而使用基于 TCC 实现分布式框架，相对 2PC 性能较高，可以保证数据最终一致性。但是对于应用层来说，一个方法必须改造成三个方法，且业务中需引入一些中间状态，相对而言应用改造程度较大。</p></li>
</ul>
<h5 id="引入tcc的例子">引入TCC的例子</h5>
<p>下面模拟商城一次支付过程。用户下单使用组合支付，即余额加红包支付。一次正常流程为：</p>
<ol type="1">
<li><p>创建订单</p></li>
<li><p>下单</p></li>
<li><ul>
<li>调用余额系统，扣减余额</li>
<li>调用红包系统，扣减红包余额</li>
<li>修改订单状态为已支付</li>
<li>完后支付。</li>
</ul></li>
</ol>
<p>实际过程如下图： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程1.png" width="700"> 但是这么一个支付过程调用多个子服务，并不能保证所有服务都能成功，比如在调用红包系统扣减红包系统失败。这个时候就碰到尴尬的场景，由于红包服务失败，导致方法异常退出，这个时候订单状态为初始状态，但是用户余额已经扣减。这对用户体验非常不友好。所以这次支付过程，必须存在机制将这次过程当成一次整体的行为，必须保证这其中服务调用，要么都成功，要么都失败，成为一个整体的事务。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程2.png" width="700"> 这时可以引入 TCC 事务，将整个下单过程作为一个整体。引入后，由于余额系统扣减是失败，这个时候回滚订单系统与红包系统。整个过程如下图: <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程3.png" width="700"> 由于余额系统的失败，需要撤销这次过程中所有更改，所以向订单系统发送撤销通知，向红包系统发出撤销通知。</p>
<p>因此系统引入 TCC 事务后，需要改造我们的调用过程。</p>
<h5 id="系统如何引入-tcc-事务">系统如何引入 TCC 事务</h5>
<p>根据 TCC 事务三步，这个时候必须将各个服务改造成 Try、Confirm 、Cancle 三步</p>
<p><strong>TCC TRY：</strong></p>
<p>根据上面的业务，订单系统增加 try 方法将订单状态修改成** PAYING**。余额系统增加一个 try 方法，先检查用于余额是否充足，然后先将余额扣减，然后将扣减的余额增加到冻结金额。红包系统同余额系统。从改造过程可以看出，TCC try 方法需检查各业务资源，且这过程需要引入中间状态。根据下图来看整个过程：</p>
<p><img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程4.png" width="700"></p>
<p><strong>TCC Confirm:</strong></p>
<p>TCC 第一步 TRY 如果所有子服务调用都成功，这个时候就需要确认各服务。各个服务增加 confirm 方法。如余额系统 confirm 方法用来将冻结金额置为0，红包系统如上。订单系统将订单状态修改为 SUCCESS。confirm 方法需要注意实现幂等。如订单系统更新前，一定要先判断该笔订单状态处于 PAYING，才能更新订单。整个过程如下图： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程5.png" width="700"> 讲到这里，必须用到 TCC 事务框架推动各服务。TCC 事务管理器感知到 TRY 方法结束后，自动调用各服务提供的 confirm 方法，将各服务状态修改为终态。</p>
<p><strong>TCC Cancle：</strong></p>
<p>如若 TCC Try 过程中，冻结红包方法失败，这时就需要将之前修改都撤销，修改成其初始状态。cancle 方法也需要实现幂等如 confirm 方法，如下图： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/TCC支付流程6.png" width="700"> 看到这，可以看出 TCC Try 成功，confirm 必定要成功，try 失败，cancle 必定要成功。因为 confirm 是系统更新为终态的关键。但是实际上，生产系统 confirm 或 cancle 肯定会有几率失败，这个时候就需要 TCC 框架记录调用 confirm 结果。如果 confirm 调用失败，TCC 框架需要记录下来，然后间隔一定时间再次去调用。</p>
<p>如若 TCC Try 过程中，冻结红包方法失败，这时就需要将之前修改都撤销，修改成其初始状态。cancle 方法也需要实现幂等如 confirm 方法，如下图：</p>
<h4 id="mq事务消息">5.3.4 MQ事务消息</h4>
<p><strong>所谓的消息事务就是基于消息中间件的两阶段提交，本质上是对消息中间件的一种特殊利用，它是将本地事务和发消息放在一个分布式事务里，保证要么本地操作成功并且对外发消息成功，要么两者都失败</strong>，开源的RocketMQ就支持这一特性，具体原理如下： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/MQ事务消息.png" width="600"></p>
<ol type="1">
<li>A 系统向消息中间件发送一条预备消息</li>
<li>消息中间件保存预备消息并返回成功</li>
<li>A 执行本地事务</li>
<li>A 发送提交消息给消息中间件</li>
</ol>
<p>通过以上4步就完成了一个消息事务，对于以上4个步骤，每个步骤都可能发生错误：</p>
<ul>
<li>步骤一出错，则整个事务失败，不会执行A的本地操作</li>
<li>步骤二出错，则整个事务失败，不会执行A的本地操作</li>
<li>步骤三出错，这时候需要回滚预备消息，怎么回滚？答案是A系统实现一个消息中间件的回调接口，消息中间件会去不断执行回调接口，检查A事务执行是否执行成功，如果失败则回滚预备消息</li>
<li>步骤四出错，这时候A的本地事务是成功的，那么消息中间件要回滚A吗？答案是不需要，其实通过回调接口，消息中间件能够检查到A执行成功了，这时候其实不需要A发提交消息了，消息中间件可以自己对消息进行提交，从而完成整个消息事务。</li>
</ul>
<p>基于消息中间件的两阶段提交往往用在高并发场景下，将一个分布式事务拆成一个消息事务（A系统的本地操作+发消息）+B系统的本地操作，其中B系统的操作由消息驱动，只要消息事务成功，那么A操作就一定成功，消息也一定发出来了，这时候B会收到消息去执行本地操作，如果本地操作失败，消息就会重投，直到B操作成功，这样就变相地实现了A与B的分布式事务。原理如下： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/MQ事务消息2.png" width="600"> 虽然上面的方案能够完成A和B的操作，但是A和B并不是严格一致的，而是最终一致的，在这里牺牲了一致性，换来了性能的大幅度提升。当然，这种做法也是有风险的，如果B一直执行不成功，那么一致性会被破坏，具体要不要这样做，还是得看业务能够承担多少风险。</p>
<h2 id="分布式一致性算法">6 分布式一致性算法</h2>
<p>在分布式系统中，为了消除单点宕机以提高系统可用性，通常会使用副本来进行容错，但这会带来另一个问题，即如何保证多个副本之间的一致性？</p>
<p><strong>分布式一致性 (distributed consensus) 是分布式系统中最基本的问题，用来保证一个分布式系统的可靠性以及容错能力</strong>。简单来说，<strong>分布式一致性是指多个服务器的保持状态一致。</strong></p>
<p>在分布式系统中，可能出现各种意外（断电、网络拥塞、CPU/内存耗尽等等），使得服务器宕机或无法访问，最终导致无法和其他服务器保持状态一致。为了应对这种情况，就需要有一种一致性协议来进行容错，使得分布式系统中即使有部分服务器宕机或无法访问，整体依然可以对外提供服务。</p>
<p>所谓的强一致性（线性一致性）并不是指集群中所有节点在任一时刻的状态必须完全一致，而是指一个目标，即让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，这样应用层就可以忽略系统底层多个数据副本间的同步问题。也就是说，我们可以将一个强一致性分布式系统当成一个整体，一旦某个客户端成功的执行了写操作，那么所有客户端都一定能读出刚刚写入的值。即使发生网络分区故障，或者少部分节点发生异常，整个集群依然能够像单机一样提供服务。</p>
<p><strong>共识算法（Consensus Algorithm）就是用来做这个事情的，它保证即使在小部分（≤ (N-1)/2）节点故障的情况下，系统仍然能正常对外提供服务。</strong></p>
<p>共<strong>识算法通常基于状态复制机（Replicated State Machine）模型，也就是所有节点从同一个 state 出发，经过同样的操作 log，最终达到一致的 state。</strong> <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/分布式算法—复制状态机.png" width="600"></p>
<p>复制状态机（Replicated State Machines） 是指一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。</p>
<p>复制状态机通常都是基于复制日志实现的，每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。</p>
<p><strong>保证复制日志相同就是一致性算法的工作了</strong>。在一台服务器上，一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，尽管有些服务器会宕机。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成一个高可靠的状态机。</p>
<p>实际系统中使用的一致性算法通常含有以下特性：</p>
<ul>
<li><p><strong>安全性保证（绝对不会返回一个错误的结果）：</strong>在非拜占庭错误（消息篡改）情况下，包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。</p></li>
<li><p><strong>可用性</strong>：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。</p></li>
<li><p><strong>不依赖时序来保证一致性</strong>：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题</p></li>
</ul>
<p>通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。</p>
<p>共识算法是构建强一致性分布式系统的基石，Paxos 是共识算法的代表，而 Raft 则是其作者在博士期间研究 Paxos 时提出的一个变种，主要优点是容易理解、易于实现，甚至关键的部分都在论文中给出了伪代码实现。</p>
<h2 id="paxos算法">7. Paxos算法</h2>
<h2 id="raft算法">8. Raft算法</h2>
<p>Raft 使用 Quorum 机制来实现共识和容错，对 Raft 集群的操作称为提案，每当发起一个提案，必须得到大多数（&gt; N/2）节点的同意才能提交。 &gt;这里的“提案”可以先狭义地理解为对集群的读写操作，“提交”理解为操作成功。 那么当向 Raft 集群发起一系列读写操作时，集群内部究竟发生了什么呢？</p>
<p>首先，Raft 集群必须存在一个主节点（leader），客户端向集群发起的所有操作都必须经由主节点处理。所以 Raft 核心算法中的第一部分就是<strong>选主</strong>（Leader election）——没有主节点集群就无法工作，先票选出一个主节点，再考虑其它事情。</p>
<p>其次，主节点需要承载什么工作呢？它会负责接收客户端发过来的操作请求，将操作包装为<strong>日志</strong>同步给其它节点，在保证<strong>大部分</strong>节点都同步了本次操作后，就可以安全地给客户端回应响应了。这一部分工作在 Raft 核心算法中叫<strong>日志复制（Log replication）</strong>。</p>
<p>然后，因为主节点的责任是如此之大，所以节点们在选主的时候一定要谨慎，只有<strong>符合条件</strong>的节点才可以当选主节点。此外主节点在处理操作日志的时候也一定要谨慎，为了保证集群对外展现的一致性，不可以<strong>覆盖或删除</strong>前任主节点已经处理成功的操作日志。所谓的“谨慎处理”，其实就是在选主和提交日志的时候进行一些限制，这一部分在 Raft 核心算法中叫<strong>安全性（Safety）</strong>。</p>
<p><strong>Raft 核心算法其实就是由这三个子问题组成的：选主（Leader election）、日志复制（Log replication）、安全性（Safety）。这三部分共同实现了 Raft 核心的共识和容错机制。</strong></p>
<p>除了核心算法外，Raft 也提供了几个工程实践中必须面对问题的解决方案。</p>
<p>第一个是关于日志无限增长的问题。Raft 将操作包装成为了日志，集群每个节点都维护了一个不断增长的日志序列，状态机只有通过重放日志序列来得到。但由于这个日志序列可能会随着时间流逝不断增长，因此必须有一些办法来避免无休止的磁盘占用和过久的日志重放。这一部分叫<strong>日志压缩（Log compaction）。</strong></p>
<p>第二个是关于集群成员变更的问题。一个 Raft 集群不太可能永远是固定几个节点，总有扩缩容的需求，或是节点宕机需要替换的时候。直接更换集群成员可能会导致严重的脑裂问题。Raft 给出了一种安全变更集群成员的方式。这一部分叫<strong>集群成员变更（Cluster membership change）</strong>。</p>
<p>此外，还会额外讨论<strong>线性一致性</strong>的定义、为什么** Raft 不能与线性一致划等号<strong>、如何基于</strong> Raft 实现线性一致<strong>，以及在如何</strong>保证线性一致的前提下进行读性能优化**。</p>
<h3 id="选主">8.1 选主</h3>
<p>原生的 Paxos 算法使用了一种点对点（peer-to-peer）的方式，所有节点地位是平等的。在理想情况下，算法的目的是制定<strong>一个决策</strong>，这对于简化的模型比较有意义。但在工业界很少会有系统会使用这种方式，当有一系列的决策需要被制定的时候，先选出一个 leader 节点然后让它去协调所有的决策，这样算法会更加简单快速。</p>
<p>此外，和其它一致性算法相比，Raft 赋予了 leader 节点更强的领导力，称之为 <strong>Strong Leader</strong>。比如说日志条目只能从 leader 节点发送给其它节点而不能反着来，这种方式简化了日志复制的逻辑，使 Raft 变得更加简单易懂。</p>
<h4 id="节点角色">8.1.1 节点角色</h4>
<p>Raft 集群中每个节点都处于以下三种角色之一：</p>
<ul>
<li><strong>Leader</strong>: 所有请求的处理者，接收客户端发起的操作请求，写入本地日志后同步至集群其它节点。</li>
<li><strong>Follower</strong>: 请求的被动更新者，从 leader 接收更新请求，写入本地文件。如果客户端的操作请求发送给了 follower，会首先由 follower 重定向给 leader。</li>
<li><strong>Candidate:</strong> 如果 follower 在一定时间内没有收到 leader 的心跳，则判断 leader 可能已经故障，此时启动 leader election 过程，本节点切换为 candidate 直到选主结束。</li>
</ul>
<h4 id="任期">8.1.2 任期</h4>
<p>每开始一次新的选举，称为一个<strong>任期（term）</strong>，每个 term 都有一个严格递增的整数与之关联。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft任期.png" width="600"> 每当 candidate 触发 leader election 时都会增加 term，如果一个 candidate 赢得选举，他将在本 term 中担任 leader 的角色。但并不是每个 term 都一定对应一个 leader，有时候某个 term 内会由于<strong>选举超时</strong>导致选不出 leader，这时 candicate 会递增 term 号并开始新一轮选举。</p>
<p>不同服务器节点观察到的任期转换状态可能不一样：有的服务器节点可能观察到多次的任期转换，而有的服务器节点可能观察不到任何一次任期转换。</p>
<p>任期在 Raft 算法中充当逻辑时钟的作用，使得服务器节点可以查明一些过期的信息（比如过期的 Leader）。每个服务器节点都会存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号。</p>
<ul>
<li>如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。</li>
<li>如果一个 Candidate 或者 Leader 发现自己的任期号过期了，那么他会立即恢复成跟随者状态。</li>
<li>如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</li>
</ul>
<h4 id="节点通信">8.1.3 节点通信</h4>
<p>Raft 算法中服务器节点之间的通信使用 <strong>远程过程调用（RPC）</strong>。基本的一致性算法只需要两种 RPC：</p>
<ul>
<li><strong>RequestVote RPC</strong> - 请求投票 RPC，由 Candidate 在选举期间发起。</li>
<li><strong>AppendEntries RPC</strong> - 附加条目 RPC，由 Leader 发起，用来复制日志和提供一种心跳机制。</li>
</ul>
<h4 id="节点状态转换">8.1.4 节点状态转换</h4>
<p>集群每个节点的状态都只能是 leader、follower 或 candidate，那么节点什么时候会处于哪种状态呢？下图展示了一个节点可能发生的状态转换： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft状态转换.png" width="600"> 下面详细讨论下每个转换所发生的场景。 ##### 8.1.4.1 Follower 状态转换过程 Raft 的<strong>选主</strong>基于一种<strong>心跳机制</strong>，集群中每个节点刚启动时都是 follower 身份（Step: starts up），leader 会周期性的向所有节点发送心跳包来维持自己的权威，那么首个 leader 是如何被选举出来的呢？方法是<strong>如果一个 follower 在一段时间内没有收到任何心跳，也就是选举超时，那么它就会主观认为系统中没有可用的 leader，并发起新的选举（Step: times out, starts election）。</strong></p>
<p>若 follower 想发起一次选举，<strong>follower 需要先增加自己的当前 term，并将身份切换为 candidate。然后它会向集群其它节点发送“请给自己投票”的消息（RequestVote RPC）。</strong></p>
<blockquote>
<p>这里有一个问题，即这个“选举超时时间”该如何制定？如果所有节点在同一时刻启动，经过同样的超时时间后同时发起选举，整个集群会变得低效不堪，极端情况下甚至会一直选不出一个主节点（后面分析）。 <strong>Raft 巧妙的使用了一个随机化的定时器，让每个节点的“超时时间”在一定范围内随机生成（一般为 150ms ~ 300ms），这样就大大的降低了多个节点同时发起选举的可能性。</strong></p>
</blockquote>
<h5 id="candidate-状态转换过程">8.1.4.2 Candidate 状态转换过程</h5>
<p>Follower 切换为 candidate 并向集群其他节点发送“请给自己投票”的消息后，接下来会有三种可能的结果，也即上面节点状态图中 candidate 状态向外伸出的三条线。</p>
<ul>
<li><strong>选举成功（Step: receives votes from majority of servers）</strong> 当candicate从整个集群的大多数（N/2+1）节点获得了针对同一 term 的选票时，它就赢得了这次选举，立刻将自己的身份转变为 leader 并开始向其它节点发送心跳来维持自己的权威。</li>
</ul>
<p><strong>每个节点针对每个 term 只能投出一张票，并且按照先到先得的原则</strong>。这个规则确保只有一个 candidate 会成为 leader。</p>
<ul>
<li><strong>选举失败（Step: discovers current leader or new term）</strong> Candidate 在等待投票回复的时候，可能会突然收到其它自称是 leader 的节点发送的心跳包（AppendEntries RPC），如果这个心跳包里携带的 term <strong>不小于</strong> candidate 当前的 term，那么 candidate 会承认这个 leader，并将身份切回 follower。</li>
</ul>
<p>这说明其它节点已经成功赢得了选举，只需立刻跟随即可。但如果心跳包中的 term 比自己小，candidate 会拒绝这次请求并保持选举状态。</p>
<ul>
<li><strong>选举超时（Step: times out, new election）</strong> 第三种可能的结果是 candidate 既没有赢也没有输。如果有多个 follower 同时成为 candidate，选票是可能被瓜分的，如果没有任何一个 candidate 能得到大多数节点的支持，那么每一个 candidate 都会超时。</li>
</ul>
<p>此时 candidate 需要增加自己的 term，然后发起新一轮选举。</p>
<p>如果这里不做一些特殊处理，选票可能会一直被瓜分，导致选不出 leader 来。这里的“特殊处理”指的就是前文所述的<strong>随机化选举超时时间</strong>。</p>
<p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，竞选超时时间是一个随机的时间，在一个固定的区间（例如 150-300 毫秒）随机选择，这样可以把选举都分散开。</p>
<p>以至于在大多数情况下，只有一个服务器会超时，然后它赢得选举，成为 Leader，并在其他服务器超时之前发送心跳包。</p>
<p>同样的机制也被用在选票瓜分的情况下：每一个 Candidate 在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。</p>
<h5 id="leader-状态转换过程">8.1.4.3 Leader 状态转换过程</h5>
<p>节点状态图中的最后一条线是：discovers server with higher term。</p>
<p>想象一个场景：当 leader 节点发生了宕机或网络断连，此时其它 follower 会收不到 leader 心跳，首个触发超时的节点会变为 candidate 并开始拉票（由于随机化各个 follower 超时时间不同），由于该 candidate 的 term 大于原 leader 的 term，因此所有 follower 都会投票给它，这名 candidate 会变为新的 leader。一段时间后原 leader 恢复了，收到了来自新 leader 的心跳包，发现心跳中的 term 大于自己的 term，此时该节点会立刻切换为 follower 并跟随的新 leader。</p>
<p>以上就是 Raft 的选主逻辑，<strong>但还有一些细节（譬如是否给该 candidate 投票还有一些其它条件）依赖算法的其它部分基础，会在后续“安全性”一章描述。</strong></p>
<p>当票选出 leader 后，leader 也该承担起相应的责任了，这个责任是什么？就是下面介绍的“<strong>日志复制</strong>”。</p>
<h3 id="日志复制">8.2 日志复制</h3>
<p>前面说过，共识算法通常基于<strong>状态复制机（Replicated State Machine）</strong>模型，所有节点从<strong>同一个 state</strong> 出发，经过一系列同<strong>样操作 log</strong> 的步骤，最终也必将达到<strong>一致的 state</strong>。也就是说，只要保证集群中所有节点的 log 一致，那么经过一系列应用（apply）后最终得到的状态机也就是一致的。</p>
<p><strong>Raft 负责保证集群中所有节点 log 的一致性。</strong></p>
<p>此外还提到过：Raft 赋予了 leader 节点<strong>更强的领导力（Strong Leader）</strong>。那么 Raft 保证 log 一致的方式就很容易理解了，<strong>即所有 log 都必须交给 leader 节点处理，并由 leader 节点复制给其它节点</strong>。</p>
<p>这个过程，就叫做<strong>日志复制（Log replication）</strong></p>
<h4 id="日志格式">8.2.1 日志格式</h4>
<p>日志由含<strong>日志索引（log index）</strong>的<strong>日志条目（log entry）</strong>组成。每个日志条目包含它被创建时的 Term 号（下图中方框中的数字），和一个复制状态机需要执行的指令。如果一个日志条目被复制到半数以上的服务器上，就被认为可以提交（Commit）了。</p>
<p>日志模型如下图所示：（x ← 3 代表 x 赋值为 3） <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志格式.png" width="600"> 每条日志除了存储状态机的操作指令外，还会拥有一个<strong>唯一的整数索引值（log index）</strong>来表明它在日志集合中的位置。</p>
<p>此外，每条日志还会存储一个 <strong>term</strong> 号（日志条目方块最上方的数字，相同颜色 term 号相同），该 term 表示 leader 收到这条指令时的当前任期，term 相同的 log 是由同一个 leader 在其任期内发送的。</p>
<p>当一条日志被 leader 节点认为可以安全的 apply 到状态机时，称这条日志是 <strong>committed</strong>（上图中的 committed entries）。</p>
<p>那么什么样的日志可以被 commit 呢？答案是：<strong>当 leader 得知这条日志被集群过半的节点复制成功时</strong>。因此在上图中可以看到 (term3, index7) 这条日志以及之前的日志都是 committed，尽管有两个节点拥有的日志并不完整。</p>
<p>Raft 保证所有 committed 日志都已经被持久化，且“最终”一定会被状态机apply。</p>
<blockquote>
<p>注：这里的“最终”用词很微妙，它表明了一个特点：Raft 保证的只是集群内日志的一致性，而真正期望的集群对外的状态机一致性还需要做一些额外工作，这一点在后面线性一致性与读性能优化说。</p>
</blockquote>
<h4 id="日志复制流程">8.2.2 日志复制流程</h4>
<p>S1 当选 leader，此时还没有任何日志。此时模拟客户端向 S1 发起一个请求。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-1.png" width="600"> S1 收到客户端请求后新增了一条日志 (term2, index1)，然后并行地向其它节点发起 AppendEntries RPC。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-2.png" width="600"> S2、S4 率先收到了请求，各自附加了该日志，并向 S1 回应响应。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-3.png" width="600"> 所有节点都附加了该日志，但由于 leader 尚未收到任何响应，因此暂时还不清楚该日志到底是否被成功复制。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-4.png" width="600"> 当 S1 收到2个节点的响应时，该日志条目的边框就已经变为实线，表示该日志已经<strong>安全的复制</strong>，因为在5节点集群中，2个 follower 节点加上 leader 节点自身，副本数已经确保过半，此时 <strong>S1 将响应客户端的请求</strong>。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-5.png" width="600"> leader 后续会持续发送心跳包给 followers，心跳包中会携带当前已经安全复制（我们称之为 committed）的日志索引，此处为 (term2, index1)。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-6.png" width="600"> 所有 follower 都通过心跳包得知 (term2, index1) 的 log 已经成功复制 （committed），因此所有节点中该日志条目的边框均变为实线。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志复制流程-7.png" width="600"></p>
<h4 id="日志一致性保障">8.2.3 日志一致性保障</h4>
<p>前边使用了 <code>(term2, index1)</code> 这种方式来表示一条日志条目，这里为什么要带上 term，而不仅仅是使用 index？<strong>原因是 term 可以用来检查不同节点间日志是否存在不一致的情况</strong>。</p>
<p>Raft 日志同步保证如下两点：</p>
<ol type="1">
<li><strong>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则它们所存储的命令是相同的。</strong></li>
</ol>
<p>这个特性基于这条原则：Raft 要求 leader 在一个 term 内针对同一个 index 只能创建一条日志，并且永远不会修改它。</p>
<ol start="2" type="1">
<li><strong>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则它们之前的所有条目都是完全一样的</strong>。 这个特性由 AppendEntries RPC 的一个简单的一致性检查所保证。在发送 AppendEntries RPC 时，Leader 会把新日志条目之前的日志条目的日志索引和 Term 号一起发送。如果 Follower 在它的日志中找不到包含相同日志索引和 Term 号的日志条目，它就会拒绝接收新的日志条目。</li>
</ol>
<p>所以，<strong>只要 follower 持续正常地接收来自 leader 的日志</strong>，那么就可以通过归纳法验证上述结论。</p>
<h4 id="可能出现的日志不一致场景">8.2.4 可能出现的日志不一致场景</h4>
<p>一般情况下，Leader 和 Followers 的日志保持一致，因此日志条目一致性检查通常不会失败。然而，Leader 崩溃可能会导致日志不一致：旧的 Leader 可能没有完全复制完日志中的所有条目。</p>
<p>Leader 和 Follower 可能存在多种日志不一致的可能： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft-leader和follower日志不一致的情况.png" width="600"> 上图展示了一个 term8 的 leader 刚上任时，集群中日志可能存在的混乱情况。例如 follower 可能缺少一些日志（a ~ b），可能多了一些未提交的日志（c ~ d），也可能既缺少日志又多了一些未提交日志（e ~ f）。</p>
<blockquote>
<p>Follower 不可能比 leader 多出一些已提交（committed）日志，这一点是通过选举上的限制来达成的。</p>
</blockquote>
<p>先来尝试复现上述 a ~ f 场景，最后再讲 Raft 如何解决这种不一致问题。</p>
<h5 id="场景ab-follower-日志落后于-leader">场景a~b: Follower 日志落后于 leader</h5>
<p>这种场景其实很简单，即 follower 宕机了一段时间，follower-a 从收到 (term6, index9) 后开始宕机，follower-b 从收到 (term4, index4) 后开始宕机。</p>
<h5 id="场景c.-follower-日志比-leader-多-term6">场景c. Follower 日志比 leader 多 term6</h5>
<p>当 term6 的 leader 正在将 (term6, index11) 向 follower 同步时，该 leader 发生了宕机，且此时只有 follower-c 收到了这条日志的 AppendEntries RPC。然后经过一系列的选举，term7 可能是选举超时，也可能是 leader 刚上任就宕机了，最终 term8 的 leader 上任了，于是就看到了场景 c。</p>
<h5 id="场景d.-follower-日志比-leader-多-term7">场景d. Follower 日志比 leader 多 term7</h5>
<p>当 term6 的 leader 将 (term6, index10) 成功 commit 后，发生了宕机。此时 term7 的 leader 走马上任，连续同步了两条日志给 follower，然而还没来得及 commit 就宕机了，随后集群选出了 term8 的 leader。</p>
<h5 id="场景e.-follower-日志比-leader-少-term5-6多-term4">场景e. Follower 日志比 leader 少 term5 ~ 6，多 term4</h5>
<p>当 term4 的 leader 将 (term4, index7) 同步给 follower，且将 (term4, index5) 及之前的日志成功 commit 后，发生了宕机，紧接着 follower-e 也发生了宕机。这样在 term5~7 内发生的日志同步全都被 follower-e 错过了。当 follower-e 恢复后，term8 的 leader 也刚好上任了。</p>
<h5 id="场景f.-follower-日志比-leader-少-term4-6多-term2-3">场景f. Follower 日志比 leader 少 term4 ~ 6，多 term2 ~ 3</h5>
<p>当 term2 的 leader 同步了一些日志（index4 ~ 6）给 follower 后，尚未来得及 commit 时发生了宕机，但它很快恢复过来了，又被选为了 term3 的 leader，它继续同步了一些日志（index7~11）给 follower，但同样未来得及 commit 就又发生了宕机，紧接着 follower-f 也发生了宕机，当 follower-f 醒来时，集群已经前进到 term8 了。</p>
<h4 id="如何处理日志不一致的场景">8.2.5 如何处理日志不一致的场景</h4>
<p>通过上述场景可以看到，真实世界的集群情况很复杂，那么 Raft 是如何应对这么多不一致场景的呢？其实方式很简单暴力，想想 <strong>Strong Leader</strong> 这个词。</p>
<p><strong>Raft 强制要求 follower 必须复制 leader 的日志集合来解决不一致问题。</strong></p>
<p>也就是说，follower 节点上任何与 leader 不一致的日志，都会被 leader 节点上的日志所覆盖。这并不会产生什么问题，因为某些<strong>选举上的限制</strong>，如果 follower 上的日志与 leader 不一致，那么该日志在 follower 上一定是未提交的。未提交的日志并不会应用到状态机，也不会被外部的客户端感知到。</p>
<p>要使得 follower 的日志集合跟自己保持完全一致，leader 必须先找到二者间最后一次达成一致的地方。因为一旦这条日志达成一致，在这之前的日志一定也都一致。这个确认操作是在 AppendEntries RPC 的一致性检查步骤完成的。</p>
<p>Leader 针对每个 follower 都维护一个** next index<strong>，</strong>表示下一条需要发送给该follower 的日志索引**。当一个 leader 刚刚上任时，它初始化所有 next index 值为自己最后一条日志的 index+1。但凡某个 follower 的日志跟 leader 不一致，那么此次 AppendEntries RPC 的一致性检查就会失败。在被 follower 拒绝这次 Append Entries RPC 后，leader 会减少 next index 的值并进行重试。</p>
<p>最终一定会存在一个 next index 使得 leader 和 follower 在这之前的日志都保持一致。极端情况下 next index 为1，表示 follower 没有任何日志与 leader 一致，leader 必须从第一条日志开始同步。</p>
<p>针对每个 follower，一旦确定了 next index 的值，leader 便开始从该 index 同步日志，follower 会删除掉现存的不一致的日志，保留 leader 最新同步过来的。</p>
<p>整个集群的日志会在这个简单的机制下自动趋于一致。此外要注意，<strong>leader 从来不会覆盖或者删除自己的日志，而是强制 follower 与它保持一致</strong>。</p>
<p>这就要求集<strong>群票选出的 leader 一定要具备“日志的正确性”</strong>，这也就关联到了前文提到的：<strong>选举上的限制</strong>。</p>
<h3 id="安全性及正确性">8.3 安全性及正确性</h3>
<p>前面的章节描述了 Raft 算法是如何选主和复制日志的，然而到目前为止描述的这套机制还不能保证每个节点的状态机会严格按照相同的顺序 apply 日志。想象以下场景：</p>
<ul>
<li>1.Leader 将一些日志复制到了大多数节点上，进行 commit 后发生了宕机。</li>
<li>2.某个 follower 并没有被复制到这些日志，但它参与选举并当选了下一任 leader。</li>
<li>3.新的 leader 又同步并 commit 了一些日志，这些日志覆盖掉了其它节点上的上一任 committed 日志。</li>
<li>4.各个节点的状态机可能 apply 了不同的日志序列，出现了不一致的情况</li>
</ul>
<p>如果按上述操作选举，就会覆盖之前term所committed的日志。因此需要对“<strong>选主+日志复制</strong>”这套机制加上一些<strong>额外的限制</strong>，来保证状态机的安全性，也就是 Raft 算法的正确性。</p>
<p>Raft 增加了一些限制来完善 Raft 算法，以保证安全性：保证了任意 Leader 对于给定的 Term，都拥有了之前 Term 的所有被提交的日志条目。有两个，一是对选举做了限制，而是对提交做了限制</p>
<h4 id="对选举的限制">8.3.1 对选举的限制</h4>
<ul>
<li><strong>raft规定拥有最新的已提交的日志条目的 Follower 才有资格成为 Leader。</strong>，具体就是RequestVote RPC 实现了这样的限制：RequestVote RPC 中包含了 Candidate 的日志信息， Follower 会拒绝掉那些日志没有自己新的投票请求。</li>
</ul>
<p>再来分析下前文所述的 committed 日志被覆盖的场景，根本问题其实发生在<strong>第2步</strong>。Candidate 必须有足够的资格才能当选集群 leader，否则它就会给集群带来不可预料的错误。</p>
<p><strong>Candidate 想要赢得选举成为 leader，必须得到集群大多数节点的投票，那么它的日志就一定至少不落后于大多数节点</strong>。<strong>又因为一条日志只有复制到了大多数节点才能被 commit，因此能赢得选举的 candidate 一定拥有所有 committed 日志。，因此这种对选举的限制能够保证raft的安全和准确性</strong></p>
<p>因此才会断定地说：Follower 不可能比 leader 多出一些 committed 日志。</p>
<h5 id="如何判断哪个日志条目比较新">如何判断哪个日志条目比较新？</h5>
<p>Raft 通过比较两份日志中最后一条日志条目的日志索引和 Term 来判断哪个日志比较新。</p>
<ol type="1">
<li>先判断 Term，哪个数值大即代表哪个日志比较新。</li>
<li>如果 Term 相同，再比较 日志索引，哪个数值大即代表哪个日志比较新。</li>
</ol>
<h4 id="对提交的限制">8.3.1 对提交的限制</h4>
<ul>
<li>raft规定<strong>Leader 只允许 commit 包含当前 term 的日志。如果不包含当前term就不能提交</strong></li>
</ul>
<p>除了对选举增加一点限制外，还需对 commit 行为增加一点限制，来完成 Raft 算法核心部分的最后一块拼图。</p>
<p>回忆下什么是<code>commit</code>：</p>
<p>当 <code>leader</code> 得知某条日志被集群过半的节点复制成功时，就可以进行 <code>commit</code>，<code>committed</code> 日志一定最终会被状态机 <code>apply</code>。</p>
<p>所谓 <code>commit</code>其实就是对日志简单进行一个标记，表明其可以被 <code>apply</code>到状态机，并针对相应的客户端请求进行响应。</p>
<p>然而 <code>leader</code> 并不能在任何时候都随意 <code>commit</code> 旧任期留下的日志，即使它已经被复制到了大多数节点。</p>
<p>Raft 论文给出了一个经典场景： <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft提交限制.png" width="600"></p>
<p>上图从左到右按时间顺序模拟了问题场景。</p>
<p><strong>阶段a：</strong>S1 是 leader，收到请求后将 (term2, index2) 只复制给了 S2，尚未复制给 S3 ~ S5。</p>
<p><strong>阶段b：</strong>S1 宕机，S5 当选 term3 的 leader（S3、S4、S5 三票），收到请求后保存了 (term3, index2)，尚未复制给任何节点。</p>
<p><strong>阶段c：</strong>S5 宕机，S1 恢复，S1 重新当选 term4 的 leader，继续将 (term2, index2) 复制给了 S3，已经满足大多数节点，我们将其 commit。</p>
<p><strong>阶段d：</strong>S1 又宕机，S5 恢复，S5 重新当选 leader（S2、S3、S4 三票），将 (term3, inde2) 复制给了所有节点并 commit。<strong>注意，此时发生了致命错误，已经 committed 的 (term2, index2) 被 (term3, index2) 覆盖了。</strong></p>
<p><strong>为了避免这种错误，需要添加一个额外的限制：Leader 只允许 commit 包含当前 term 的日志。一旦当前 Term 的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。</strong></p>
<p>针对上述场景，问题发生在<strong>阶段c</strong>，即使作为 term4 leader 的 S1 将 (term2, index2) 复制给了大多数节点，它也不能直接将其 commit，而是必须等待 term4 的日志到来并成功复制后，一并进行 commit。</p>
<p><strong>阶段e：</strong>在添加了这个限制后，要么 <code>(term2, index2)</code>始终没有被 <code>commit</code>，这样 S5 在阶段d将其覆盖就是安全的；要么 <code>(term2, index2)</code>同 (term4, index3) 一起被 <code>commit</code>，这样 S5 根本就无法当选 leader，因为大多数节点的日志都比它新，也就不存在前边的问题了。</p>
<h3 id="集群成员变更与日志压缩">8.4 集群成员变更与日志压缩</h3>
<p>尽管已经通过的内容了解了 Raft 算法的核心部分，但相较于算法理论来说，在工程实践中仍有一些现实问题需要去面对。Raft 非常贴心的在论文中给出了两个常见问题的解决方案，它们分别是：</p>
<ul>
<li><strong>集群成员变更</strong>：如何安全地改变集群的节点成员。</li>
<li><strong>日志压缩</strong>：如何解决日志集合无限制增长带来的问题。</li>
</ul>
<h4 id="集群成员变更">8.4.1 集群成员变更</h4>
<p>前文的理论描述中都假设了集群成员是不变的，然而在实践中有时会需要替换宕机机器或者改变复制级别（即增减节点）。一种最简单暴力达成目的的方式就是：停止集群、改变成员、启动集群。这种方式在执行时会导致集群整体不可用，此外还存在手工操作带来的风险。</p>
<p>为了避免这样的问题，Raft 论文中给出了一种无需停机的、自动化的改变集群成员的方式，其实本质上还是利用了 Raft 的核心算法，将集群成员配置作为一个特殊日志从 leader 节点同步到其它节点去。</p>
<h6 id="直接切换集群成员配置">8.4.1.1 直接切换集群成员配置</h6>
<p><strong>先说结论：所有将集群从旧配置直接完全切换到新配置的方案都是不安全的，可能会产生多个leader。</strong></p>
<p>因此不能想当然的将新配置直接作为日志同步给集群并 apply。因为不可能让集群中的全部节点在“同一时刻”原子地切换其集群成员配置，所以在切换期间不同的节点看到的集群视图可能存在不同，最终可能导致集群存在多个 leader。</p>
<p>为了理解上述结论，来看一个实际出现问题的场景，下图对其进行了展现。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft集群成员变更-1.png" width="700"> 阶段a：集群存在 S1 ~ S3 三个节点，将该成员配置表示为 C-old，绿色表示该节点当前视图（成员配置）为 C-old，其中红边的 S3 为 leader。</p>
<p>阶段b：集群新增了 S4、S5 两个节点，该变更从 leader 写入，将 S1 ~ S5 的五节点新成员配置表示为 C-new，蓝色表示该节点当前视图为 C-new。</p>
<p>阶段c：假设 S3 短暂宕机触发了 S1 与 S5 的超时选主。</p>
<p>阶段d：S1 向 S2、S3 拉票，S5 向其它全部四个节点拉票。由于 S2 的日志并没有比 S1 更新，因此 S2 可能会将选票投给 S1，S1 两票当选（因为 S1 认为集群只有三个节点）。而 S5 肯定会得到 S3、S4 的选票，因为 S1 感知不到 S4，没有向它发送 RequestVote RPC，并且 S1 的日志落后于 S3，S3 也一定不会投给 S1，结果 S5 三票当选。<strong>最终集群出现了多个主节点的致命错误，也就是所谓的脑裂。</strong></p>
<p>上面导致成员变更脑裂的<strong>原因其实就是某一时刻Cold和Cnew中同时存在两个不相交的多数派</strong>，如下图(改图跟上面一个图是一样，表达方式不同)，在虚线时刻位置Server1和Server就出现了<span class="math inline">\(C_{old}\)</span>和<span class="math inline">\(C_{new}\)</span>不相交的多数派，此时如果leader节点宕机，就极有可能产生脑裂。 <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/不相交多数派.png" width="700"></p>
<h5 id="两阶段切换集群成员配置">8.4.1.2 两阶段切换集群成员配置</h5>
<p>为避免直接切换带来的脑裂问题，Raft 使用一种两阶段方法来切换集群成员配置，该方法引入了<strong>一个联合成员配置<span class="math inline">\(C_{old,new}\)</span>作为过渡配置</strong></p>
<ul>
<li><strong>阶段一</strong>：
<ul>
<li>1.客户端将 C-new 发送给 leader，leader在本地生成一个log entry，其内容是Cold∪Cnew即Cold和Cnew取并集，表示为 C-old,new。</li>
<li>2.Leader 将 C-old,new 包装为日志同步给其它节点。</li>
<li>3.Follower 收到 C-old,new 后立即 apply，当 C-old,和C-new 的大多数节点（即 C-old 的大多数节点和 C-new 的大多数节点）都确认了这条日志后，leader 将该日志 commit。</li>
</ul></li>
<li><strong>阶段二</strong>:
<ul>
<li>1.Leader 接着生成一个新的log entry，其内容是新成员配置C-new包装为日志同步给其它节点。</li>
<li>2.Follower 收到 C-new 后立即 apply，如果此时发现自己不在 C-new 列表，则主动退出集群。</li>
<li>3.Leader 确认 C-new 的大多数节点都切换成功后，给客户端发送执行成功的响应，切换成功。</li>
</ul></li>
</ul>
<h5 id="什么两阶段切换集群成员配置可以保证不会出现多个-leader">8.4.1.3什么两阶段切换集群成员配置可以保证不会出现多个 leader？</h5>
<p>因为两阶段切换引入了一个联合成员配置<span class="math inline">\(C_{old,new}\)</span>作为过渡配置**，从而在切换过程中出现三个阶段，一个是完全有<span class="math inline">\(C_{old}&amp;做解决的，另一个是在过渡阶段\)</span>C_{old,new}<span class="math inline">\(决定，最后一个是切换完成后由\)</span>C_{new}$决定。因此无论在哪个阶段leader宕机，都只能选出一个新的leader <img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/三个阶段.png" width="700"></p>
<p><strong>阶段1. C-old,new 尚未 commit</strong> 该阶段所有节点的配置要么是 <code>C-old</code>，要么是<code>C-old,new</code>，但无论是二者哪种，只要原 leader 发生宕机，<strong>该阶段新 leader 都必须得到大多数 C-old 集合内节点的投票。</strong></p>
<p>以上面说到的场景为例，S5 在阶段d根本没有机会成为 leader，因为 C-old 中只有 S3 给它投票了，不满足大多数。</p>
<p><strong>阶段2. C-old,new 已经 commit，C-new 尚未下发</strong> 该阶段 C-old,new 已经 commit，可以确保已经被 C-old,new 的大多数节点（再次强调：C-old 的大多数节点和 C-new 的大多数节点）复制。</p>
<p>因此当 leader 宕机时，新选出的 leader 一定是已经拥有 C-old,new 的节点，不可能出现两个 leader。</p>
<p><strong>阶段3. C-new 已经下发但尚未 commit</strong> 该阶段集群中可能有三种节点 C-old、C-old,new、C-new，但由于已经经历了阶段2，因此 C-old 节点不可能再成为 leader。而无论是 C-old,new 还是 C-new 节点发起选举，都需要经过大多数 C-new 节点的同意，因此也不可能出现两个 leader。</p>
<p><strong>阶段4. C-new 已经 commit</strong> 该阶段 C-new 已经被 commit，因此只有 C-new 节点可以得到大多数选票成为 leader。此时集群已经安全地完成了这轮变更，可以继续开启下一轮变更了。</p>
<p>以上便是对该两阶段方法可行性的分步验证，Raft 论文将该方法称之为共同一致（Joint Consensus）。</p>
<h4 id="日志压缩">8.4.2 日志压缩</h4>
<p>Raft 核心算法维护了日志的一致性，通过 apply 日志也就得到了一致的状态机，客户端的操作命令会被包装成日志交给 Raft 处理。</p>
<p>然而在实际系统中，客户端操作是连绵不断的，但日志却不能无限增长，首先它会占用很高的存储空间，其次每次系统重启时都需要完整回放一遍所有日志才能得到最新的状态机。</p>
<p>因此 Raft 提供了一种机制去清除日志里积累的陈旧信息，叫做<strong>日志压缩</strong>。</p>
<p>快照（Snapshot）是一种常用的、简单的日志压缩方式，ZooKeeper、Chubby 等系统都在用。简单来说，就是将某一时刻<strong>系统的状态 dump 下来并落地存储，这样该时刻之前的所有日志就都可以丢弃了</strong>。 &gt;这里对“压缩”一词不要产生错误理解，并没有办法将状态机快照“解压缩”回日志序列。</p>
<p><img src="/2024/03/10/%E5%88%86%E5%B8%83%E5%BC%8F/raft日志快照.png" width="700"></p>
<p>快照一般包含以下内容：</p>
<ul>
<li><strong>日志的元数据：最后一条被该快照 apply 的日志 term 及 index</strong></li>
<li><strong>状态机：前边全部日志 apply 后最终得到的状态机</strong></li>
</ul>
<p>当 leader 需要给某个 follower 同步一些旧日志，但这些日志已经被 leader 做了快照并删除掉了时，leader 就需要把该快照发送给 follower。</p>
<p>同样，当集群中有新节点加入，或者某个节点宕机太久落后了太多日志时，leader 也可以直接发送快照，大量节约日志传输和回放时间。</p>
<p>同步快照使用一个新的 RPC 方法，叫做 InstallSnapshot RPC。</p>
<p>注意，在 Raft 中只能为 committed 日志做 snapshot，因为只有 committed 日志才是确保最终会应用到状态机的。</p>
<p>另外，生成快照的频率要适中，频率过高会消耗大量 I/O 带宽；频率过低，一旦需要执行恢复操作，会丢失大量数据，影响可用性。</p>
<p>推荐当日志达到某个固定的大小时生成快照。生成一次快照可能耗时过长，影响正常日志同步。可以通过使用 copy-on-write 技术避免快照过程影响正常日志同步。</p>
<h3 id="线性一致性与读性能优化">8.5 线性一致性与读性能优化</h3>
<h4 id="什么是线性一致性">8.5.1 什么是线性一致性？</h4>
<p>在分布式系统中，为了消除单点提高系统可用性，通常会使用副本来进行容错，但这会带来另一个问题，即如何保证多个副本之间的一致性。</p>
<p>什么是一致性？所谓一致性有很多种模型，不同的模型都是用来评判一个并发系统正确与否的不同程度的标准。而现在要讨论的是<strong>强一致性（Strong Consistency）模型，也就是线性一致性（Linearizability）</strong>，经常听到的 CAP 理论中的 C 指的就是它。</p>
<p>前面已经简要描述过何为线性一致性：</p>
<p>所谓的强一致性（线性一致性）并不是指集群中所有节点在任一时刻的状态必须完全一致，而是指一个目标，即让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，这样应用层就可以忽略系统底层多个数据副本间的同步问题。也就是说，可以将一个强一致性分布式系统当成一个整体，一旦某个客户端成功的执行了写操作，那么所有客户端都一定能读出刚刚写入的值。即使发生网络分区故障，或者少部分节点发生异常，整个集群依然能够像单机一样提供服务。</p>
<p>“<strong>像单机一样提供服务</strong>”从感官上描述了一个线性一致性系统应该具备的特性，那么该如何判断一个系统是否具备线性一致性呢？通俗来说就是不能读到旧（stale）数据，但具体分为两种情况：</p>
<ul>
<li>对于调用时间存在重叠（并发）的请求，生效顺序可以任意确定。</li>
<li>对于调用时间存在先后关系（偏序）的请求，后一个请求不能违背前一个请求确定的结果。</li>
</ul>
<p>只要根据上述两条规则即可判断一个系统是否具备线性一致性。</p>
<blockquote>
<p>线性一致性并非限定在分布式环境下，在单机单核系统中可以简单理解为“寄存器”的特性。</p>
</blockquote>
<h4 id="raft-线性一致性读">8.5.2 Raft 线性一致性读</h4>
<p>在了解了什么是线性一致性之后，我们将其与 Raft 结合来探讨。</p>
<p>首先需要明确一个问题，使用了 Raft 的系统都是线性一致的吗？不是的，Raft 只是提供了一个基础，要实现整个系统的线性一致还需要做一些额外的工作。</p>
<p>假设期望基于 Raft 实现一个线性一致的分布式 kv 系统，从最朴素的方案开始，指出每种方案存在的问题，最终使整个系统满足线性一致性。</p>
<h5 id="写主读从缺陷分析">8.5.2.1 写主读从缺陷分析</h5>
<p><strong>写操作并不是我们关注的重点，如果稍微看了一些理论部分就应该知道，所有写操作都要作为提案从 leader 节点发起，当然所有的写命令都应该简单交给 leader 处理</strong>。<strong>真正关键的点在于读操作的处理方式</strong>，这涉及到整个系统关于一致性方面的取舍。</p>
<p><strong>假设读操作直接简单地向 follower 发起，那么由于 Raft 的 Quorum 机制（大部分节点成功即可），针对某个提案在某一时间段内，集群可能会有以下两种状态：</strong></p>
<ul>
<li>某次写操作的日志尚未被复制到一少部分 follower，但 leader 已经将其 commit。</li>
<li>某次写操作的日志已经被同步到所有 follower，但 leader 将其 commit 后，心跳包尚未通知到一部分 follower。</li>
</ul>
<p>以上每个场景客户端都可能读到过时的数据，整个系统显然是不满足线性一致的。</p>
<h5 id="写主读主缺陷分析">8.5.2.2 写主读主缺陷分析</h5>
<blockquote>
<p><strong>那将读操作也必须经由 leader 节点处理，读写都经过 leader 难道还不能满足线性一致？</strong> <strong>是的！！,也还是存在不满足线性一致问题，并且该方案存在不止一个问题！！</strong></p>
</blockquote>
<ul>
<li><p><strong>问题一：状态机落后于 committed log 导致脏读</strong> &gt;回想一下前文讲过的，在解释什么是 commit 时提到了写操作什么时候可以响应客户端： &gt; &gt;所谓 commit 其实就是对日志简单进行一个标记，表明其可以被 apply 到状态机，并针对相应的客户端请求进行响应。 &gt; &gt;也就是说一个提案只要被 leader commit 就可以响应客户端了，Raft 并没有限定提案结果在返回给客户端前必须先应用到状态机。所以从客户端视角当我们的某个写操作执行成功后，下一次读操作可能还是会读到旧值。 &gt; &gt;解决方法：在 leader 收到读命令时只需记录下当前的 commit index，当 apply index 追上该 commit index 时，即可将状态机中的内容响应给客户端。</p></li>
<li><p><strong>问题二：网络分区导致脏读</strong>。假设集群发生网络分区，旧 leader 位于少数派分区中，而且此刻旧 leader 刚好还未发现自己已经失去了领导权，当多数派分区选出了新的 leader 并开始进行后续写操作时，连接到旧 leader 的客户端可能就会读到旧值了。</p></li>
</ul>
<p><strong>因此，仅仅是直接读 leader 状态机的话，系统仍然不满足线性一致性。</strong></p>
<h5 id="raft-log-read">8.5.2.3 Raft Log Read</h5>
<p><strong>为了确保 leader 处理读操作时仍拥有领导权，</strong>可以将读请求同样作为一个提案走一遍 Raft 流程，当这次读请求对应的日志可以被应用到状态机时，leader 就可以读状态机并返回给用户了。</p>
<p>这种读方案称为 <strong>Raft Log Read</strong>，也可以直观叫做 Read as Proposal。</p>
<p>为什么这种方案满足线性一致？</p>
<p>因为该方案根据 commit index 对所有读写请求都一起做了线性化，这样每个读请求都能感知到状态机在执行完前一写请求后的最新状态，将读写日志一条一条的应用到状态机，整个系统当然满足线性一致。但该方案的缺点也非常明显，那就是<strong>性能差</strong>，读操作的开销与写操作几乎完全一致。而且由于所有操作都线性化了，我们无法并发读状态机。</p>
<h4 id="raft-读性能优化">8.5.3 Raft 读性能优化</h4>
<p>接下来将介绍几种优化方案，它们在不违背系统线性一致性的前提下，大幅提升了读性能。</p>
<h5 id="read-index">8.5.3.1 Read Index</h5>
<p>与 Raft Log Read 相比，Read Index 省掉了同步 log 的开销，能够大幅提升读的吞吐，一定程度上降低读的时延。其大致流程为：</p>
<ul>
<li>Leader 在收到客户端读请求时，记录下当前的 commit index，称之为 read index。</li>
<li>Leader 向 followers 发起一次心跳包，这一步是为了确保领导权，避免网络分区时少数派 leader 仍处理请求。</li>
<li>等待状态机至少应用到 read index（即 apply index 大于等于 read index）。</li>
<li>执行读请求，将状态机中的结果返回给客户端。</li>
<li>这里第三步的 apply index 大于等于 read index 是一个关键点。因为在该读请求发起时，我们将当时的 commit index 记录了下来，只要使客户端读到的内容在该 commit index 之后，那么结果一定都满足线性一致）。</li>
</ul>
<h5 id="lease-read">8.5.3.2 Lease Read</h5>
<p>与 Read Index 相比，Lease Read 进一步省去了网络交互开销，因此更能显著降低读的时延。</p>
<p>基本思路是 leader 设置一个比选举超时（Election Timeout）更短的时间作为租期，在租期内我们可以相信其它节点一定没有发起选举，集群也就一定不会存在脑裂，所以在这个时间段内直接读主即可，而非该时间段内可以继续走 Read Index 流程，Read Index 的心跳包也可以为租期带来更新。</p>
<p>Lease Read 可以认为是 Read Index 的时间戳版本，额外依赖时间戳会为算法带来一些不确定性，如果时钟发生漂移会引发一系列问题，因此需要谨慎的进行配置。</p>
<h5 id="follower-read">8.5.3.3 Follower Read</h5>
<p>在前边两种优化方案中，无论怎么折腾，核心思想其实只有两点：</p>
<ul>
<li>保证在读取时的最新 commit index 已经被 apply。</li>
<li>保证在读取时 leader 仍拥有领导权。</li>
</ul>
<p>其实无论是 Read Index 还是 Lease Read，最终目的都是为了解决第二个问题。换句话说，读请求最终一定都是由 leader 来承载的。</p>
<p>那么读 follower 真的就不能满足线性一致吗？其实不然，<strong>这里给出一个可行的读 follower 方案：Follower 在收到客户端的读请求时，向 leader 询问当前最新的 commit index，反正所有日志条目最终一定会被同步到自己身上，follower 只需等待该日志被自己 commit 并 apply 到状态机后，返回给客户端本地状态机的结果即可。这个方案叫做 Follower Read。</strong></p>
<p>注意：Follower Read 并不意味着我们在读过程中完全不依赖 leader 了，在保证线性一致性的前提下完全不依赖 leader 理论上是不可能做到的。</p>
<p>以上就是 Raft 算法的核心内容及工程实践最需要考虑的内容。</p>
<blockquote>
<p>Redis 中哨兵就是用了 RAFT 算法</p>
</blockquote>
<h2 id="问题">问题</h2>
<h3 id="raft的选举流程">raft的选举流程？</h3>
<p>raft的选举流程是这样的，在raft集群这，每个节点都会处于三个状态的其中之一，分别是leader领导者、follower跟随者，已经candidate候选者，一般在正常情况下呢节点的状态只有leader和follower状态。当发送选举之后才会出现candidate状态。</p>
<p>candidate是这样产生的，raft集群中leader与follwer会有心跳机制维护自己的领导地位，但是当follower在一段时间内都没有收到任何心跳，发生选举超时，它会认为系统中没有可用的leader，会发起新的选举，此时这个follower就会先增加自己的term，也叫任期号，切换自己成为candidate,并向其他节点发送一个<code>RequestVote RPC</code>，当这个candidate获得这个集群大多数节点（N/2+1）的投票时，它就赢得了这次选举，立刻将自己的身份转变为 leader 并开始向其它节点发送心跳来维持自己的地位。</p>
<h4 id="选举失败">选举失败？</h4>
<p>选举失败的是指有其他的candidate成为了leader，那么这个新leader就会开始发送心跳包维护自己领导地位，这个新的leader发送的心跳包所携带的 term 不小于当前这个candidate 的 term话，那么 candidate 会承认这个 leader，并将身份切回 follower去跟随这个新leader。</p>
<p>（raft对选举和commit做了限制，能够保证新选举处理的leadr的term一定是最大）</p>
<h4 id="那选举超时就是出现选票瓜分怎么办">那选举超时，就是出现选票瓜分怎么办？</h4>
<p>如果所有的candidate都没有获得半数以上的票，那么谁也无法成为新的leader，此时触发选举超时，此时 candidate 需要增加自己的 term，然后发起新一轮选举。</p>
<blockquote>
<p>但这里存在一个问题，就是一直无法选出leader，这个系统不就没用了吗？ 这是因为选票被瓜分所引起的，导致没有candidate获得半数以上的选票，一般出现在所有candidate同一时间选举就会出现（如集群刚开启）。为了防止这种选票瓜分现象，raft使用了<strong>随机化选举超时时间</strong>的措施处理，把选举分散开。<strong>这样每一个 Candidate 在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。</strong></p>
</blockquote>
<h3 id="raft是怎么保证一致性的">raft是怎么保证一致性的？</h3>
<p>raft保证一致性的措施是通过日志复制实现的，raft规定leader具有<code>strong leader</code>的属性，即leader 从来不会覆盖或者删除自己的日志，而是强制 follower 与它保持一致。</p>
<p>Leader 针对每个 follower 都维护一个 next index，表示下一条需要发送给该follower 的日志索引。当一个 leader 刚刚上任时，它初始化所有 next index 值为自己最后一条日志的 index+1。但凡某个 follower 的日志跟 leader 不一致，那么下次 AppendEntries RPC 的一致性检查就会失败。在被 follower 拒绝这次 Append Entries RPC 后，leader 会减少 next index 的值并进行重试。</p>
<p>最终一定会存在一个 next index 使得 leader 和 follower 在这之前的日志都保持一致。极端情况下 next index 为1，表示 follower 没有任何日志与 leader 一致，leader 必须从第一条日志开始同步。</p>
<p>因此对于raft日志同步来说有如下两点：</p>
<ul>
<li><strong>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则它们所存储的命令是相同的</strong>。这个特性基于这条原则：Raft 要求 leader 在一个 term 内针对同一个 index 只能创建一条日志，并且永远不会修改它。</li>
<li><strong>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则它们之前的所有条目都是完全一样的。</strong></li>
</ul>
<h3 id="raft的安全性怎么保证的">raft的安全性怎么保证的</h3>
<p>raft的安全性通过增加了两条限制做保证，一个是对选举做限制，另一个是对提交做限制：</p>
<ul>
<li><p><strong>对选举的限制</strong>：raft规定只有拥有最新的已提交的日志条目的 Follower 才有资格成为 Leader。具体来说就是RequestVote RPC 中包含了 Candidate 的日志信息， Follower 会拒绝掉那些日志没有自己新的Vote请求。</p></li>
<li><p><strong>对提交的限制</strong>：Leader 只允许 commit 包含当前 term 的日志。</p></li>
</ul>
<h3 id="那对raft集群读能保证每次读到的都是最新的吗">那对raft集群读，能保证每次读到的都是最新的吗?</h3>
<p>不能保证，者取决于raft集群的具体配置。对于读操作，Raft算法本身并没有强制要求必须在Leader节点上执行，或者必须等待最新的写操作被提交后再执行。读操作可以在Follower节点上执行，并且可能不需要等待最新的写操作（适合于读多写少）。</p>
<p>而且即使经过leader节点读，如果没有做强一致性读或者线性一致性读也会读到旧值。<strong>因为leader的commit 其实就是对日志简单进行一个标记，表明其可以被 apply 到状态机，并针对相应的客户端请求进行响应。也就是说一个提案只要被 leader commit 就可以响应客户端了，Raft 并没有限定提案结果在返回给客户端前必须先应用到状态机。所以从客户端视角当我们的某个写操作执行成功后，下一次读操作可能还是会读到旧值。</strong></p>
<p>所有要做到每次读都是最新的就需要做线性一致性读的保证措施(有三种）：</p>
<ul>
<li>Read Index</li>
<li>Lease read</li>
<li>follower read</li>
</ul>
<h3 id="raft中读写操作一定都在leader吗">raft中读写操作一定都在leader吗?</h3>
<p>写一定在leader.读操作依据你设定的方案是经过leader后在从节点读，还是直接在从节点读，也有读写都在leader的，依据你的策略看。</p>
<h3 id="写都在leader那性能会不会有瓶颈怎么解决">写都在leader,那性能会不会有瓶颈，怎么解决？</h3>
<p>如果所有的读写操作都集中在Leader节点上，那么在处理大量请求时，Leader节点确实可能会成为性能瓶颈。为了解决这个问题，可以采用以下几种策略：</p>
<ul>
<li><strong>负载均衡：</strong>通过设置代理层，并使用哈希算法来将请求分发到多个Raft集群，从而实现负载均衡。这样可以避免单一Leader节点过载，提高整体系统的吞吐量。</li>
<li><strong>分片（Sharding）</strong>：将数据划分为多个分片，每个分片由一个Raft集群负责管理。通过将读写请求分散到不同的分片上，可以降低每个节点的负载，提高系统的并行处理能力。</li>
<li><strong>硬件和配置优化</strong>：通过升级硬件、优化系统配置等方式，提高节点的处理能力，从而缓解性能瓶颈</li>
</ul>
<h4 id="怎么分片使数据尽量均匀">怎么分片使数据尽量均匀</h4>
<ul>
<li>范围分片（Range Sharding）：将数据按照某个字段的范围进行分片。例如，如果数据是按时间顺序排列的，那么可以将每个时间段的数据分配到不同的分片中</li>
<li><strong>哈希分片（Hash Sharding）：</strong>使用哈希函数将数据的键（Key）映射到特定的分片上。这种方法通常能够确保数据分布的均匀性，因为哈希函数能够将键空间均匀地映射到分片空间。常见的做法是使用一致性哈希，它能够处理节点增加或减少的情况，而不需要重新分配所有的数据。</li>
</ul>
<p>为了确保数据均匀分布，还需要注意以下几点：</p>
<ul>
<li>监控和调整：定期监控每个分片的负载情况，如果发现某个分片负载过高或过低，可以通过调整分片策略或重新分配数据来平衡负载。</li>
<li>冗余和备份：为了防止节点故障导致数据丢失或不可访问，需要对分片进行冗余备份</li>
</ul>
<h3 id="leader节点一直收不到大部分从节点额心跳回复会怎样">leader节点一直收不到大部分从节点额心跳回复会怎样？</h3>
<p>我认为也会同样触发新的选举。在Raft算法中，如果Leader节点长时间无法收到<strong>大部分（&gt;N/2+1）</strong>Follower节点的心跳回复，Leader节点会怀疑自己的领导地位可能已经丢失，并进入一个称为“选举超时”的状态。</p>
<p>一旦进入选举超时状态，Leader节点会停止接收新的日志条目，并开始一个新的选举过程，试图重新成为Leader或选举一个新的Leader。Leader节点会向集群中的所有节点发送一个投票请求，询问它们是否支持自己成为新的Leader。</p>
<h3 id="一个请求是怎么知道落在分布式哪个服务器上呢">一个请求是怎么知道落在分布式哪个服务器上呢?</h3>
<p>在分布式系统中，一个请求如何知道落在哪个服务器上，这通常取决于系统的架构设计和负载均衡策略。</p>
<ul>
<li><p><strong>静态配置：</strong>在某些情况下，可能通过静态配置的方式指定请求应该发送到哪个服务器。例如，在DNS轮询或硬编码的服务器列表中，客户端或代理可以根据预设的规则选择服务器。</p></li>
<li><p><strong>负载均衡器：</strong>负载均衡器是分布式系统中常用的组件，它负责将请求分发到多个服务器上。负载均衡器可以使用多种算法（如轮询、随机、最少连接数等）来决定将请求发送到哪个服务器。当客户端发送请求时，它首先与负载均衡器通信，然后由负载均衡器决定哪个服务器应该处理该请求。</p></li>
<li><p><strong>一致性哈希</strong>：在某些分布式缓存或存储系统中，会使用一致性哈希来确定数据或请求应该存储或发送到哪个节点。一致性哈希通过哈希函数将键映射到特定的服务器，当服务器数量发生变化时，只需要重新分配一小部分键，从而保持系统的高可用性和可扩展性。</p></li>
<li><p><strong>服务注册与发现</strong>：在微服务架构中，服务注册与发现机制可以帮助客户端找到可用的服务实例。服务提供者将自己的地址注册到服务注册中心，服务消费者从注册中心查询可用的服务实例，并使用负载均衡策略选择一个实例发送请求。</p></li>
<li><p><strong>基于路由的规则</strong>：在某些复杂的分布式系统中，可能会使用基于路由的规则来确定请求的目标服务器。这些规则可以根据请求的特定属性（如URL路径、请求头信息等）来决定如何路由请求</p></li>
</ul>
<h3 id="分布式将业务拆分为多个子业务部署不同的服务器那一个请求要多个服务器协调处理是怎么做的">分布式将业务拆分为多个子业务部署不同的服务器，那一个请求要多个服务器协调处理是怎么做的？</h3>
<ul>
<li><strong>服务拆分与定义：</strong>
<ul>
<li>首先，业务被拆分为多个子业务或服务，每个服务负责处理业务的一部分逻辑。</li>
<li>每个服务都有明确的接口和协议定义，以便其他服务可以与之通信和协作。</li>
</ul></li>
<li><strong>服务注册与发现：</strong>
<ul>
<li>服务提供者将自身的信息（如IP地址、端口号、服务名称等）注册到服务注册中心，如Eureka、Consul或ZooKeeper等。</li>
<li>服务消费者通过服务注册中心查询可用的服务提供者，获取其地址信息。</li>
</ul></li>
<li><strong>负载均衡：</strong>
<ul>
<li>在有多个服务提供者的情况下，负载均衡器（如Nginx、HAProxy等）负责将请求分发到不同的服务提供者上，以确保请求的均衡处理和系统的可扩展性。</li>
</ul></li>
<li><strong>请求路由：</strong>
<ul>
<li><strong>当客户端发起一个需要多个服务协调处理的请求时，通常会有一个入口点或API网关负责接收请求。</strong></li>
<li><strong>API网关根据业务逻辑和路由规则，将请求拆分成多个子请求，并分别发送到相应的服务提供者。</strong></li>
</ul></li>
<li><strong>服务间通信：</strong>
<ul>
<li>服务之间可以通过各种协议进行通信，如HTTP、RPC（如gRPC、Thrift）、消息队列（如Kafka、RabbitMQ）等。</li>
<li>根据具体的业务场景和需求，选择合适的通信协议和方式。</li>
</ul></li>
<li><strong>分布式事务处理：</strong>
<ul>
<li><strong>如果多个服务之间的操作需要保持事务的一致性，可以采用分布式事务处理机制，如基于两阶段提交（2PC）或三阶段提交（3PC）的协议，或使用基于补偿事务（Compensating Transaction）的模式。</strong></li>
<li><strong>也可以利用数据库的事务机制或分布式锁来确保数据的一致性。</strong></li>
</ul></li>
<li><strong>数据同步与一致性：</strong>
<ul>
<li><strong>在分布式系统中，数据的一致性是一个重要问题。可以使用各种一致性协议（如Raft、Paxos）或数据同步机制（如主从复制、多副本一致性）来确保数据在不同服务之间的一致性。</strong></li>
</ul></li>
<li><strong>容错与重试机制：</strong>
<ul>
<li>由于网络延迟、服务故障等原因，请求在处理过程中可能会失败。因此，需要设计容错和重试机制，确保请求能够最终得到处理。</li>
<li>可以使用熔断器模式、降级策略、重试逻辑等来增强系统的健壮性和可用性。</li>
</ul></li>
<li><strong>监控与日志：</strong>
<ul>
<li>为了更好地追踪和调试分布式系统中的问题，需要建立完善的监控和日志系统。</li>
<li>通过收集和分析系统的监控数据和日志信息，可以及时发现和解决问题，优化系统的性能和稳定性。</li>
</ul></li>
</ul>
<p>综上所述，分布式系统中多个服务器协调处理一个请求是一个复杂的过程，<strong>涉及服务拆分、注册与发现、负载均衡、请求路由、服务间通信、分布式事务处理、数据同步与一致性、容错与重试机制以及监控与日志等多个方面</strong>。在实际应用中，需要根据具体的业务需求和系统特点来选择合适的技术和策略来实现这些功能。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="trluper 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="trluper 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag"># 面试</a>
              <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"># 分布式</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/01/20/Trluper%E6%A1%86%E6%9E%B6%E9%9D%A2%E8%AF%95/" rel="prev" title="Trluper框架面试">
      <i class="fa fa-chevron-left"></i> Trluper框架面试
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%92%8C%E9%9B%86%E7%BE%A4%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">1.</span> <span class="nav-text">1. 分布式和集群的区别是什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cap%E5%AE%9A%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">2. CAP定理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#base%E7%90%86%E8%AE%BA"><span class="nav-number">3.</span> <span class="nav-text">3. BASE理论</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="nav-number">3.1.</span> <span class="nav-text">。1核心思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#base-%E7%90%86%E8%AE%BA%E4%B8%89%E8%A6%81%E7%B4%A0"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 BASE 理论三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%8F%AF%E7%94%A8"><span class="nav-number">3.2.1.</span> <span class="nav-text">1.基本可用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BD%AF%E7%8A%B6%E6%80%81"><span class="nav-number">3.2.2.</span> <span class="nav-text">2. 软状态</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">3.2.3.</span> <span class="nav-text">3. 最终一致性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%9A%84%E4%B8%A4%E5%A4%A7%E6%80%9D%E8%B7%AF"><span class="nav-number">4.</span> <span class="nav-text">4. 分布式系统设计的两大思路</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%AD%E5%BF%83%E5%8C%96%E8%AE%BE%E8%AE%A1"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 中心化设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96%E8%AE%BE%E8%AE%A1"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 去中心化设计</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1"><span class="nav-number">5.</span> <span class="nav-text">5. 分布式事务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 分布式事务和分布式锁的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%BA%A7%E7%94%9F%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 分布式事务产生的原因</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 常见的分布式事务解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Exa%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A42pc"><span class="nav-number">5.3.1.</span> <span class="nav-text">5.3.1 基于XA协议的两阶段提交（2PC）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E5%87%86%E5%A4%87%E9%98%B6%E6%AE%B5"><span class="nav-number">5.3.1.1.</span> <span class="nav-text">第一阶段：准备阶段</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E9%98%B6%E6%AE%B5"><span class="nav-number">5.3.1.2.</span> <span class="nav-text">第二阶段：提交阶段</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Exa%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%B8%89%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A43pc"><span class="nav-number">5.3.2.</span> <span class="nav-text">5.3.2 基于XA协议的三阶段提交（3PC）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A1%A5%E5%81%BF%E4%BA%8B%E5%8A%A1tcc"><span class="nav-number">5.3.3.</span> <span class="nav-text">5.3.3 补偿事务（TCC）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%95%E5%85%A5tcc%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-number">5.3.3.1.</span> <span class="nav-text">引入TCC的例子</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%BC%95%E5%85%A5-tcc-%E4%BA%8B%E5%8A%A1"><span class="nav-number">5.3.3.2.</span> <span class="nav-text">系统如何引入 TCC 事务</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF"><span class="nav-number">5.3.4.</span> <span class="nav-text">5.3.4 MQ事务消息</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">6 分布式一致性算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#paxos%E7%AE%97%E6%B3%95"><span class="nav-number">7.</span> <span class="nav-text">7. Paxos算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#raft%E7%AE%97%E6%B3%95"><span class="nav-number">8.</span> <span class="nav-text">8. Raft算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%89%E4%B8%BB"><span class="nav-number">8.1.</span> <span class="nav-text">8.1 选主</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E8%A7%92%E8%89%B2"><span class="nav-number">8.1.1.</span> <span class="nav-text">8.1.1 节点角色</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%BB%E6%9C%9F"><span class="nav-number">8.1.2.</span> <span class="nav-text">8.1.2 任期</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1"><span class="nav-number">8.1.3.</span> <span class="nav-text">8.1.3 节点通信</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2"><span class="nav-number">8.1.4.</span> <span class="nav-text">8.1.4 节点状态转换</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#candidate-%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E8%BF%87%E7%A8%8B"><span class="nav-number">8.1.4.1.</span> <span class="nav-text">8.1.4.2 Candidate 状态转换过程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#leader-%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E8%BF%87%E7%A8%8B"><span class="nav-number">8.1.4.2.</span> <span class="nav-text">8.1.4.3 Leader 状态转换过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6"><span class="nav-number">8.2.</span> <span class="nav-text">8.2 日志复制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F"><span class="nav-number">8.2.1.</span> <span class="nav-text">8.2.1 日志格式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B"><span class="nav-number">8.2.2.</span> <span class="nav-text">8.2.2 日志复制流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E4%B8%80%E8%87%B4%E6%80%A7%E4%BF%9D%E9%9A%9C"><span class="nav-number">8.2.3.</span> <span class="nav-text">8.2.3 日志一致性保障</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%8D%E4%B8%80%E8%87%B4%E5%9C%BA%E6%99%AF"><span class="nav-number">8.2.4.</span> <span class="nav-text">8.2.4 可能出现的日志不一致场景</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9C%BA%E6%99%AFab-follower-%E6%97%A5%E5%BF%97%E8%90%BD%E5%90%8E%E4%BA%8E-leader"><span class="nav-number">8.2.4.1.</span> <span class="nav-text">场景a~b: Follower 日志落后于 leader</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9C%BA%E6%99%AFc.-follower-%E6%97%A5%E5%BF%97%E6%AF%94-leader-%E5%A4%9A-term6"><span class="nav-number">8.2.4.2.</span> <span class="nav-text">场景c. Follower 日志比 leader 多 term6</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9C%BA%E6%99%AFd.-follower-%E6%97%A5%E5%BF%97%E6%AF%94-leader-%E5%A4%9A-term7"><span class="nav-number">8.2.4.3.</span> <span class="nav-text">场景d. Follower 日志比 leader 多 term7</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9C%BA%E6%99%AFe.-follower-%E6%97%A5%E5%BF%97%E6%AF%94-leader-%E5%B0%91-term5-6%E5%A4%9A-term4"><span class="nav-number">8.2.4.4.</span> <span class="nav-text">场景e. Follower 日志比 leader 少 term5 ~ 6，多 term4</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9C%BA%E6%99%AFf.-follower-%E6%97%A5%E5%BF%97%E6%AF%94-leader-%E5%B0%91-term4-6%E5%A4%9A-term2-3"><span class="nav-number">8.2.4.5.</span> <span class="nav-text">场景f. Follower 日志比 leader 少 term4 ~ 6，多 term2 ~ 3</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%97%A5%E5%BF%97%E4%B8%8D%E4%B8%80%E8%87%B4%E7%9A%84%E5%9C%BA%E6%99%AF"><span class="nav-number">8.2.5.</span> <span class="nav-text">8.2.5 如何处理日志不一致的场景</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E5%85%A8%E6%80%A7%E5%8F%8A%E6%AD%A3%E7%A1%AE%E6%80%A7"><span class="nav-number">8.3.</span> <span class="nav-text">8.3 安全性及正确性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E9%80%89%E4%B8%BE%E7%9A%84%E9%99%90%E5%88%B6"><span class="nav-number">8.3.1.</span> <span class="nav-text">8.3.1 对选举的限制</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E5%93%AA%E4%B8%AA%E6%97%A5%E5%BF%97%E6%9D%A1%E7%9B%AE%E6%AF%94%E8%BE%83%E6%96%B0"><span class="nav-number">8.3.1.1.</span> <span class="nav-text">如何判断哪个日志条目比较新？</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E6%8F%90%E4%BA%A4%E7%9A%84%E9%99%90%E5%88%B6"><span class="nav-number">8.3.2.</span> <span class="nav-text">8.3.1 对提交的限制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E4%B8%8E%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9"><span class="nav-number">8.4.</span> <span class="nav-text">8.4 集群成员变更与日志压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4"><span class="nav-number">8.4.1.</span> <span class="nav-text">8.4.1 集群成员变更</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E5%88%87%E6%8D%A2%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E9%85%8D%E7%BD%AE"><span class="nav-number">8.4.1.0.1.</span> <span class="nav-text">8.4.1.1 直接切换集群成员配置</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%88%87%E6%8D%A2%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E9%85%8D%E7%BD%AE"><span class="nav-number">8.4.1.1.</span> <span class="nav-text">8.4.1.2 两阶段切换集群成员配置</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%88%87%E6%8D%A2%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E9%85%8D%E7%BD%AE%E5%8F%AF%E4%BB%A5%E4%BF%9D%E8%AF%81%E4%B8%8D%E4%BC%9A%E5%87%BA%E7%8E%B0%E5%A4%9A%E4%B8%AA-leader"><span class="nav-number">8.4.1.2.</span> <span class="nav-text">8.4.1.3什么两阶段切换集群成员配置可以保证不会出现多个 leader？</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9"><span class="nav-number">8.4.2.</span> <span class="nav-text">8.4.2 日志压缩</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="nav-number">8.5.</span> <span class="nav-text">8.5 线性一致性与读性能优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">8.5.1.</span> <span class="nav-text">8.5.1 什么是线性一致性？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#raft-%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%BB"><span class="nav-number">8.5.2.</span> <span class="nav-text">8.5.2 Raft 线性一致性读</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%99%E4%B8%BB%E8%AF%BB%E4%BB%8E%E7%BC%BA%E9%99%B7%E5%88%86%E6%9E%90"><span class="nav-number">8.5.2.1.</span> <span class="nav-text">8.5.2.1 写主读从缺陷分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%99%E4%B8%BB%E8%AF%BB%E4%B8%BB%E7%BC%BA%E9%99%B7%E5%88%86%E6%9E%90"><span class="nav-number">8.5.2.2.</span> <span class="nav-text">8.5.2.2 写主读主缺陷分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#raft-log-read"><span class="nav-number">8.5.2.3.</span> <span class="nav-text">8.5.2.3 Raft Log Read</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#raft-%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="nav-number">8.5.3.</span> <span class="nav-text">8.5.3 Raft 读性能优化</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#read-index"><span class="nav-number">8.5.3.1.</span> <span class="nav-text">8.5.3.1 Read Index</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#lease-read"><span class="nav-number">8.5.3.2.</span> <span class="nav-text">8.5.3.2 Lease Read</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#follower-read"><span class="nav-number">8.5.3.3.</span> <span class="nav-text">8.5.3.3 Follower Read</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98"><span class="nav-number">9.</span> <span class="nav-text">问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#raft%E7%9A%84%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B"><span class="nav-number">9.1.</span> <span class="nav-text">raft的选举流程？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%89%E4%B8%BE%E5%A4%B1%E8%B4%A5"><span class="nav-number">9.1.1.</span> <span class="nav-text">选举失败？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%82%A3%E9%80%89%E4%B8%BE%E8%B6%85%E6%97%B6%E5%B0%B1%E6%98%AF%E5%87%BA%E7%8E%B0%E9%80%89%E7%A5%A8%E7%93%9C%E5%88%86%E6%80%8E%E4%B9%88%E5%8A%9E"><span class="nav-number">9.1.2.</span> <span class="nav-text">那选举超时，就是出现选票瓜分怎么办？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#raft%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84"><span class="nav-number">9.2.</span> <span class="nav-text">raft是怎么保证一致性的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#raft%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E7%9A%84"><span class="nav-number">9.3.</span> <span class="nav-text">raft的安全性怎么保证的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%82%A3%E5%AF%B9raft%E9%9B%86%E7%BE%A4%E8%AF%BB%E8%83%BD%E4%BF%9D%E8%AF%81%E6%AF%8F%E6%AC%A1%E8%AF%BB%E5%88%B0%E7%9A%84%E9%83%BD%E6%98%AF%E6%9C%80%E6%96%B0%E7%9A%84%E5%90%97"><span class="nav-number">9.4.</span> <span class="nav-text">那对raft集群读，能保证每次读到的都是最新的吗?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#raft%E4%B8%AD%E8%AF%BB%E5%86%99%E6%93%8D%E4%BD%9C%E4%B8%80%E5%AE%9A%E9%83%BD%E5%9C%A8leader%E5%90%97"><span class="nav-number">9.5.</span> <span class="nav-text">raft中读写操作一定都在leader吗?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E9%83%BD%E5%9C%A8leader%E9%82%A3%E6%80%A7%E8%83%BD%E4%BC%9A%E4%B8%8D%E4%BC%9A%E6%9C%89%E7%93%B6%E9%A2%88%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3"><span class="nav-number">9.6.</span> <span class="nav-text">写都在leader,那性能会不会有瓶颈，怎么解决？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%8E%E4%B9%88%E5%88%86%E7%89%87%E4%BD%BF%E6%95%B0%E6%8D%AE%E5%B0%BD%E9%87%8F%E5%9D%87%E5%8C%80"><span class="nav-number">9.6.1.</span> <span class="nav-text">怎么分片使数据尽量均匀</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#leader%E8%8A%82%E7%82%B9%E4%B8%80%E7%9B%B4%E6%94%B6%E4%B8%8D%E5%88%B0%E5%A4%A7%E9%83%A8%E5%88%86%E4%BB%8E%E8%8A%82%E7%82%B9%E9%A2%9D%E5%BF%83%E8%B7%B3%E5%9B%9E%E5%A4%8D%E4%BC%9A%E6%80%8E%E6%A0%B7"><span class="nav-number">9.7.</span> <span class="nav-text">leader节点一直收不到大部分从节点额心跳回复会怎样？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E8%AF%B7%E6%B1%82%E6%98%AF%E6%80%8E%E4%B9%88%E7%9F%A5%E9%81%93%E8%90%BD%E5%9C%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%93%AA%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%91%A2"><span class="nav-number">9.8.</span> <span class="nav-text">一个请求是怎么知道落在分布式哪个服务器上呢?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%B0%86%E4%B8%9A%E5%8A%A1%E6%8B%86%E5%88%86%E4%B8%BA%E5%A4%9A%E4%B8%AA%E5%AD%90%E4%B8%9A%E5%8A%A1%E9%83%A8%E7%BD%B2%E4%B8%8D%E5%90%8C%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%82%A3%E4%B8%80%E4%B8%AA%E8%AF%B7%E6%B1%82%E8%A6%81%E5%A4%9A%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8D%8F%E8%B0%83%E5%A4%84%E7%90%86%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E7%9A%84"><span class="nav-number">9.9.</span> <span class="nav-text">分布式将业务拆分为多个子业务部署不同的服务器，那一个请求要多个服务器协调处理是怎么做的？</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="trluper"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">trluper</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">77</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/trluper" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;trluper" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Trluper</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">1.3m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">19:11</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<!-- LOCAL: You can save these files to your site and update links -->
  
  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<!-- END LOCAL -->
 
    
      <script type="text/javascript">
      function renderGitalk(){
        var gitalk = new Gitalk({
            owner: '',
            repo: '',
            clientID: '123fe329fdbb06b0f1d1',
            clientSecret: '40add829107b6e69f43274d3545ae71c988de8eb',
            admin: '',
            
            });
        gitalk.render('gitalk-container');
      }
      renderGitalk();
      </script>
    
 


<script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>