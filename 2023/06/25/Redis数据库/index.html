<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo_1.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo_1.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo_1.png">
  <link rel="mask-icon" href="/images/logo_1.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-pace-theme-center-circle.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"buttons","active":"valine","storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1. Redis数据类型 Redis提供了String,Hash,List,Set,Zset五种数据类型。 1.1 String String数据结构是最简单的key-value类型，value不仅可以是String,也可以是数字，包括整数，浮点数和二进制数。 string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis数据库">
<meta property="og:url" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/index.html">
<meta property="og:site_name" content="Trluper">
<meta property="og:description" content="1. Redis数据类型 Redis提供了String,Hash,List,Set,Zset五种数据类型。 1.1 String String数据结构是最简单的key-value类型，value不仅可以是String,也可以是数字，包括整数，浮点数和二进制数。 string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis事件处理器.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis一次通行过程.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis多线程实现机制.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis多线程实现流程.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis过期时间实现原理.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RDB.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RDB03.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/saveparams.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/缓存雪崩解决方案.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/加入布隆过滤器后的缓存处理流程.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/question.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/Redis与MySQL双写一致性保证.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/先写数据库再写缓存.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/cacheAside.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/special.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/binlog.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/单机锁和分布式锁.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RedLock.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/加锁节点宕机.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RedLock锁流程.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/使用Fencing解决锁不安全问题.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/master-slave.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/主从复制核心原理.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/哨兵监控原理.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/哨兵监控.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/Sentinel.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/哨兵和从节点建立联系.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/异步复制导致的数据丢失.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/槽分配.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/集中式.png">
<meta property="og:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis集群内节点通信.png">
<meta property="article:published_time" content="2023-06-25T08:16:51.000Z">
<meta property="article:modified_time" content="2023-07-12T10:10:50.232Z">
<meta property="article:author" content="trluper">
<meta property="article:tag" content="面试">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis事件处理器.png">

<link rel="canonical" href="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Redis数据库 | Trluper</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Trluper</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/trluper" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://example.com/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="trluper">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Trluper">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Redis数据库
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-25 16:16:51" itemprop="dateCreated datePublished" datetime="2023-06-25T16:16:51+08:00">2023-06-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-07-12 18:10:50" itemprop="dateModified" datetime="2023-07-12T18:10:50+08:00">2023-07-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/%E9%9D%A2%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">面试</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>43k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>39 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="redis数据类型">1. Redis数据类型</h2>
<p>Redis提供了<code>String,Hash,List,Set,Zset</code>五种数据类型。</p>
<h3 id="string">1.1 String</h3>
<p><code>String</code>数据结构是最简单的<code>key-value</code>类型，<code>value</code>不仅可以是<code>String</code>,也可以是数字，包括整数，浮点数和二进制数。</p>
<p><code>string</code> 数据结构是简单的 <code>key-value</code> 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串（simple dynamic string，SDS）</strong>。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。</p>
<p>主要的应用有：缓存，计数（比如用户的访问次数、热点文章的点赞转发数量等等），共享session和限速。</p>
<span id="more"></span>
<p>内部编码主要有：</p>
<ul>
<li><strong><code>int</code></strong>:8个字节的长整型</li>
<li><strong><code>embstr</code></strong>:小于等于39个字节的字符串</li>
<li><strong><code>raw</code></strong>:大于39个字节的字符串</li>
</ul>
<p>各个指令的时间复杂度</p>
<ul>
<li><strong><code>SET</code></strong>：为一个 key 设置 value，可以配合 EX/PX 参数指定 key 的有效期，通过 NX/XX 参数针对 key 是否存在的情况进行区别操作，时间复杂度 O(1)</li>
<li><strong><code>GET</code></strong>：获取某个 key 对应的 value，时间复杂度 O(1)</li>
<li><strong><code>GETSET</code></strong>：为一个 key 设置 value，并返回该 key 的原 value，时间复杂度 O(1)</li>
<li><strong><code>MSET</code></strong>：为多个 key 设置 value，时间复杂度 O(N)</li>
<li><strong><code>MSETNX</code></strong>：同 MSET，如果指定的 key 中有任意一个已存在，则不进行任何操作，时间复杂度 O(N)</li>
<li><strong><code>MGET</code></strong>：获取多个 key 对应的 value，时间复杂度 O(N)</li>
<li><strong><code>INCR</code></strong>：将 key 对应的 value 值自增1，并返回自增后的值。只对可以转换为整型的 String 数据起作用。时间复杂度 O(1)</li>
<li><strong><code>INCRBY</code></strong>：将 key 对应的 value 值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的 String 数据起作用。时间复杂度 O(1)</li>
<li><strong><code>DECR/DECRBY</code></strong>：同 INCR/INCRBY，自增改为自减。</li>
</ul>
<h3 id="hash">1.2 Hash</h3>
<p><code>Hash</code>是一个<code>string</code>类型的<code>field</code>和<code>value</code>的映射表，hash特别适合用于存储对象，后续操作的时候，可以直接仅仅修改这个对象某个字段的值。比如可以用hash数据结构来存储用户信息，商品信息等。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">key = JavaUser</span><br><span class="line">value = &#123;</span><br><span class="line">    <span class="string">&quot;id&quot;</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;name&quot;</span>:<span class="string">&quot;xiaoming&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age&quot;</span>: <span class="number">22</span>,</span><br><span class="line">    <span class="string">&quot;location&quot;</span>: <span class="string">&quot;GuangDong,Jieyang&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>主要应用有：将关系型数据库每一行数据存储为一个哈希键</p>
<p><strong>内部编码主要：</strong></p>
<ul>
<li><code>ziplist(压缩列表)</code>：当哈希类型元素个数小于<code>hash-max-ziplist-entries</code>配置（默认512个字节），同时所有值小于<code>hash-max-ziplist-value</code>配置（默认64个字节）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀</li>
<li><code>hashtable(哈希表)</code>：当哈希类型无法满足ziplist的条件时，使用hashtable作为内部实现，因为此时ziplist读写效率会下降，而hashtable读写时间复杂度为O(1)</li>
</ul>
<h4 id="各个指令的时间复杂度">1.2.1 各个指令的时间复杂度</h4>
<p>与 Hash 相关的常用命令：</p>
<ul>
<li><strong>HSET</strong>：将 key 对应的 Hash 中的 field 设置为 value。如果该 Hash 不存在，会自动创建一个。时间复杂度 O(1)</li>
<li>***：返回指定 Hash 中 field 字段的值，时间复杂度 O(1)</li>
<li>HMSET/HMGET：同 HSET 和 HGET，可以批量操作同一个 key 下的多个 field，时间复杂度：O(N)，N为一次操作的 field 数量</li>
<li>HSETNX：同 HSET，但如 field 已经存在，HSETNX 不会进行任何操作，时间复杂度 O(1)</li>
<li>HEXISTS：判断指定Hash中 field 是否存在，存在返回1，不存在返回0，时间复杂度 O(1)</li>
<li>HDEL：删除指定 Hash 中的 field（1个或多个），时间复杂度：O(N)，N 为操作的 field 数量</li>
<li>HINCRBY：同 INCRBY 命令，对指定 Hash 中的一个 field 进行 INCRBY，时间复杂度 O(1)</li>
</ul>
<p><strong>应谨慎使用的Hash相关命令：</strong></p>
<ul>
<li>HGETALL：返回指定 Hash 中所有的 field-value 对。返回结果为数组，数组中 field 和 value 交替出现。时间复杂度 O(N)</li>
<li>HKEYS/HVALS：返回指定 Hash 中所有的 field/value，时间复杂度 O(N)</li>
<li>上述三个命令都会对 Hash 进行完整遍历，Hash中的 field 数量与命令的耗时线性相关，对于尺寸不可预知的 Hash，应严格避免使用上面三个命令，而改为使用 HSCAN 命令进行游标式的遍历</li>
</ul>
<h3 id="list">1.3 List</h3>
<p><code>list</code>就是链表，Redis中list的应用场景非常多，也是Redis最重要的数据结构之一</p>
<p><strong><code>list</code>的实现是一个双向链表，既可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</strong></p>
<p>另外可以通过<code>lrange</code>，就是从某个元素开始读取多少个元素，可以基于<code>list</code>实现分页查询，基于 redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。</p>
<p>主要的应用有：<strong>栈、队列，消息队列（抢购），文章列表等</strong></p>
<p><strong>内部编码有：</strong></p>
<ul>
<li><strong><code>ziplist(压缩列表)</code>：</strong>当哈希类型元素个数小于<code>list-max-ziplist-entries</code>配置（默认512），同时所有值小于<code>list-max-ziplist-value</code>配置（默认64）时，使用<code>ziplist作</code>为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀</li>
<li><strong><code>linkedlist</code>(链表)</strong>：当列表类型无法满足<code>ziplist</code>条件时，使用链表作为内部实现</li>
</ul>
<h4 id="各个指令的时间复杂度-1">1.3.1 各个指令的时间复杂度</h4>
<ul>
<li><strong><code>LPUSH</code></strong>：向指定<code>List</code>的左侧（即头部）插入 1 个或多个元素，返回插入后的<code>List</code> 长度。时间复杂度<code>O(N)</code>，<code>N</code>为插入元素的数量</li>
<li><strong><code>RPUSH</code>：</strong>同 <code>LPUSH</code>，向指定<code>List</code>的右侧（即尾部）插入 1 或多个元素</li>
<li><strong><code>LPOP</code>：</strong>从指定<code>List</code>的左侧（即头部）移除一个元素并返回，时间复杂度 O(1)</li>
<li><strong><code>RPOP</code>：</strong>同 <code>LPOP</code>，从指定 <code>List</code> 的右侧（即尾部）移除 1 个元素并返回</li>
<li><strong><code>LPUSHX/RPUSHX</code></strong>：与 <code>LPUSH/RPUSH</code> 类似，区别在于，<code>LPUSHX/RPUSHX</code> 操作的 <code>key</code> 如果不存在，则不会进行任何操作</li>
<li><strong><code>LLEN</code></strong>：返回指定<code>List</code>的长度，时间复杂度 O(1)</li>
<li><strong><code>LRANGE</code></strong>：返回指定 <code>List</code> 中指定范围的元素（双端包含，即 <code>LRANGE key 0 10</code>会返回 <code>11</code> 个元素），时间复杂度 O(N)。应尽可能控制一次获取的元素数量，一次获取过大范围的 <code>List</code> 元素会导致延迟，同时对长度不可预知的<code>List</code>，避免使用 <code>LRANGE key 0 -1</code>这样的完整遍历操作。</li>
</ul>
<p>应谨慎使用的List相关命令：</p>
<ul>
<li><strong><code>LINDEX</code></strong>：返回指定<code>List</code>指定 <code>index</code> 上的元素，如果<code>index</code> 越界，返回<code>nil</code>。<code>index</code>数值是回环的，即 <code>-1</code>代表 <code>List</code> 最后一个位置，<code>-2</code>代表<code>List</code>倒数第二个位置。时间复杂度 O(N)</li>
<li><strong><code>LSET</code></strong>：将指定 <code>List</code>指定 <code>index</code> 上的元素设置为 <code>value</code>，如果 <code>index</code> 越界则返回错误，时间复杂度 <code>O(N)</code>，如果操作的是头/尾部的元素，则时间复杂度为<code>O(1)</code></li>
<li><strong><code>LINSERT</code></strong>：向指定 <code>List</code> 中指定元素之前/之后插入一个新元素，并返回操作后的 <code>List</code> 长度。如果指定的元素不存在，返回<code>-1</code>。如果指定<code>key</code> 不存在，不会进行任何操作，时间复杂度 <code>O(N)</code></li>
</ul>
<p><strong>由于<code>Redis</code> 的 List 是链表结构的，上述的三个命令的算法效率较低，需要对 <code>List</code>进行遍历，命令的耗时无法预估，在<code>List</code>长度大的情况下耗时会明显增加，应谨慎使用。</strong></p>
<h3 id="set">1.4 Set</h3>
<p>集合（set）可以保存多个字符串元素，但是不允许有重复元素，并且集合中的元素是无序的，一个集合最多可以存储2^32-1个元素，集合可以进行内部的增删改查和多个集合取交集，并集，差集。</p>
<p>主要的应用有：<strong>标签，生成随机数（抽奖），社交需求（共同好友，粉丝等等）</strong></p>
<p><strong>内部编码主要有：</strong></p>
<ul>
<li>** intset(整数集合)**：当集合中的元素都是整数而且元素个数小于set-max-intset-entries配置（默认512个）时，使用该编码减少内存的使用</li>
<li><strong>hashtable(哈希表)</strong>：其它条件下使用哈希表作为内部实现</li>
</ul>
<h4 id="各个指令的时间复杂度-2">1.4.1 各个指令的时间复杂度</h4>
<ul>
<li><strong>SADD</strong>：向指定 Set 中添加 1 个或多个 member，如果指定 Set 不存在，会自动创建一个。时间复杂度 O(N)，N 为添加的 member 个数</li>
<li><strong>SREM</strong>：从指定 Set 中移除 1 个或多个 member，时间复杂度 O(N)，N 为移除的 member 个数</li>
<li><strong>SRANDMEMBER</strong>：从指定 Set 中随机返回 1 个或多个 member，时间复杂度 O(N)，N 为返回的 member 个数</li>
<li><strong>SPOP：</strong>从指定 Set 中随机移除并返回 count 个 member，时间复杂度 O(N)，N 为移除的 member 个数</li>
<li><strong>SCARD</strong>：返回指定 Set 中的 member 个数，时间复杂度 O(1)</li>
<li><strong>SISMEMBER</strong>：判断指定的 value 是否存在于指定 Set 中，时间复杂度 O(1)</li>
<li><strong>SMOVE</strong>：将指定 member 从一个 Set 移至另一个 Set</li>
</ul>
<p>慎用的Set相关命令：</p>
<ul>
<li><strong>SMEMBERS</strong>：返回指定 Hash 中所有的 member，时间复杂度 O(N)</li>
<li><strong>SUNION/SUNIONSTORE：</strong>计算多个 Set 的并集并返回/存储至另一个 Set 中，时间复杂度 O(N)，N 为参与计算的所有集合的总 member 数</li>
<li><strong>SINTER/SINTERSTORE</strong>：计算多个 Set 的交集并返回/存储至另一个 Set 中，时间复杂度 O(N)，N 为参与计算的所有集合的总 member 数</li>
<li><strong>SDIFF/SDIFFSTORE：</strong>计算 1 个 Set 与 1 或多个 Set 的差集并返回/存储至另一个 Set 中，时间复杂度 O(N)，N 为参与计算的所有集合的总 member 数</li>
</ul>
<p>上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的 Set 尺寸不可知的情况下，应严格避免使用。可以考虑通过 SSCAN 命令遍历获取相关 Set 的全部 member，如果需要做并集/交集/差集计算，可以在客户端进行，或在不服务实时查询请求的 Slave 上进行</p>
<h3 id="zset">1.5 ZSet</h3>
<p>有序集合（zset）保留集合元素不能重复的特性，但是有序集合中的元素可以排序，它为每一个元素设定一个score作为排序的依据</p>
<p>应用：<strong>排行榜系统，用户点赞。需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。</strong></p>
<p><strong>内部编码实现：</strong></p>
<ul>
<li><strong>ziplist(压缩列表)</strong>：当哈希类型元素个数小于zset-max-ziplist-entries配置（默认128个），同时所有值小于zset-max-ziplist-value配置（默认64）时，使用ziplist作为内部实现，ziplist使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀。</li>
<li><strong>skiplist(跳表)：</strong>当ziplist条件不满足时，有序集合会使用skiplist作为内部实现，因为此时ziplist的读写效率会下降</li>
</ul>
<h4 id="各个指令的时间复杂度-3">1.5.1 各个指令的时间复杂度</h4>
<ul>
<li><strong>ZADD</strong>：向指定 Sorted Set 中添加 1 个或多个 member，时间复杂度 O(Mlog(N))，M 为添加的 member 数量，N 为 Sorted Set 中的 member 数量</li>
<li><strong>ZREM</strong>：从指定 Sorted Set 中删除 1 个或多个 member，时间复杂度 O(Mlog(N))，M 为删除的 member 数量，N 为 Sorted Set 中的 member 数量</li>
<li><strong>ZCOUNT</strong>：返回指定 Sorted Set 中指定 score 范围内的 member 数量，时间复杂度：O(log(N))</li>
<li><strong>ZCARD</strong>：返回指定 Sorted Set 中的 member 数量，时间复杂度 O(1)</li>
<li><strong>ZSCORE</strong>：返回指定 Sorted Set 中指定 member 的 score，时间复杂度 O(1)</li>
<li><strong>ZRANK/ZREVRANK</strong>：返回指定 member 在 Sorted Set 中的排名，ZRANK 返回按升序排序的排名，ZREVRANK 则返回按降序排序的排名。时间复杂度 O(log(N))</li>
<li><strong>ZINCRBY</strong>：同 INCRBY，对指定 Sorted Set 中的指定 member 的 score 进行自增，时间复杂度 O(log(N))</li>
</ul>
<p><strong>慎用的Sorted Set相关命令：</strong></p>
<ul>
<li><strong>ZRANGE/ZREVRANGE：</strong>返回指定 Sorted Set 中指定排名范围内的所有 member，ZRANGE 为按 score 升序排序，ZREVRANGE 为按 score 降序排序，时间复杂度 O(log(N)+M)，M为本次返回的 member 数</li>
<li><strong>ZRANGEBYSCORE/ZREVRANGEBYSCORE</strong>：返回指定 Sorted Set 中指定 score 范围内的所有 member，返回结果以升序/降序排序，min 和 max 可以指定为 -inf和+ inf，代表返回所有的 member。时间复杂度 O(log(N)+M)</li>
<li><strong>ZREMRANGEBYRANK/ZREMRANGEBYSCORE</strong>：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有 member。时间复杂度 O(log(N)+M)</li>
</ul>
<p>上述几个命令，应尽量避免传递<code>[0 -1]</code>或<code>[-inf +inf]</code>这样的参数，来对 Sorted Set 做一次性的完整遍历，特别是在 Sorted Set 的尺寸不可预知的情况下。可以通过 ZSCAN 命令来进行游标式的遍历，或通过 LIMIT 参数来限制返回 member 的数量（适用于 ZRANGEBYSCORE 和 ZREVRANGEBYSCORE 命令），以实现游标式的遍历。</p>
<h2 id="为什么要用redis为什么要用缓存">2. 为什么要用redis/为什么要用缓存</h2>
<p>主要从“高性能”和“高并发”这两个点来看待这个问题</p>
<p><strong>高性能：</strong></p>
<p>Redis中的数据是存储在内存中的，所以读写速度非常快。假如用户第一次访问数据库中的某些数据，这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变之后，同步改变缓存中相应的数据即可。</p>
<p><strong>高并发：</strong></p>
<p>一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。</p>
<blockquote>
<p>QPS（Query Per Second）：服务器每秒可以执行的查询次数；</p>
</blockquote>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库</p>
<blockquote>
<p><strong>使用Redis的好处有哪些？</strong> 1、访问速度快，因为数据存在内存中，类似于Java中的HashMap或者C++中的哈希表（如unordered_map/unordered_set），这两者的优势就是查找和操作的时间复杂度都是O(1)</p>
</blockquote>
<blockquote>
<p>2、数据类型丰富，支持String，list，set，sorted set，hash这五种数据结构</p>
</blockquote>
<blockquote>
<p>3、支持事务，Redis中的操作都是原子性，换句话说就是对数据的更改要么全部执行，要么全部不执行，这就是原子性的定义</p>
</blockquote>
<blockquote>
<p>4、特性丰富：Redis可用于缓存，消息，按key设置过期时间，过期后将会自动删除。</p>
</blockquote>
<h2 id="redis的数据怎么存储在内存中内存这么有限怎么存储的">3. Redis的数据怎么存储在内存中（内存这么有限，怎么存储的）</h2>
<h2 id="为什么使用redis而不直接在程序中使用map做缓存">4. 为什么使用redis而不直接在程序中使用map做缓存？</h2>
<p>缓存分为本地缓存和分布式缓存，使用语言自带得map实现的是本地缓存，最主要得特点是轻量以及快速，生命周期随着该实例的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>
<p>使用redis或memcached之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持redis或memcached服务的高可用，整个程序架构上较为复杂。</p>
<h2 id="redis的线程模型">5. redis的线程模型</h2>
<p><strong>Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型 </strong>。redis内部使用文件事件处理器file event handler,这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。</p>
<p>它采用IO多路复用机制同时监听多个socket，它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。根据socket上的事件来选择对应的事件处理器进行处理。</p>
<p>这样的好处非常明显： I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。</p>
<p>另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件：</p>
<ul>
<li>文件事件;</li>
<li>时间事件。</li>
</ul>
<p>时间事件不需要多花时间了解，我们接触最多的还是 文件事件（客户端进行读取写入等操作，涉及一系列网络通信）。</p>
<p>《Redis 设计与实现》有一段话是如是介绍文件事件的： &gt;Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event &gt;handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。</p>
<blockquote>
<p>当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。</p>
</blockquote>
<blockquote>
<p><strong>虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。</strong></p>
</blockquote>
<p>文件事件处理器的结构包含4各部分：</p>
<ul>
<li>多个socket</li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器（连接应答处理器，命令请求处理器、命令回复处理器）</li>
</ul>
<p>多个socket可能会并发产生不同的操作，每个操作对应不同的文件事件，但是IO多路服用程序会监听多个socket，会将socket产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis事件处理器.png" width="700"></p>
<p>客户端与redis的一次通信过程如下： <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis一次通行过程.png" width="800"></p>
<p>客户端<code>socket01</code>向<code>redis</code>的<code>server socket</code>请求建立连接，此时<code>server socket</code>会产生一个<code>AE_READBLE</code>事件，IO多路复用程序监听到<code>server socket</code>产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的<code>socket01</code>,并将该<code>socket01</code>的<code>AE_READBLE</code>事件与命令请求处理器相关联。</p>
<p>假设此时客户端发送了一个<code>set key value</code>请求，此时<code>redis</code>的<code>socket01</code>会产生<code>AE_READABLE</code>事件，IO多路复用程序将事件压入队列，此时事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取<code>socket01</code>中的<code>key value</code>并在自己内存中完成<code>key value</code>的设置。操作完成后，它会将<code>socket01</code>的<code>AE_WRITABLE</code>事件与命令回复处理器相关联。</p>
<p>如果此时客户端准备好接收返回结果了，那么redis中的<code>socket01</code>会产生一个<code>AE_WRITABLE</code>事件，同样压入队列中，事件分派器找到相关联的的命令回复处理器，由命令回复处理器对<code>socket01</code>输入本次操作的一个结果，比如ok，之后解除<code>socket01</code>的<code>AE_WRITABLE</code>事件与命令回复处理器的关联。</p>
<p>这就完成了一次通信。</p>
<blockquote>
<p><strong>单线程的Redis为什么这么快？</strong> 主要是有三个原因： 1、Redis的全部操作都是纯内存的操作； 2、Redis采用单线程，有效避免了频繁的上下文切换； 3、采用了非阻塞I/O多路复用机制。</p>
</blockquote>
<h2 id="redis-使用单线程的原因">6. Redis 使用单线程的原因</h2>
<p>Redis 从一开始就选择使用单线程模型处理来自客户端的绝大多数网络请求，这种考虑其实是多方面的，其中最重要的几个原因如下：</p>
<ul>
<li>使用单线程模型能带来更好的可维护性，方便开发和调试；</li>
<li>使用单线程模型也能并发的处理客户端的请求；</li>
<li><strong>Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPU；</strong></li>
</ul>
<p>上述三个原因中的最后一个是最终使用单线程模型的决定性因素，其他的两个原因都是使用单线程模型额外带来的好处，在这里按顺序介绍上述的几个原因。</p>
<h3 id="可维护性">6.1 可维护性</h3>
<p>可维护性对于一个项目来说非常重要，如果代码难以调试和测试，问题也经常难以复现，这对于任何一个项目来说都会严重地影响项目的可维护性。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，代码的执行过程不再是串行的，多个线程同时访问的变量如果没有谨慎处理就会带来诡异的问题。</p>
<p>如果计算机中的两个进程（线程同理）同时尝试修改一个共享内存的内容，在没有并发控制的情况下，最终的结果依赖于两个进程的执行顺序和时机，如果发生了并发访问冲突，最后的结果就会是不正确的。</p>
<p>引入了多线程，就必须要同时引入并发控制来保证在多个线程同时访问数据时程序行为的正确性，这就需要工程师额外维护并发控制的相关代码，例如，会需要在可能被并发读写的变量上增加互斥锁。</p>
<p>在访问这些变量或者内存之前也需要先对获取互斥锁，一旦忘记获取锁或者忘记释放锁就可能会导致各种诡异的问题，管理相关的并发控制机制也需要付出额外的研发成本和负担。</p>
<h3 id="并发处理">6.2 并发处理</h3>
<p><strong>使用单线程模型也并不意味着程序不能并发的处理任务，Redis 虽然使用单线程模型处理用户的请求，但是它却使用 I/O 多路复用机制并发处理来自客户端的多个连接，同时等待多个连接发送的请求。</strong></p>
<p>在 I/O 多路复用模型中，最重要的函数调用就是 select 以及类似函数，该方法的能够同时监控多个文件描述符（也就是客户端的连接）的可读可写情况，当其中的某些文件描述符可读或者可写时，select 方法就会返回可读以及可写的文件描述符个数。</p>
<p>使用 I/O 多路复用技术能够极大地减少系统的开销，系统不再需要额外创建和维护进程和线程来监听来自客户端的大量连接，减少了服务器的开发成本和维护成本。</p>
<h3 id="性能瓶颈">6.3 性能瓶颈</h3>
<p>这个就是 Redis 选择单线程模型的决定性原因 —— 多线程技术能够帮助我们充分利用 CPU 的计算资源来并发的执行不同的任务，但是 CPU 资源往往都不是 Redis 服务器的性能瓶颈。哪怕在一个普通的 Linux 服务器上启动 Redis 服务，它也能在 1s 的时间内处理 1,000,000 个用户请求。</p>
<p>如果这种吞吐量不能满足我们的需求，更推荐的做法是使用分片的方式将不同的请求交给不同的 Redis 服务器来处理，而不是在同一个 Redis 服务中引入大量的多线程操作。</p>
<p>简单总结一下，Redis 并不是 CPU 密集型的服务，如果不开启 AOF 备份，所有 Redis 的操作都会在内存中完成不会涉及任何的 I/O 操作，这些数据的读写由于只发生在内存中，所以处理速度是非常快的；<strong>整个服务的瓶颈在于网络传输带来的延迟和等待客户端的数据传输，也就是网络 I/O，所以使用多线程模型处理全部的外部请求可能不是一个好的方案。</strong></p>
<p>多线程虽然会更充分地利用 CPU 资源，但是操作系统上线程的切换也不是免费的，线程切换其实会带来额外的开销，其中包括：</p>
<ul>
<li>保存线程 1 的执行上下文；</li>
<li>加载线程 2 的执行上下文；</li>
</ul>
<p>频繁的对线程的上下文进行切换可能还会导致性能地急剧下降，这可能会导致不仅没有提升请求处理的平均速度，反而进行了负优化，所以这也是为什么 Redis 对于使用多线程技术非常谨慎。</p>
<p>##7. Redis 多线程 ### 7.1 Redis 4.0 虽然说 <code>Redis</code> 是单线程模型，但是， 实际上，<code>Redis</code> 在 4.0 之后的版本中就已经加入了对多线程的支持。</p>
<p>不过，<strong><code>Redis 4.0</code> 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。</strong></p>
<p>Redis 在最新的几个版本中加入了一些可以被其他线程异步处理的删除操作，例如 <code>UNLINK、FLUSHALL ASYNC、FLUSHDB ASYNC</code>等非阻塞的删除操作。为什么会需要这些删除操作，而它们为什么需要通过多线程的方式异步处理？</p>
<h4 id="删除操作多线程的原因">7.1.1 删除操作多线程的原因</h4>
<p>可以在 Redis 在中使用 <code>DEL</code> 命令来删除一个键对应的值，如果待删除的键值对占用了较小的内存空间，那么哪怕是同步地删除这些键值对也不会消耗太多的时间。</p>
<p>但<strong>是对于 Redis 中的一些超大键值对，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，Redis 可能会需要在释放内存空间上消耗较多的时间，这些操作就会阻塞待处理的任务，影响 Redis 服务处理请求的 PCT99 和可用性。</strong></p>
<p><strong>然而释放内存空间的工作其实可以由后台线程异步进行处理，这也就是 UNLINK 命令的实现原理，它只会将键从元数据中删除，真正的删除操作会在后台异步执行。</strong></p>
<blockquote>
<p>大体上来说，Redis 6.0 之前主要还是单线程处理。</p>
</blockquote>
<h3 id="redis6.0-之后引入了多线程">7.2 Redis6.0 之后引入了多线程</h3>
<p><strong>引入多线程的原因：</strong></p>
<p>Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80,000到100,000 QPS，这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。</p>
<p>但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QPS。常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器太多，维护代价大；某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。</p>
<p>从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:</p>
<ul>
<li>提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式</li>
<li>使用多线程充分利用多核，典型的实现比如 Memcached。</li>
</ul>
<p><strong>协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因：</strong></p>
<ul>
<li><strong>可以充分利用服务器 CPU 资源，目前主线程只能利用一个核</strong></li>
<li><strong>多线程任务可以分摊 Redis 同步 IO 读写负荷</strong></li>
</ul>
<p><strong>Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。</strong> 虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，也不需要担心线程安全问题。</p>
<blockquote>
<p>Redis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 redis.conf ： <figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;io-threads-<span class="keyword">do</span>-reads <span class="literal">yes</span></span><br></pre></td></tr></table></figure> 开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 redis.conf : <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">io-threads 4 <span class="comment">#官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程</span></span></span><br></pre></td></tr></table></figure> 关于线程数的设置，官方有一个建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了。</p>
</blockquote>
<h3 id="redis-多线程实现机制">7.3 Redis 多线程实现机制</h3>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis多线程实现机制.png" width="800"></p>
<p><strong>流程简述如下：</strong></p>
<ol type="1">
<li><p>主线程负责接收建立连接请求，获取 socket 放入全局等待读处理队列</p></li>
<li><p>主线程处理完连接事件之后，将这些连接分配给这些 IO 线程</p></li>
<li><p>主线程阻塞等待 IO 线程读取 socket 完毕</p></li>
<li><p>主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行</p></li>
<li><p>主线程阻塞等待 IO 线程将数据回写 socket 完毕</p></li>
<li><p>解除绑定，清空等待队列</p></li>
</ol>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis多线程实现流程.png" width="800"></p>
<p>该设计有如下特点：</p>
<ul>
<li><p>IO 线程要么同时在读 socket，要么同时在写，不会同时读或写</p></li>
<li><p>IO 线程只负责读写 socket 解析命令，不负责命令处理</p></li>
</ul>
<h2 id="memcached与redis的区别都有哪些">8 Memcached与Redis的区别都有哪些？</h2>
<h3 id="共同点">8.1 共同点</h3>
<ul>
<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>
<li>都有过期策略。</li>
<li>两者的性能都非常高。</li>
</ul>
<h3 id="区别">8.2 区别</h3>
<ul>
<li><strong>Redis支持更丰富的数据类型</strong>（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供<code>list,hash,set,zset</code>等数据结构的存储。memcached支持简单数据类型String（k/v)。</li>
<li><strong>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而Memcached把数据全部存在内存之中</strong></li>
<li><strong>Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。</strong></li>
<li>Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。</li>
<li><strong>集群模式</strong>：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是redis目前是原生支持cluster模式的</li>
<li><strong>Memcached是多线程的，非阻塞IO复用的网络模型；Redis使用单线程的多路复用IO模型（Redis 6.0 引入了多线程 IO ）</strong></li>
<li><strong>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。</strong></li>
<li><strong>Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。</strong></li>
</ul>
<blockquote>
<p>Redis比Memcached的优势在哪里？ 1、Memcached所有的值均是简单字符串，Redis作为其替代者，支持更为丰富的数据类型</p>
</blockquote>
<blockquote>
<p>2、Redis 的速度比 Memcached 快很多</p>
</blockquote>
<blockquote>
<p>3、Redis可以做到持久化数据</p>
</blockquote>
<h2 id="redis为什么要给缓存数据设置过期时间">9 Redis为什么要给缓存数据设置过期时间</h2>
<p>一般情况下，设置保存的缓存数据的时候都会设置一个过期时间。</p>
<p>因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接<code>Out of memory</code>。</p>
<p>Redis 自带了给缓存数据设置过期时间的功能，比如： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; exp key  <span class="number">60</span> # 数据在 <span class="number">60</span>s 后过期</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; setex key <span class="number">60</span> value # 数据在 <span class="number">60</span>s 后过期 (setex:[set] + [ex]pire)</span><br><span class="line">OK</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; ttl key # 查看数据还有多久过期</span><br><span class="line">(integer) <span class="number">56</span></span><br></pre></td></tr></table></figure> &gt;<strong><em>注意：</em></strong>Redis中除了字符串类型有自己独有设置过期时间的命令 <code>setex</code>外，其他方法都需要依靠 <code>expire</code> 命令来设置过期时间 。另外， <code>persist</code> 命令可以移除一个键的过期时间</p>
<p><strong>过期时间除了有助于缓解内存的消耗，还有什么其他用么？</strong></p>
<p>很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。</p>
<p>如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。</p>
<h2 id="redis-判断数据过期的原理">10 Redis 判断数据过期的原理</h2>
<p>Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis过期时间实现原理.png" width="800"></p>
<p>过期字典是存储在redisDb结构里的： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">redisDb</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    dict *dict;     <span class="comment">//数据库键空间,保存着数据库中所有键值对</span></span><br><span class="line">    dict *expires   <span class="comment">// 过期字典,保存着键的过期时间</span></span><br><span class="line">    ...</span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure></p>
<h2 id="redis过期键处理方式">11 redis过期键处理方式</h2>
<p>Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如一般项目中的<code>token</code>或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。</p>
<p>在<code>set key</code>的时候，都可以给一个<code>expire time</code>，就是过期时间，通过过期时间可以指定这个key可以存活的时间。</p>
<p>Redis对过期的键采用的删除方式是：<strong>定期删除+惰性删除</strong></p>
<ul>
<li><strong>定期删除：</strong>redis默认是每隔<code>100ms</code>就随机抽取一些设置了过期时间的key,检查其是否过期，如果过期就删除。注意这里是随机抽取的。采用随机抽取的方式是因为如果Redis存了很多key的话，每隔<code>100ms</code>就遍历所有的设置过期时间的key的话，就会给CPU带来很大的负载。</li>
<li><strong>惰性删除：</strong>定期删除可能会导致很多过期key到了时间并没有被删除掉。所以就有了惰性删除。对于过期的key,如果过了时间还没有被定期删除，还停留在内存中，只有在系统中查询一下这个key，redis才会把它给删除掉，这就是所谓的惰性删除。</li>
</ul>
<p>但是仅仅通过设置过期时间还是有问题的。<strong>如果定期删除漏掉了很多过期key，然后也没及时去查，也就没走惰性删除，此时会有大量过期key堆积在内存里，导致redis内存块耗尽了。redis采用内存淘汰机制进行处理。</strong></p>
<h2 id="redis内存淘汰机制mysql中有2000w数据redis中只存了20w数据如何保证redis中的数据都是热点数据">12 redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）</h2>
<p>可以使用Redis的数据淘汰策略，Redis 内存数据集大小上升到一定大小的时候，就会施行这种策略。具体说来，主要有 6种内存淘汰策略:</p>
<ul>
<li><strong><code>olatile-lru</code></strong>：从已设置过期时间的数据集<code>(server.db[i].expires)</code>中挑选最近最少使用的数据淘汰</li>
<li><strong><code>volatile-ttl</code></strong>：从已设置过期时间的数据集<code>(server.db[i].expires)</code>中挑选将要过期的数据淘汰</li>
<li><strong><code>volatile-random</code></strong>：从已设置过期时间的数据集<code>(server.db[i].expires)</code>中任意选择数据淘汰</li>
<li><strong><code>allkeys-lru</code></strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key(这个是最常用的)</li>
<li><strong><code>allkeys-random</code></strong>：从数据集(server.db[i].dict)中任意选择数据淘汰</li>
<li><strong><code>no-eviction</code></strong>:禁止驱逐数据，也就是说当内存不足以容纳新写入的数据时，新写入操作会报错。</li>
</ul>
<blockquote>
<p>另一种问法：定期和惰性一定能保证删除数据吗？如果不能，Redis会有什么应对措施？</p>
</blockquote>
<p>4.0版本以后增加了以下两种：</p>
<ul>
<li><strong><code>volatile-lfu</code></strong>：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰</li>
<li><strong><code>allkeys-lfu</code></strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key</li>
</ul>
<h2 id="缓存中常说的热点数据和冷数据是什么">13 缓存中常说的热点数据和冷数据是什么？</h2>
<p>其实就是名字上的意思，<strong>热数据就是访问次数较多的数据，冷数据就是访问很少或者从不访问的数据。</strong></p>
<p>需要注意的是<strong>只有热点数据，缓存才有价值 </strong>对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。</p>
<p><strong>数据更新前至少读取两次，缓存才有意义</strong>。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。</p>
<h2 id="redis持久化机制">14 Redis持久化机制</h2>
<p><strong>Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。</strong></p>
<p>很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机 器、机器故障之后回复数据），或者是为了防止系统故障而将数据备份到一个远程位置。</p>
<p><strong>实现机理</strong>：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放</p>
<p>Redis支持两种持久化方案，分别是<strong>RDB（快照）和AOF（只追加文件）</strong></p>
<h3 id="快照持久化rdb持久化">14.1 快照持久化（RDB持久化）</h3>
<p><strong>Redis可以通过创建快照RDB来获得存储在某个时间点上数据的副本。RDB就是是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的一个数据快照。同时因为RDB保存在磁盘上，所以即使Redis服务器进程退出，只要RDB存在，就能够还原数据库状态。因此非常适用于备份，全量复制等场景。</strong></p>
<p>Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。<strong>快照持久化是Redis默认采用的持久化方式。</strong></p>
<h4 id="rdb文件结构">14.1.1 RDB文件结构</h4>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RDB.png" width="800"></p>
<ul>
<li><code>redis</code>:5字节，保存&quot;REDIS&quot;五个字符，以便在载入文件时，快速检查载入文件是否为RDB文件，5字节长度。</li>
<li><code>db_version</code>:存储字符串形式整数，指示RDB文件的版本号，4字节长度。</li>
<li><strong><code>databases</code></strong>:包含零个或多个数据库，以及各个数据库中的键值对数据。
<ul>
<li>如果服务器的数据库状态为空，那么这部分为空。</li>
<li>非空，那么这个部分会根据数据库所保存的键值对数量、类型和内容不同来开辟空间。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RDB03.png" width="800"></li>
</ul></li>
</ul>
<h4 id="rdb文件的创建及自动触发">14.1.2 RDB文件的创建及自动触发</h4>
<p>创建RDB文件的任务由<code>rdb.c/rdbSave</code>函数完成，Redis有两种命令来生成RDB文件，分别是<code>sava</code>和<code>bgsave</code>，这两个命令以不同形式调用<code>rdb.c/rdbSave</code>：</p>
<ul>
<li><strong><code>save</code></strong>:由主线程执行生成RDB操作，因此会阻塞当前Redis，直到RDB过程完成，对于内存比较大的实例会造成阻塞，已经被淘汰</li>
<li><strong><code>bgsave</code></strong>:Redis主线程进行执行fork操作创建子进程，RDB持久化过程由子进程完成，完成后自动结束，阻塞只发生在fork阶段，一般时间很短。</li>
</ul>
<p><strong>自动触发</strong>：</p>
<ul>
<li><p>使用save相关配置，会自动出发bgsave,在<code>redis.conf</code>配置文件中默认有此下配置： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save <span class="number">900</span> <span class="number">1</span>           #在<span class="number">900</span>秒(<span class="number">15</span>分钟)之后，如果至少有<span class="number">1</span>个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line">save <span class="number">300</span> <span class="number">10</span>          #在<span class="number">300</span>秒(<span class="number">5</span>分钟)之后，如果至少有<span class="number">10</span>个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line">save <span class="number">60</span> <span class="number">10000</span>        #在<span class="number">60</span>秒(<span class="number">1</span>分钟)之后，如果至少有<span class="number">10000</span>个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure></p></li>
<li>如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点</li>
<li>执行debug reload命令时重新加载Redis时，也会自动触发save操作</li>
<li><p>默认情况下执行shutdown命令，如果没有开启AOF持久化功能则自动执行bgsave</p></li>
</ul>
<blockquote>
<p>自动触发流程：</p>
<ul>
<li>其设置会保存在<code>redisSever</code>结构的<code>saveparams</code>下 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/saveparams.png" width="800"></li>
<li>处理<code>saveparams</code>，redis服务器还维护一个<code>dirty</code>计数器，以及<code>lastsave</code>属性，<code>dirty</code>计数器记录数据库记录了离上一次<code>save</code>或<code>bgsave</code>执行了多少次修改，<code>lastsave</code>是一个unix时间戳</li>
<li>Redis周期性的执行一个操作函数<code>serverCron</code>,其中一项工作就是检查<code>save</code>或<code>bgsave</code>所设置的条件是否满足。满足则触发生成RDB操作。</li>
</ul>
</blockquote>
<h4 id="save执行时服务器状态">14.1.3 SAVE执行时服务器状态</h4>
<ul>
<li>SAVE命令执行时，Redis服务会阻塞，所以当SAVE命令正在执行时，客户端发生的所有命令请求都会被拒绝。</li>
<li>save完成后,才可以处理客户端的下一条命令</li>
</ul>
<h4 id="bgsave执行是服务器状态">14.1.4 BGSAVE执行是服务器状态</h4>
<ul>
<li>Redis为了避免产生条件禁止，禁止<code>SAVE</code>命令和<code>BGSAVE</code>命令同时调用<code>rdb.c/rdbSave</code>；因此在<code>BGSAVE</code>命令下，<code>SAVE</code>和<code>BGSAVE</code>命令会被拒绝；</li>
<li>在<code>BGSAVE</code>命令下，<code>BGREWRITEAOF</code>命令会被延迟到<code>BGSAVE</code>命令执行完毕后执行。虽然<code>BGREWRITEAOF</code>和<code>BGSAVE</code>不会冲突，但两个子进程同时执行大量的磁盘写入操作，这显然不是一个好主意。（多线程下，数据安全要保证）</li>
</ul>
<p><strong>bgsave执行的流程如下：</strong></p>
<ol type="1">
<li>执行<code>bgsave</code>命令，Redis父进程判断当前是否存在正在执行的子进程，如果<code>RDB/AOF</code>子进程存在则直接返回</li>
<li>父进程执行<code>fork</code>操作创建子进程，<code>fork</code>操作过程父进程会阻塞。（通过<code>info stats</code>查看<code>latest_fork_usec</code>选项，获得最近一个<code>fork</code>操作的耗时，单位为微秒）</li>
<li>父进程<code>fork</code>完成后，<code>bgsave</code>命令返回<code>Background saving started</code>信息并不再阻塞父进程，可以继续响应其他命令</li>
<li>子进程创建<code>RDB</code>文件，根据父进程内存生成的临时快照文件，完成后对原有文件进行原子替换，执行<code>lastsave</code>可以获取最后一次生成<code>RDB</code>的事件，对应info统计的<code>rdb_last_save_time</code></li>
<li>进程发送信号给父进程表示完成，父进程更新统计信息，存放在<code>info</code>的<code>Persistence</code>下。</li>
</ol>
<h4 id="rdb持久化的优缺点">14.1.5 RDB持久化的优缺点</h4>
<h5 id="rdb模式的优点">RDB模式的优点</h5>
<ul>
<li><p>RDB快照保存了某个时间点的数据，可以通过脚本执行redis指令bgsave(非阻塞，后台执行)或者save(会阻塞写操作,不推荐)命令自定义时间点备份，<strong>可以保留多个备份，当出现问题可以恢复到不同时间点的版本,很适合备份</strong>,并且此文件格式也支持有不少第三方工具可以进行后续的数据分析，并且能够把备份的数据导出到指定的文件下，其他redis重启进行加载。<strong>比如: 可以在最近的24小时内，每小时备份一次RDB文件，并且在每个月的每一天，也备份一个RDB文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。</strong></p></li>
<li><p><strong>RDB可以最大化Redis的性能，父进程在保存 RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘工/0操作。</strong></p></li>
<li><p><strong>因为是直接数据恢复，不是操作恢复。因此RDB在大量数据,比如几个G的数据，恢复的速度比AOF的快</strong></p></li>
</ul>
<h5 id="rdb模式的缺点">RDB模式的缺点</h5>
<ul>
<li><strong>不能实时保存数据，可能会丢失自上一次执行RDB备份到这一次还未达到条件备份但已发生部分修改的数据</strong></li>
<li><p>如果你需要尽量避免在服务器故障时丢失数据，那么RDB并不适合。虽然Redis允许设置不同的保存点（save point）来控制保存RDB文件的频率，但是，因为RDB文件需要保存整个数据集的状态，所以它并不是一个轻松快速的操作。因此一般会超过5分钟以上才保存一次RDB文件。在这种情况下，一旦发生故障停机，你就可能会丢失好几分钟的数据。</p></li>
<li><p>当数据量非常大的时候，从父进程<code>fork</code>子进程进行保存至RDB文件时需要一点时间，可能是毫秒或者秒。因此在数据集比较庞大时，<code>fork()</code>可能会非常耗时，造成服务器在一定时间内停止处理客户端﹔如果数据集非常巨大，并且CPU时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒或更久。</p></li>
</ul>
<h3 id="aof持久化">14.2 AOF持久化</h3>
<p>与RDB持久化通过保存数据库中的键值对来记录数据库的状态不同，AOF持久化是通过保存Redis服务器的写命令来记录数据库的状态。</p>
<p>以独立日志的方式记录每次写命令，将写命令添加到<code>AOF</code> 文件（<code>Append Only File</code>）的末尾。重启时再重新执行<code>AOF</code>文件中的命令达到恢复数据的目的。AOF的主要作用是解决数据持久化的实时性，因此已成为主流的持久化方案。</p>
<p>默认情况下Redis没有开启AOF方式的持久化，可以通过以下配置开启： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure> 开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是<code>appendonly.aof</code>。</p>
<h4 id="aof持久化的实现">14.2.1 AOF持久化的实现</h4>
<p>AOF持久化的实现可以分为命令追加、文件写入、文件同步：</p>
<ul>
<li><strong>写入命令(append)</strong>:所有的写入命令都会追加到aof_buf缓冲区</li>
<li><strong>文件写入和同步</strong>：通过<code>flushAppendOnlyFile</code>函数考虑是否将aof_buf缓冲区的命令写入AOF文件,<code>flushAppendOnlyFile</code>的行为由服务器配置的<code>appendfsync</code>选项的值来决定；然后AOF缓冲区根据对应的策略向硬盘做同步操作： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘</span><br><span class="line">appendfsync no        #让操作系统决定何时进行同步</span><br></pre></td></tr></table></figure>
<ul>
<li><code>always</code>：写入aof_buf后调用系统fsync操作同步到AOF文件，fsync完成后线程返回；每次写入都要进行文件同步，严重降低Redis速度，一般不建议使用</li>
<li><code>everysec</code>：命令写入aof_buf后调用系统write操作，完成后线程返回。fsync同步文件操作由专门线程每秒调用一次；建议的策略，理论上在系统突然宕机的情况下会丢失1秒数据，fsync完成后会与上次fsync时间做对比，超过两秒后主线程阻塞，直到同步操作完成,因此最多可能丢失2秒数据，不是1秒</li>
<li><code>no</code>:命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步，同步硬盘操作由操作系统负责，通常同步周期最长30秒，周期不可控，加大每次同步的数据量，虽然提升了性能，安全性无法保证</li>
</ul></li>
<li><strong>重启加载(load)</strong>:当Redis服务器重启时，可以加载AOF文件进行数据恢复</li>
</ul>
<h4 id="redis-4.0-对于持久化机制的优化">14.2.2 Redis 4.0 对于持久化机制的优化</h4>
<p>Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<h4 id="aof重写机制">14.2.3 AOF重写机制</h4>
<p><strong>随着命令不断写入<code>AOF</code>，文件会越来越大,如果不加以控制的话，使用AOF文化进行数据还原所需的时间会越来越多，因此Redis引入重写机制压缩文件体积</strong>，AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程</p>
<p><strong>AOF重写并不是对现有的AOF文件进行任何读取、分析和写入操作，而是通过读取服务器的当前数据库状态来实现的。其由重写程序<code>aof_rewrite</code>函数实现，因为这个函数会进行大量的写入操作，所以调用这个函数的线程将会长时间阻塞，因此redis将这个AOF重写程序放到子进程执行，即让服务器进程可以举行处理请求，同时避免使用锁的情况下保证数据安全性。</strong></p>
<p><strong>重写后AOF文件变小的原理：</strong></p>
<ul>
<li>进程内已经超时的数据不再写入文件</li>
<li>旧的AOF文件含有无效命令，如<code>del key</code>，<code>hdel key2</code>，<code>srem keys</code>，<code>set a1</code>，<code>set a2</code>等，重写时使用进程内的数据直接生成，这样新的AOF文件只保留最终数据的写入命令</li>
<li>多条写的命令合并为一条，如<code>lpush list a</code>，<code>lpush list b</code>转化为<code>lpush list a b</code>，为了防止过多造成客户端缓冲区溢出，以64个元素为界拆分多条</li>
</ul>
<p><strong>重写的优点：降低文件占用空间，更快的被Redis加载</strong></p>
<h5 id="aof重写缓冲区">AOF重写缓冲区</h5>
<p>虽然AOF使用了子进程来执行重写程序，避免服务器父进程的阻塞，以及能在不使用锁前提下保证数据安全，<strong>但也有一种情况要考虑，在子进程重写AOF期间，服务器进程还需要继续处理客户端请求，新的命令可能会对数据库状态修改，从而使得服务器当前的数据库状态与重写的AOF所保存的数据库状态不一致</strong>。</p>
<p>为解决该问题，提出了AOF重写缓冲区，这个缓冲区在服务器创建AOF子进程后开始使用，当Redis服务器执行完一个写命令后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区，当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容 追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致</p>
<h5 id="重写过程的触发">重写过程的触发：</h5>
<ul>
<li><strong>手动触发</strong>：使用bgrewriteaof命令</li>
<li><strong>自动触发</strong>：配置文件配置<code>auto-aof-rewrite-min-size</code>,<code>auto-aof-rewrite-percentage</code>,前者表示AOF重写时文件最小体积，默认64MB，后者代表AOF文件空间（<code>aof_current_size</code>）和上一次重写后AOF文件空间（<code>aof_base_size</code>）的比值</li>
</ul>
<h5 id="重写流程">重写流程</h5>
<ol type="1">
<li>执行<code>AOF</code>重写请求，如果当前进程正在执行AOF重写，请求不执行；如果当前进程正在执行<code>bgsave</code>操作，重写命令延迟到<code>bgsave</code>完成之后再执行</li>
<li>父进程执行<code>fork</code>创建子进程，开销等同于<code>bgsave</code></li>
<li>(1).主进程<code>fork</code>操作完成后，继续响应其他命令，所有修改命令依然写入<code>AOF</code>缓冲区并根据<code>appendfsync</code>策略同步到硬盘，保证原有<code>AOF</code>机制正确性 (2).由于<code>fork</code>操作运用<strong>写时复制技术</strong>，子进程只能共享<code>fork</code>操作时的内部数据。由于父进程依然响应命令，<strong>Redis使用AOF重写缓冲区保证这部分新数据，防止新的AOF文件生成期间丢失这部分数据</strong></li>
<li>子进程根据内存快照，按照命令合并规则写入到新的AOF文件，每次批量写入硬盘数据量由配置<code>aof-rewrite-incremental-fsync</code>控制，默认<code>32MB</code>，防止单次刷盘数据过多造成硬盘阻塞</li>
<li>(1). 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息 (2). 父进程把AOF重写缓冲区的数据写入到新的AOF文件 (3). 使用新的AOF文件替换老文件，重写完成</li>
</ol>
<h4 id="aof模式的优缺点">14.2.4 AOF模式的优缺点</h4>
<h5 id="aof模式的优点">AOF模式的优点</h5>
<ul>
<li><p><strong>可以提供实时性保存，数据安全性相对较高</strong>。根据所使用的fsync策略(fsync是同步内存中redis所有已经修改的文件到存储设备)，默认是appendfsync everysec，即每秒执行一次 fsync,在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据( fsync会在后台线程执行，所以主线程可以继续努力地处理命令请求)</p></li>
<li><p><strong>由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中不需要seek, 即使出现宕机现象，也不会破坏日志文件中已经存在的内容</strong>。然而如果本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，可以通过 redis-check-aof 工具来解决数据一致性的问题</p></li>
<li><p><strong>Redis可以在 AOF文件体积变得过大时，自动地在后台对AOF进行重写,重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合</strong>。整个重写操作是绝对安全的，因为Redis在创建新 AOF文件的过程中，append模式不断的将修改数据追加到现有的 AOF文件里面，即使重写过程中发生停机，现有的 AOF文件也不会丢失。而一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。</p></li>
<li><p><strong>AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作</strong>。事实上，也可以通过该文件完成数据的重建。AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此 AOF文件的内容非常容易被人读懂，对文件进行分(parse)也很轻松。</p></li>
</ul>
<h5 id="aof模式的缺点">AOF模式的缺点</h5>
<ul>
<li>即使有些操作是重复的也会全部记录，AOF 的文件大小要大于 RDB 格式的文件</li>
<li>AOF 在恢复大数据集时的速度比 RDB 的恢复速度要慢，重复操作过程，不是直接导入数据。</li>
<li>根据fsync策略不同,AOF速度可能会慢于RDB</li>
<li>bug 出现的可能性更多</li>
</ul>
<h3 id="rdb和aof-的选择">14.3 RDB和AOF 的选择</h3>
<ul>
<li><p>如果主要充当缓存功能,或者可以承受数分钟数据的丢失, 通常生产环境一般只需启用RDB即可,此也是默认值</p></li>
<li><p>如果数据需要持久保存,一点不能丢失,可以选择同时开启RDB和AOF</p></li>
<li><p>一般不建议只开启AOF</p></li>
</ul>
<h2 id="缓存雪崩是什么如何解决">15 缓存雪崩是什么，如何解决？</h2>
<p>缓存雪崩指的是缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量的请求而崩掉。可以理解为<strong>由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，此时所有原本应该访问缓存的请求都去查询数据库了，这对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。</strong></p>
<h3 id="解决方法">15.1 解决方法</h3>
<ul>
<li><strong>事前：</strong>尽量保证整个 Redis 集群的高可用性，发现机器宕机尽快补上，选择合适的内存淘汰策略。</li>
<li><strong>事中</strong>：本地<code>ehcache缓存 + hystrix限流&amp;降级</code>，避免MySQL崩掉， 通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</li>
<li><strong>事后</strong>：利用 Redis 持久化机制保存的数据尽快恢复缓存 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/缓存雪崩解决方案.png" width="800"></li>
</ul>
<h2 id="缓存穿透是什么如何解决">16 缓存穿透是什么，如何解决？</h2>
<p><strong>缓存穿透是指查询一个一定不存在的数据，由于缓存不命中，接着查询数据库也无法查询出结果，因此也不会写入到缓存中，这将会导致每个查询都会去请求数据库，造成缓存穿透。</strong></p>
<p>举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。</p>
<h3 id="解决方法-1">16.1 解决方法</h3>
<p>最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p>
<h4 id="方法一布隆过滤器">16.1.1 方法一：布隆过滤器</h4>
<p>将所有可能存在的数据哈希到一个足够大的<code>bitmap</code>中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。</p>
<p>具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。即对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃，从而避免了对底层存储系统的查询压力；</p>
<p>流程如下： <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/加入布隆过滤器后的缓存处理流程.png" width="800"></p>
<p>这里稍微科普一下布隆过滤器: &gt;布隆过滤器是引入了k(k&gt;1)k(k&gt;1)个相互独立的哈希函数，保证在给定的空间、误判率&gt;&gt;下，完成元素判重的过程。 它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 &gt; &gt;该算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是布隆过滤器的基本思想，一般用于在大数据量的集合中判定某元素是否存在。</p>
<h4 id="方法二缓存空对象">16.1.2 方法二：缓存空对象</h4>
<p>当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源；如果一个查询返回的数据为空（不管是数据不存 在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p>
<p><strong>但是这种方法会存在两个问题：</strong></p>
<ul>
<li><p>1、如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多的空值的键；（对于黑客攻击来说，内存极有可能分分钟out of memory,因此对于空值键其过期时间应该短一些)</p></li>
<li><p>2、即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。</p></li>
</ul>
<p><strong>我们可以从适用场景和维护成本两方面对这两汇总方法进行一个简单比较：</strong></p>
<ul>
<li><p><strong>适用场景：</strong>缓存空对象适用于数据命中不高但数据频繁变化且实时性较高 ；而布隆过滤器适用数据命中不高但数据相对固定即实时性较低</p></li>
<li><p><strong>维护成本</strong>：缓存空对象的方法代码维护简单但需要较多的缓存空间，而且数据会出现不一致的现象；布隆过滤器的代码维护较复杂但缓存空间要少一些</p></li>
</ul>
<h2 id="缓存预热">17 缓存预热</h2>
<p>热数据就是访问次数较多的数据，冷数据就是访问很少或者从不访问的数据。只有热点数据，缓存才有价值，对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。</p>
<p>对于热点数据，我们希望缓存应该总是命中的，<strong>缓存预热</strong>是指系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户会直接查询事先被预热的缓存数据！</p>
<p>方法：</p>
<ul>
<li>直接写个缓存刷新页面，上线时手工操作下；</li>
<li>数据量不大，可以在项目启动的时候自动进行加载；</li>
<li>定时刷新缓存；</li>
</ul>
<h2 id="缓存击穿是什么">18. 缓存击穿是什么</h2>
<p>缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。</p>
<p>比如常见的电商项目中，某些货物成为“爆款”了，可以对一些主打商品的缓存直接设置为永不过期。即便某些商品自己发酵成了爆款，也是直接设为永不过期就好了。</p>
<h2 id="缓存降级是什么">19 缓存降级是什么</h2>
<p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，这时仍然需要保证服务还是可用的，即使是有损服务。此时系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 降级的最终目的是保证核心服务可用，即使是有损的</p>
<p>服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。<strong>因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。</strong></p>
<blockquote>
<p>可以参考日志级别设置预案： （1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； （2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； （3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； （4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p>
</blockquote>
<h2 id="如何解决redis的并发竞争key问题">19 如何解决Redis的并发竞争key问题</h2>
<p>所谓Redis的并发竞争Key的问题也就是多个系统同时对一个Key进行操作，但是最后执行的顺序和期望的顺序不同，这样也就导致了结果的不同。</p>
<p>解决方案：可以使用分布式锁（Zookeeper和 redis 都可以实现分布式锁）。（如果不存在Redis的并发竞争Key问题，不要使用分布式锁，这样会影响性能）</p>
<p>基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点来释放锁。</p>
<p>在实践中，当然是以可靠性为主,所以首推Zookeeper。</p>
<h2 id="如何保证缓存与数据库双写时的数据一致性">20 如何保证缓存与数据库双写时的数据一致性？</h2>
<blockquote>
<p>互联网公司非常喜欢问这道面试题因为缓存在互联网公司使用非常频繁 <strong>在高并发的业务场景下，数据库的性能瓶颈往往都是用户并发访问过大。所以，一般都使用Redis做一个缓冲操作，让请求先访问到Redis，而不是直接去访问MySQL等数据库，从而减少网络请求的延迟响应。</strong></p>
</blockquote>
<p>我们使用缓存的目的是为了提升查询的性能。大多数情况下，我们是这样使用缓存的： <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/question.png" width="600"></p>
<p>如果数据库中的某条数据，放入缓存之后，又立马被更新了，那么该如何更新缓存呢，这里就涉及到了双写问题。<strong>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题</strong>？要弄明白这个问题，并且能够理解各种情况，需要一步步的说明： <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/Redis与MySQL双写一致性保证.png" width="600"></p>
<h3 id="什么是一致性">20.1 什么是一致性</h3>
<p><strong>一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。</strong></p>
<ul>
<li><strong>强一致性</strong>：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大</li>
<li><strong>弱一致性</strong>：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态</li>
<li><strong>最终一致性</strong>：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型</li>
</ul>
<h3 id="不同的双写策略">20.2 不同的双写策略</h3>
<p>对于缓存和数据库的更新有以下四种：<strong>①先写缓存，再写数据库；②先写数据库，再写缓存；③先删缓存，再写数据库；④先写数据库，再删缓存（<code>Cache Aside Pattern旁路缓存模式</code>）</strong></p>
<ul>
<li><p><strong>先写缓存，再写数据库</strong>：拒绝使用。试想某一个用户的每一次写操作，如果刚写完缓存，突然网络出现了异常，导致写数据库失败了。其结果是缓存更新成了最新数据，但数据库根本没有，这样缓存中的数据变成脏数据了。（就好像你往银行存款1000元，你是存进缓存了，但是没有进数据库，那么当银行因为某些原因缓存更新，发现你这1000块不翼而飞，这个问题极其严重）。</p></li>
<li><strong>先写数据库，再写缓存</strong>：也不推荐使用，在高并发场景下，写数据库与写缓存不在同一事务中，如果写数据库成功，但写缓存失败，这就会导致数据库是新数据，而缓存是旧数据，两边数据不一致的情况。
<ul>
<li>另一个问题就是，多个写并发场景下，由于写缓存的网络卡顿，导致数据不一致 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/先写数据库再写缓存.png" width="600"></li>
</ul></li>
</ul>
<h4 id="cache-aside-pattern旁路缓存模式">20.2.1 Cache Aside Pattern旁路缓存模式</h4>
<p><strong>解决双写数据一致性问题的最经典的模式，就是Cache Aside Pattern旁路缓存模式，它的提出尽可能地解决缓存与数据库的数据不一致问题。</strong></p>
<ul>
<li><strong>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</strong></li>
<li><strong>更新的时候,先更新数据库，再删除缓存</strong></li>
</ul>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/cacheAside.png" width="600"></p>
<p>但是旁路缓存模式也不是百分百的保证缓存与数据库一致，</p>
<ul>
<li><p><strong>问题：先更新数据库，再删除缓存，如果删除缓存失败了(删除命令阻塞在网络中），导致数据库中是新数据，缓存中是旧数据，就出现数据不一致的问题。</strong>假设存在下面这种情况<strong>缓存失效，查询先于写</strong>,： <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/special.png" width="600"></p>
<ul>
<li>缓存过期时间到了，自动失效。</li>
<li>请求f查询缓存，发缓存中没有数据，查询数据库的旧值，但由于网络原因卡顿了，没有来得及更新缓存。</li>
<li>请求e先写数据库，接着删除了缓存。</li>
<li>请求f更新旧值到缓存中。</li>
</ul></li>
</ul>
<h4 id="先删缓存再写数据库">20.2.2 先删缓存，再写数据库</h4>
<p>Cache Aside Pattern旁路缓存模式存在问题：先更新数据库，再删除缓存，如果删除缓存失败了，导致数据库中是新数据，缓存中是旧数据，就出现数据不一致的问题。</p>
<p>解决思路：<strong>先删除缓存，再更新数据库。</strong></p>
<ul>
<li><strong>缓存删除失败</strong>：如果缓存删除失败，那么就不会继续执行，数据库信息没有被修改，保持了数据的一致性；</li>
<li><strong>缓存删除成功，数据库更新失败</strong>：此时数据库里的是旧数据，缓存是空的，查询时发现缓存不存在，就查询数据库并更新缓存，数据保持一致。</li>
</ul>
<p>问题：上面的方案也存在不足，如果删除完缓存更新数据库出现网络卡顿时，这时如果一个请求过来查询数据，缓存不存在，就查询数据库的旧数据，更新旧数据到缓存中。随后数据更新完成，修改了数据库的数据，此时缓存和数据库的数据就会出现不一致了。高并发下会出现这种数据库 + 缓存不一致的情况。 <strong>如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</strong></p>
<p><strong>解决方案：</strong>采用<strong>双删除策略</strong>。写请求先删除缓存，再去更新数据库，等待一段时间后再异步删除缓存。这样可以保证在读取错误数据时能及时被修正过来。</p>
<blockquote>
<p>还有一种策略，就是：写请求先修改缓存为指定值，然后再去更新数据库，再更新缓存。读请求过来后，会先读缓存，判断是指定值后就进入循环读取状态，等到写请求更新缓存。如果循环超时就去数据库读取数据，更新缓存。这种方案保证了读写的一致性，但由于读请求等待写请求的完成，会降低系统的吞吐量。</p>
</blockquote>
<h5 id="进一步提问那二次删除也失败怎么办">进一步提问，那二次删除也失败怎么办？</h5>
<ul>
<li><strong>解决方法：引入删除缓存重试机制</strong>。既然删除失败那就多删除几次，保证删除缓存成功。
<ul>
<li>可以把删除失败的key放进消息队列mq，然后消费消息队列的消息，获取要删除的key，重试删除缓存操作。</li>
<li>也可以用定时任务进行重试多次。</li>
</ul></li>
</ul>
<p>上面采用mq的方法做重试机制，对业务都有一定的侵入性。在使用定时任务的方案中，需要在业务代码中增加额外逻辑，如果删除缓存失败，需要将数据写入重试表。而使用mq的方案中，如果删除缓存失败了，需要在业务代码中发送mq消息到mq服务器。</p>
<h5 id="binlog异步淘汰key">binlog异步淘汰key</h5>
<p><strong>上述的步骤，都是在业务线里面执行，可新增一个线下的读取binlog异步淘汰缓存模块，读取binlog总的数据，然后进行异步淘汰。因此另一种更优雅方法就是<code>监听binlog+重试机制</code>：</strong></p>
<ul>
<li>读请求走Redis：热数据基本都在Redis</li>
<li>写请求走MySQL: 增删改都操作MySQL</li>
</ul>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/binlog.png" width="600"> 一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新，就无需在从业务线去操作缓存内容。</p>
<ol type="1">
<li>mysql发生变更产生一条binlog</li>
<li>binlog写进消息队列（MQ）</li>
<li>程序监听消息队列，得到binlog消息</li>
<li>解析binlog，得到变更的内容</li>
<li>将变更的内容更新至redis</li>
</ol>
<h3 id="为什么采用删除而不是更新缓存">20.3 为什么采用删除而不是更新缓存？</h3>
<p>很多时候复杂的缓存场景，缓存不是仅仅从数据库中取出来的值。可能是关联多张表的数据并通过计算才是缓存需要的值。并且，更新缓存的代价有时候很高。<strong>缓存存在的意义是优化查询速度，对于需要频繁写操作，而读操作很少的时候，每次进行数据库的修改，缓存也要随之更新，会造成系统吞吐的下降，但此时缓存并不会被频繁访问到，用到的缓存才去算缓存。</strong>删除缓存而不是更新缓存，是一种懒加载的思想，不是每次都重复更新缓存，只有用到的时候才去更新缓存，同时即使有大量的读请求，实际也就更新了一次，后面的请求不会重复读</p>
<h2 id="redlock分布式锁">21 Redlock分布式锁</h2>
<p>RedLock算法是Redis作者提出基于Redis在分布式锁的一种实现。在介绍RedLock之前，先来看看传统的单机锁和分布式锁的比较，还有常见的分布式锁实现方案。 ### 21.1 单机锁 vs 分布式锁 当我们的业务数据流量上来了之后，系统的架构就会从单机集中式系统升级位分布式架构。在单机系统高并发的情况下，我们直接使用内置的锁比如<code>Synchronize</code>或者是<code>ReentrantLock</code>或者<code>mutex</code>就可以实现业务需求。</p>
<p><strong>这类锁属于单机锁，对于单机架构来说是完全够用的。但并不适用于在分布式架构中。用户请求通过负载均衡设备打在每个服务上面的，单机锁只能够限制打入到当前机器的请求，并不能限制整个分布式集群。</strong> <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/单机锁和分布式锁.png" width="700"> 在分布式环境下，如果我们想要并发严格控制资源，那么就需要用到分布式锁。</p>
<h3 id="常见分布式锁实现">21.2 常见分布式锁实现</h3>
<p>常见的分布式锁实现有基于<code>Redis、Mysql、Zookeeper</code>的。归根到底是因为这些中间件可以提供共享资源的一个能力。</p>
<h4 id="redis">21.2.1 Redis</h4>
<p>基于Redis的实现，也是非常常见的一种解决方案。因为一个系统可能没有Zookeeper，可能没有消息中间件，但是Redis缓存肯定会有</p>
<h5 id="key的唯一性">Key的唯一性</h5>
<p>一种实现方案是基于Key的唯一性。也就是<code>setNx</code>，那条指令。 <figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">原理：setNx 就是 <span class="keyword">set</span> if <span class="comment">not Existed</span> （存入<span class="comment">Key</span>如果没有存在的话</span><br></pre></td></tr></table></figure></p>
<p><strong>在单点上获取分布式锁</strong>： 一般我们都会携带超时时间，避免释放锁的时候出现故障导致Key一直存活在Redis里面无法再次进行锁的获取。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET resource_name my_random_value NX PX <span class="number">30000</span></span><br></pre></td></tr></table></figure> 该命令仅当key不存在（NX保证）时，set值，并且设置过期时间为3000ms(PX保证)，值my_random_value必须是所有client和所有锁请求发生期间唯一的，释放锁的逻辑是： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.<span class="built_in">call</span>(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] then</span><br><span class="line">    <span class="keyword">return</span> redis.<span class="built_in">call</span>(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure> 上述实现避免了释放另一个client创建的锁。如果只有<code>del</code>命令的话，如果<code>client1</code>拿到<code>lock1</code>之后因为某些操作阻塞了很长时间，此时<code>Redis</code>端<code>lock1</code>已经过期了并且已经被重新分配给了<code>client2</code>,那么<code>client1</code>此时再去释放这把锁就会造成<code>client2</code>原本获取到的锁被<code>client1</code>无故释放了，但现在为每<code>个client</code>分配一个<code>unique</code>的<code>string</code>值可以避免这个问题。至于如何去生成这个<code>unique string</code>，方法很多随意选择一种就行了。</p>
<p>缺点：<strong>Redis基于Key唯一性只能使用于单Redis实例，不支持Redis集群</strong>。 并且如果锁所在的Redis实例挂掉了之后，别的客户端就可以趁机而入进行锁的获取，但是已经拿到锁的客户端无法感知。</p>
<p>那有没有能够支持Redis集群的锁呢？现在Redis基本都是集群架构来抗并发压力了。答案其实是有的RedLock。</p>
<h3 id="redlock">21.3 RedLock</h3>
<h4 id="算法思想">21.3.1 算法思想</h4>
<ol type="1">
<li>获取当前的时间戳</li>
<li>使用同一个<code>Key</code>且带有超时时间，向<code>Redis</code>集群发出锁获取请求，并且给客户端也设置一个超时时间，防止<code>Redis</code>实例挂掉了之后客户端还傻傻等待。（客户端超时时间要比Key的超时时间要短）</li>
<li>超过半数实例获取锁成功并且没有超过客户端超时时间（根据步骤1计算），那么就是视为客户端成功获取锁。</li>
<li>如果获取锁失败，比如没有得到半数客户端加锁成功或者是超时了就视为获取锁失败，客户端需要向全部<code>Redis</code>实例发送解锁请求（del）。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RedLock.png" width="700"></li>
</ol>
<h4 id="redlock是否真的能彻底解决分布式锁的问题呢">21.3.2 RedLock是否真的能彻底解决分布式锁的问题呢？</h4>
<p>正常情况下，是可以解决分布式问题的。但是面对极端情况下，RedLock可能就不包熟了！</p>
<ul>
<li><strong>加锁的节点宕机情景</strong> <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/加锁节点宕机.png" width="700">
<ul>
<li><strong>解决办法：</strong>
<ul>
<li><strong>持久化数据，</strong>使用AOF方式来存储数据，尽可能地保存全部锁的数据，当节点宕机之后也能保证重启之后锁依然在Redis中。AOF同步策略中，有每秒同步、每次同步。设置位每秒同步，每次进行写操作的时候都会写日志，就是效率优点低。</li>
<li><strong>延迟启动</strong>。光靠持久化数据还不够，必须估计到数据还没有持久化到磁盘后就宕机的情况。此时我们可以采取延迟启动。Redis宕机之后不要立即重启，而是要等分布式锁中最长的Key的TTL（超时时间）过了之后再启动，保证全部Key都被强制解锁了。但这种方案需要用一个东西来存储每个分布式锁的TTL时间。</li>
</ul></li>
</ul></li>
<li><p><strong>极端场景：由于Key在Redis中具有超时自动释放的机制，而客户端无法感知自己的锁失效了。</strong>那么就会出现一种情况，客户端<code>client1</code>获得分布式锁后，恰巧遇到客户端执行垃圾回收时GC中<code>STW(stop the world)</code>停顿机制导致客户端阻塞一段时间，此时<code>client1</code>失效，<code>client2</code>获得锁，而<code>client1</code>不知道自己的锁已经失效了，这时候<code>client1</code>再进行写时就会发生错误. <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/RedLock锁流程.png" width="700"> &gt;除了GC停顿，还有很多原因可能导致进程pause。例如进程可能读取尚未进入内存的数据，所以它得到一个 page fault （错误页面）并且等待 page 被加载进缓存；还有可能你依赖于网络服务；或者其他进程占用 CPU；或者其他意外发生 SIGSTOP 等。</p>
<ul>
<li><strong>解决方法：</strong>
<ul>
<li>使用Fencing（栏栅）使锁变安全：领域大牛Martin提出在每次写操作时加入一个<code>fencing token</code>,这个场景下，<code>fencing token</code>可以是一个递增的数字（lock service可以做到），每次有client申请锁就递增一次： <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/使用Fencing解决锁不安全问题.png" width="700"> <code>client1</code> 申请锁同时拿到<code>token33</code>，然后它进入长时间的停顿锁也过期了。<code>client2</code> 得到锁和<code>token34</code>写入数据，紧接着 <code>client1</code> 活过来之后尝试写入数据，自身<code>token33</code>比<code>34</code>小因此写入操作被拒绝。注意这需要存储层来检查<code>token</code>，但这并不难实现。如果使用<code>Zookeeper</code>作为<code>lock service</code>的话那么可以使用<code>zxid</code>作为递增数字。 但是对于<code>Redlock</code> ，没什么生成<code>fencing token</code>的方式，并且怎么修改<code>Redlock</code> 算法使其能产生<code>fencing toke</code>并不那么显而易见。因为产生<code>token</code>需要在集群中共享单调递增，除非在单节点Redis上完成但是这又没有高可靠性，需要引进一致性协议来让<code>Redlock</code> 产生可靠的<code>fencing token</code>。</li>
</ul></li>
</ul></li>
<li><p><strong>RedLock过于依赖时钟</strong>：在分布式架构中，其中的一个特点就是缺乏全局时钟。而RedLock的上锁机制依赖于分布式的时钟一致性，这存在很大的隐患。</p></li>
</ul>
<p>Martin批评RedLock算法太过于依赖时间，大概意思就是：<strong>强调一个好的算法，不管时间维度上出现问题，还是网络通信上出现了问题，算法可以没有立刻得到正确的答案，但算法会在未来的时间内给出正确的答案而并非是错误的答案。</strong></p>
<p>总结RedLock的两个缺点就是：</p>
<ul>
<li>1、客户端无法感知锁失效。</li>
<li>2、RedLock过于依赖时钟。</li>
</ul>
<blockquote>
<p><code>Redlock</code> 不是一个好的选择，对于需求性能的分布式锁应用它太重了且成本高；对于需求正确性的应用来说它不够安全。因为它对高危的时钟或者说其他上述列举的情况进行了不可靠的假设，如果应用只需要高性能的分布式锁不要求多高的正确性，那么单节点 Redis 够了；如果应用想要保住正确性，那么不建议 <code>Redlock</code>，建议使用一个合适的一致性协调系统，例如<code>Zookeeper</code>，且保证存在<code>fencing token</code>。</p>
</blockquote>
<h2 id="redis高并发和高可用是如何保证的">22 Redis高并发和高可用是如何保证的？</h2>
<blockquote>
<ul>
<li>主从复制集群+redis Sentinel是一种高并发高可用方案</li>
<li>redis Cluster也是一种高高并发高可用方案（redis集合可主从复制和哨兵机制） 后面会讲到</li>
</ul>
</blockquote>
<p>这样的问题主要是在并发读写访问的时候，缓存和数据相互交叉执行</p>
<ul>
<li><strong>高并发</strong>
<ul>
<li><strong>Redis的主从架构模式是实现高并发的主要依赖，一般很多项目只需要一主多从就可以实现其所需要的功能</strong>。通常使用<strong>单主用来写入数据</strong>，单机几万 QPS；<strong>多从一般是查询数据</strong>，同时这样也可以很轻松实现水平扩容，支撑读高并发。</li>
<li>同时一些项目需要在实现高并发的同时，尽可能多的容纳大量的数据，这时需要使用Redis 集群，使用Redis 集群之后，可以提供每秒几十万的读写并发。</li>
</ul></li>
<li><strong>高可用</strong>
<ul>
<li>Redis 高可用，如果是做主从架构部署，那么加上哨兵就可以实现，任何一个实例宕机，可以进行主备切换。</li>
</ul></li>
</ul>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/master-slave.png" width="600"></p>
<p><strong>Redis replication(redis主从复制) -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</strong></p>
<blockquote>
<p><strong>redis的文件事件</strong> 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型应对并发场景，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接。 <strong>Redis6.0的多线程</strong> Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。 虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，也不需要担心线程安全问题。其原因概括来说就两点： - 可以充分利用服务器 CPU 资源，目前主线程只能利用一个核 - 多线程任务可以分摊 Redis 同步 IO 读写负荷</p>
</blockquote>
<h2 id="主从复制">23 主从复制</h2>
<h3 id="redis-replication-的核心机制">23.1 Redis replication 的核心机制</h3>
<ul>
<li>Redis 采用异步方式复制数据到slave从节点，不过 Redis2.8 开始，slave node从节点会周期性地确认自己每次复制的数据量；</li>
<li>一个 master node 是可以配置多个 slave node 的；</li>
<li>slave node 也可以连接其他的 slave node；</li>
<li>slave node 做复制的时候，不会阻塞 master node 的正常工作；</li>
<li>slave node 在做复制的时候，也不会阻塞对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；</li>
<li>slave node 主要用来进行横向水平扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。</li>
</ul>
<p>注意，如果采用了主从架构，那么建议必须开启 <code>master node</code> 的持久化，同时不建议用 <code>slave node</code> 作为 <code>master node</code> 的数据热备。如果你关掉 <code>master</code> 的持久化，可能在 <code>master</code> 宕机重启的时候数据是空的，然后可能一经过复制， <code>slave node</code> 的数据也丢了。</p>
<p>另外，<code>master</code> 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份<code>rdb</code> 去恢复 <code>master</code>，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，<code>slave node</code> 可以自动接管 <code>master node</code>，但也可能 <code>sentinel</code> 还没检测到<code>master failure</code>，<code>master node</code>就自动重启了，还是可能导致上面所有的 <code>slave node</code> 数据被清空。</p>
<h3 id="redis-主从复制的核心原理流程">23.2 Redis 主从复制的核心原理(流程)</h3>
<ul>
<li><p>当启动一个 <code>slave node</code> 的时候，会在自己本地保存<code>master node</code> 的信息，包括 <code>master node</code> 的 <code>host</code> 和 <code>ip</code> ，但是复制流程没开始。</p></li>
<li><p><code>slave node</code> 内部有个定时任务，每秒检查是否有新的 <code>master node</code> 要连接和复制，如果发现，就跟<code>master node</code>建立<code>socket</code>网络连接。然后 <code>slave node</code> 发送 <code>ping</code>命令给<code>master node</code>。如果 <code>master</code> 设置了 <code>requirepass</code>，那么 <code>slave node</code> 必须发送 <code>masterauth</code> 的口令过去进行认证。</p></li>
<li><p>如果这是 <code>slave node</code> 初次连接到 <code>master node</code>，那么会触发一次 <strong><code>full resynchronization</code> 全量复制</strong>。此时 <code>master</code> 会启动一个后台线程，开始生成一份 <code>RDB</code> 快照文件，同时还会将从客户端 <code>client</code> 新收到的所有写命令缓存在内存中。 <code>RDB</code> 文件生成完毕后， <code>master</code> 会将这个<code>RDB</code> 发送给 <code>slave，slave</code>会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 <code>master</code> 会将内存中缓存的写命令发送到 <code>slave，slave</code> 也会同步这些数据。</p></li>
<li><p><code>slave node</code> 如果跟 <code>master node</code> 有网络故障，断开了连接，会自动重连，<strong>连接之后 <code>master node</code> 仅会复制给 <code>slave</code> 部分缺少的数据</strong>，也称为<strong>断点续传</strong>。</p></li>
<li><p>在后续，<code>master node</code> 持续将写命令，异步执行<strong>增量复制</strong>给 slave node</p></li>
</ul>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/主从复制核心原理.png" width="700"></p>
<h3 id="主从复制的断点续传">23.3 主从复制的断点续传</h3>
<p>从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。</p>
<p><code>master node</code> 会在内存中维护一个 <code>backlog</code>，<code>master</code> 和 <code>slave</code> 都会保存一个 <code>replication offset</code> 还有一个 <code>master run id</code>，<code>offset</code> 就是保存在 <code>backlog</code> 中的。如果 <code>master</code> 和 <code>slave</code> 网络连接断掉了，<code>slave</code> 会让 <code>master</code> 从上次 <code>replica offset</code> 开始继续复制，如果没有找到对应的<code>offset</code>，那么就会执行一次 <code>resynchronization</code>全量复制。</p>
<blockquote>
<p>如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分</p>
</blockquote>
<h3 id="无磁盘化复制">23.4 无磁盘化复制</h3>
<p><code>master</code> 在内存中直接创建 <code>RDB</code> ，然后发送给 <code>slave</code>，不会在自己本地落地磁盘了。只需要在配置文件中开启 <code>repl-diskless-sync yes</code> 即可。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">repl-diskless-sync yes</span><br><span class="line"></span><br><span class="line"># 等待 <span class="number">5</span>s 后再开始复制，因为要等更多 slave 重新连接过来</span><br><span class="line">repl-diskless-sync-delay <span class="number">5</span>Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure></p>
<h3 id="从节点过期key处理">23.5 从节点过期key处理</h3>
<p>由于从节点只负责读业务，因此从节点不会自己主动删除过期的key，而是由主节点控制，从节点只会等待<code>master</code> 过期<code>key</code>。如果 <code>master</code> 过期了一个 <code>key</code>，或者通过 <code>LRU</code> 淘汰了一个 <code>key</code>，那么会模拟一条 <code>del</code> 命令发送给 <code>slave</code></p>
<h3 id="全量复制">23.6 全量复制</h3>
<ul>
<li>master 执行 bgsave ，在本地生成一份 rdb 快照文件。</li>
<li>master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)</li>
<li>master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。</li>
<li>如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client-output-buffer-limit slave <span class="number">256</span>MB <span class="number">64</span>MB <span class="number">60</span>Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure></li>
<li>slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时基于旧的数据版本对外提供服务。</li>
<li>如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF</li>
</ul>
<h3 id="增量复制">23.6 增量复制</h3>
<ul>
<li>如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。</li>
<li>master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。</li>
<li>master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的</li>
</ul>
<h2 id="redis-如何才能做到高可用">24 Redis 如何才能做到高可用？</h2>
<p>如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。</p>
<p>一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。</p>
<p>但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。</p>
<p>Redis 的高可用架构，叫做 failover 故障转移，也可以叫做<strong>主备切换</strong>。</p>
<p><strong>master node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用</strong></p>
<h2 id="redis基于哨兵集群实现高可用">25 Redis基于哨兵集群实现高可用</h2>
<p>Redis 哨兵（<code>Sentinel</code>）是Redis提供的一种高可用实现方案，Redis在主从复制下，一旦主节点出现问题，需要人工干预，手动将一个从节点更新为主节点（<code>slaveof no one</code>），同时还要通知应用方新的主节点，让其他从节点去复制新的从节点。这种方式存在弊端大，<strong><code>Redis Sentinel</code>高可用方案就是为了解决这种问题。</strong></p>
<p><strong><code>Redis Sentinel</code> 是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点</strong>，每个<code>Sentinel</code>节点会对数据节点和其余<code>Sentinel</code>节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他<code>Sentinel</code>节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个<code>Sentinel</code>节点来完成<strong>自动故障转移</strong>的工作，同时会将这个变化实时通知给Redis应用方。</p>
<p>因此哨兵节点主要负责三件事情：<strong>监控、选主、通知。</strong>所以，我们重点要学习这三件事情： &gt;哨兵节点是如何监控节点的？又是如何判断主节点是否真的故障了？ &gt;根据什么规则选择一个从节点切换为主节点？ &gt;怎么把新主节点的相关信息通知给从节点和客户端呢？</p>
<h3 id="部署方法">25.1 部署方法</h3>
<ul>
<li>首先部署主节点和从节点</li>
<li>部署sentinel节点</li>
<li>在Redis安装目录下有一个 <code>sentinel.conf</code> 的文件，是默认的 <code>sentinel</code> 节点配置文件，对其进行复制和修改</li>
<li>启动Sentinel节点 &gt;Sentinel节点默认的端口是26379</li>
</ul>
<p>启动节点的方式有两种：</p>
<ul>
<li><p>使用redis-sentinel命令 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-sentinel sentinel配置文件.conf</span><br></pre></td></tr></table></figure></p></li>
<li><p>使用<code>redis-server</code>命令加上 <code>--sentinel</code> 参数 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server sentinel配置文件.conf —sentinel</span><br></pre></td></tr></table></figure> &gt;每个sentinel节点会对主节点和所有从节点进行监控，同时Sentinel节点之间也会相互监控</p></li>
</ul>
<h3 id="哨兵节点是如何监控节点的">25.2 哨兵节点是如何监控节点的？</h3>
<p>Redis Sentinel通过三个定时监控任务完成对每个节点发现和监控：</p>
<ol type="1">
<li><p>每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构，Sentinel节点可以通过info replication的结果进行解析找到相应的从节点。 &gt;<strong>作用：</strong>通过向主节点执行 info 命令，获取从节点的信息，这也是为什么 Sentinel 节点不需要显式配置监控从节点 &gt;当有新的从节点加入时都可以立刻感知出来。 &gt;<strong>节点不可达或者故障转移后，可以通过 info 命令实时更新节点拓扑信息。</strong></p></li>
<li><p>每隔2秒，每个Sentinel会向Redis数据节点的 <code>__sentinel__:hello</code> 频道发送该 Sentinel 节点的信息，同时每个 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及他们对主节点的判断 &gt;<strong>作用：</strong>发现新的Sentinel节点：通过订阅主节点的 <strong>sentinel</strong>：hello通道了解其他的Sentinel节点信息，如果是新加入的 Sentinel 节点，将该 Sentinel 节点信息保存起来，并与该 Sentinel 节点创建连接 &gt;<strong>Sentinel 节点之间交换主节点的状态，作为后面客观下线以及领导者选举的依据。</strong></p></li>
<li><p><strong>每隔1秒，每个<code>Sentinel</code>节点会向主节点、从节点、其余<code>Sentinel</code>节点发送一条<code>ping</code>命令做一次心跳检测，来确认这些节点当前是否可达。</strong> &gt;<strong>作用：</strong>通过对上面的定时任务，Sentinel 节点对主节点、从节点，其余 Sentinel 节点都建立起连接，<strong>实现对每个节点的监控，这个定时任务是节点失败判定的重要依据。</strong></p></li>
</ol>
<p><img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/哨兵监控原理.png" width="700"> 如果主节点或者从节点没有在规定的时间内响应哨兵的 <code>PING</code> 命令，哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项<code>down-after-milliseconds</code> 参数设定的，单位是毫秒。</p>
<h3 id="如何判断主节点是否真的故障了">25.3 如何判断主节点是否真的故障了？</h3>
<ul>
<li><p><strong>主观下线</strong>：每个 Sentinel 节点每隔1秒对主节点、从节点、其他Sentinel节点发送ping命令做心脏检测，当这些节点超过 down-after-milliseconds 没有进行有效恢复时，Seintinel 节点会对该节点做失败判定，这个行为称为主观下线。</p></li>
<li><p><strong>客观下线</strong>：当 <code>Sentinel</code> 主观下线的节点是主节点时，该 <code>Sentinel</code> 节点会通过 <code>sentinel</code>的 <code>is-master-down-by-addr</code>命令向其他 <code>Sentinel</code> 节点询问对主节点的判断。当超过 <code>quorum</code> 个数 <code>Sentinel</code> 节点认为主节点确实有问题，这时就会做出客观下线的决定 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/哨兵监控.png" width="700"></p></li>
</ul>
<blockquote>
<p>PS：<code>quorum</code> 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。</p>
</blockquote>
<h3 id="哨兵领导者选举方法">25.4 哨兵领导者选举方法</h3>
<p>在进行故障转移之前，<code>Sentinel</code>们需要先选择一个领导者，让它来指定谁应该成为新的主节点。在之前的客观下线，当一个<code>Sentinel is-master-down-by-addr</code>命令向其他 <code>Sentinel</code> 节点询问对主节点的判断，那么该哨兵节点就成为了候选者：</p>
<ul>
<li>每个在线的<code>Sentinel</code>节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他<code>Sentinel</code>节点发送 <code>sentinel is-master-down-by-addr</code> 命令， 要求将自己设置为领导者。</li>
<li>收到命令的<code>Sentinel</code>节点，如果没有同意过其他 <code>Sentinel</code>节点的 <code>sentinel is-master-down-by-addr</code> 命令，将同意该请求，否则拒绝。</li>
<li>如果该 <code>Sentinel</code> 节点发现自己的票数已经大于等于<code>max（quorum， num（sentinels）/2+1）</code>，那么它将成为领导者。</li>
<li>如果此过程没有选举出领导者，将进入下一次选举。 &gt;事实上每个Sectinel只有一票，会最先给发起请求的节点。基本上谁先完成客观下线，就会成为领导者</li>
</ul>
<h3 id="根据什么规则选择一个从节点切换为主节点如何进行主从故障转移">25.5 根据什么规则选择一个从节点切换为主节点(如何进行主从故障转移）？</h3>
<p><strong>为了在从节点中选举出主节点，其选择规则如下：</strong></p>
<ol type="1">
<li>首先进行过滤，滤除那些“不健康”（主观下线、断线）、5秒内没有回复过Sentinel节点ping响应、与主节点失联超过 <code>down-after-milliseconds*10</code> 秒，接着经过最多三步考察来确定主节点。</li>
<li>选择<code>slave-priority</code>（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续下一步考察。</li>
<li>选择复制偏移量最大的从节点（复制的最完整），如果存在则返回，不存在则继续。</li>
<li>如果优先级和下标都相同，选择<code>run id</code>最小的从节点。</li>
</ol>
<p><strong>选出主节点后，Sentinel领导者会做以下工作：</strong></p>
<ul>
<li>Sentinel领导者节点会对选出来的从节点执行<code>slaveof no one</code>命令让其成为主节点。</li>
<li>Sentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和<code>parallel-syncs</code>参数有关</li>
<li>Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点。</li>
</ul>
<blockquote>
<p><strong>更换主节点后，客户端怎么知道主节点是哪个？</strong> 哨兵主节点信息会发布到这个频道中：<code>switch-master</code>，客户端只需要订阅该指定频道，当发生故障转移后，该频道就可以收到新的主节点信息，客户端依据信息更改</p>
</blockquote>
<h3 id="哨兵节点之间如何互相发现哨兵如何发现从节点哨兵集群如何建立的">25.6 哨兵节点之间如何互相发现，哨兵如何发现从节点(哨兵集群如何建立的？)</h3>
<p>在设置哨兵集群时，只需要填下面这几个参数，设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值,不需要填写哨兵间的连续： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentienl monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;</span><br></pre></td></tr></table></figure> 这是因为<strong>哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。在主从集群中，主节点上有一个名为<code>__sentinel__:hello</code>的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</strong></p>
<p>在下图中，哨兵<code>A</code>把自己的** IP 地址和端口的信息<strong>发布到<code>__sentinel__:hello</code>频道上，哨兵<code>B</code> 和<code>C</code>订阅了该频道。那么此时，哨兵<code>B</code>和<code>C</code>就可以从这个频道直接获取哨兵<code>A</code>的</strong> IP 地址和端口号**。然后，哨兵 <code>B、C</code>可以和哨兵<code>A</code>建立网络连接。通过这个方式，哨兵 B 和 C 也可以建立网络连接，这样一来，哨兵集群就形成了。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/Sentinel.png" width="700"></p>
<blockquote>
<p>哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？</p>
</blockquote>
<p><strong>主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。</strong></p>
<p>如下图所示，哨兵 B 给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵 A 和 C 可以通过相同的方法和从节点建立连接。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/哨兵和从节点建立联系.png" width="700"></p>
<p><strong>总结：通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</strong></p>
<h3 id="总结">25.7 总结</h3>
<p>Redis 在 2.8 版本以后提供的<strong>哨兵（Sentinel）机制</strong>，它的<strong>作用是实现主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p>
<p>哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：<strong>监控、选主、通知</strong></p>
<p>哨兵节点通过 Redis 的<strong>发布者/订阅者机制</strong>，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</p>
<h2 id="redis-哨兵主备切换的数据丢失问题">26 Redis 哨兵主备切换的数据丢失问题</h2>
<h3 id="导致数据丢失的两种情况">26.1 导致数据丢失的两种情况</h3>
<p>主备切换的过程，可能会导致数据丢失：</p>
<ul>
<li><strong>异步复制导致的数据丢失：</strong>因为 <code>master-&gt;slave</code> 的复制是异步的，所以可能有部分数据还没复制到 <code>slave</code>，<code>master</code> 就宕机了，此时这部分数据就丢失了。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/异步复制导致的数据丢失.png" width="700"></li>
<li><strong>脑裂导致的数据丢失</strong>：某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会认为 master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的脑裂。此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了</li>
</ul>
<h3 id="数据丢失问题的解决方案">26.2 数据丢失问题的解决方案</h3>
<p>上面的出现数据丢失均是master的数据未能及时写进slave，可以进行如下配置,设置最大延迟10s，超过10s不允许写数据： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write <span class="number">1</span></span><br><span class="line">min-slaves-max-lag <span class="number">10</span> Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure> 上面规定要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了,这就保证最多会丢失10s的数据。</p>
<ul>
<li><p>减少异步复制数据的丢失：有了 <code>min-slaves-max-lag</code> 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p></li>
<li><p>减少脑裂的数据丢失：如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失<code>10</code>秒的数据</p></li>
</ul>
<h2 id="redis集群介绍一下redis-cluster">27 Redis集群（介绍一下redis cluster)</h2>
<p><strong>redis集群是实现高可用的方式之一，它采用无中心节点方式实现，无需proxy代理，客户端直接与redis集群的每个节点连接，与主从复制集群模式只提供一个master不同，Redis集群会提供多个master节点提供写服务，每个master节点中存储的数据都不一样，这些数据通过数据分片的方式被自动分割到不同的master节点上实现水平扩容。</strong></p>
<p><strong>同时为了保证集群的高可用，每个master节点还会添加slave节点，这样当某个master节点发生故障后，可以从它的slave节点中选举一个作为新的master节点继续提供服务。</strong></p>
<h3 id="集群数据的是怎么分区存储的">27.1 集群数据的是怎么分区存储的？</h3>
<p>因为redis集群使用多个master存储数据，每个master分片存储数据是不一样的。<strong>在<code>redis  Cluste</code>中一共会分为16384（<span class="math inline">\(2^{14}\)</span>）个槽</strong>，假如集群中有三个master，那么<code>master1</code>节点包含<span class="math inline">\(0~5500\)</span>号哈希槽，master2节点包含<span class="math inline">\(5501~11000\)</span>号哈希槽，master3节点包含<span class="math inline">\(11001~16384\)</span>号哈希槽: <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/槽分配.png" width="700"></p>
<p>因为客户端是无中心节点实现，直接与每个节点连接，<code>key</code>是怎么存储的呢，它是对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 <code>key</code> 对应的 <code>hash slot</code>确定其节点。</p>
<p>节点虚拟槽的特点：</p>
<ul>
<li>解耦数据和节点之间的关系，简化了节点扩容和收缩难度。</li>
<li>节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。</li>
<li>支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。</li>
</ul>
<h3 id="redis集群中节点的通信">27.2 Redis集群中节点的通信</h3>
<p>既然Redis集群中的数据是通过哈希槽的方式分开存储的，<strong>那么集群中每个节点都需要知道其他所有节点的元数据信息（包括当前集群状态、集群中各节点负责的哈希槽、集群中各节点的master-slave状态、集群中各节点的存活状态等）</strong></p>
<p>集群元数据的维护有两种方式：<strong>集中式、Gossip 协议。Redis cluster 节点间采用 gossip 协议进行通信。</strong></p>
<h4 id="集中式">27.2.1 集中式</h4>
<p>集中式是将集群元数据（节点信息、故障等等）集中存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 <code>storm</code> 。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 <code>zookeeper</code>（分布式协调的中间件）对所有元数据进行存储维护。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/集中式.png" width="700"></p>
<h4 id="gossip">gossip</h4>
<p>Redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p>
<p>Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息。</p>
<p><strong>通信原理：</strong></p>
<ul>
<li>集群中的每个节点都会单独开辟一个 TCP 通道，用于节点之间彼此通信，通信端口号在基础端口上加10000。</li>
<li>每个节点在固定周期内通过特定规则选择几个节点发送 ping 消息。</li>
<li>接收到 ping 消息的节点用 pong 消息作为响应。</li>
</ul>
<h3 id="gossip消息">27.3 Gossip消息</h3>
<p>Gossip protocol 也叫 Epidemic Protocol （流行病协议），实际上它还有很多别名，比如：“流言算法”、“疫情传播算法”等。</p>
<p>Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个<strong>最终一致性协议。</strong></p>
<p>Gossip 协议的主要职责就是信息交换。信息交换的载体就是节点彼此发送的 Gossip 消息。常用的 Gossip消息可分为：ping 消息、pong 消息、meet 消息、fail 消息。</p>
<ul>
<li><strong>meet 消息</strong>：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet 消息通信正常完成后，接收节点会加入到集群中并进行周期性的 ping、pong 消息交换。</li>
<li><strong>ping 消息</strong>：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送 ping 消息，用于检测节点是否在线和交换彼此状态信息。ping 消息发送封装了自身节点和部分其他节点的状态数据。</li>
<li><strong>pong 消息</strong>：当接收到 ping、meet 消息时，作为响应消息回复给发送方确认消息正常通信。pong 消息内部封装了自身状态数据。节点也可以向集群内广播自身的 pong 消息来通知整个集群对自身状态进行更新。</li>
<li><strong>fail 消息</strong>：当节点判定集群内另一个节点下线时，会向集群内广播一个 fail 消息，其他节点接收到 fail 消息之后把对应节点更新为下线状态。</li>
</ul>
<p>所有的消息格式划分为：消息头和消息体。</p>
<h4 id="优势">27.3.1 优势</h4>
<ul>
<li><strong>扩展性：</strong>网络可以允许节点的任意增加和减少，新增加的节点的状态最终会与其他节点一致。</li>
<li><strong>容错</strong>：网络中任何节点的宕机和重启都不会影响 Gossip 消息的传播，Gossip 协议具有天然的分布式系统容错特性。</li>
<li><strong>去中心化</strong>：Gossip 协议不要求任何中心节点，所有节点都可以是对等的，任何一个节点无需知道整个网络状况，只要网络是连通的，任意一个节点就可以把消息散播到全网。</li>
<li><strong>一致性收敛</strong>：Gossip 协议中的消息会以一传十、十传百一样的指数级速度在网络中快速传播，因此系统状态的不一致可以在很快的时间内收敛到一致。消息传播速度达到了 logN。</li>
</ul>
<h4 id="gossip-的缺陷">27.3.2 Gossip 的缺陷</h4>
<p>分布式网络中，没有一种完美的解决方案，Gossip 协议跟其他协议一样，也有一些不可避免的缺陷，主要是两个：</p>
<ul>
<li><p><strong>消息的延迟：</strong>由于 Gossip 协议中，节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用 Gossip 协议会造成不可避免的消息延迟。不适合用在对实时性要求较高的场景下。</p></li>
<li><p><strong>消息冗余：</strong>Gossip 协议规定，节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余，同时也增加了收到消息的节点的处理压力。而且，由于是定期发送而且不反馈，因此，即使节点收到了消息，还是会反复收到重复消息，加重了消息的冗余。</p></li>
</ul>
<h3 id="redis集群是怎么去选择节点来通信">27.4 Redis集群是怎么去选择节点来通信？</h3>
<p>Redis集群内节点通信采用固定频率（定时任务每秒执行10次），并且随机选择选取5个节点找出最久没有通信的节点发送ping消息，用于保证 Gossip 信息交换的随机性。 <img src="/2023/06/25/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/redis集群内节点通信.png" width="700"></p>
<h4 id="选择发送消息的节点数量">27.4.1 选择发送消息的节点数量</h4>
<ul>
<li>集群内每个节点维护定时任务默认每秒执行10次，每秒会随机选取5个节点找出最久没有通信的节点发送ping消息，用于保证 Gossip 信息交换的随机性。</li>
<li>每 100 毫秒都会扫描本地节点列表，如果发现节点最近一次接受 pong 消息的时间大于 cluster_node_timeout/2，则立刻发送 ping 消息，防止该节点信息太长时间未更新。</li>
<li>根据以上规则得出每个节点每秒需要发送 <code>ping 消息的数量 = 1+10*num（node.pong_received&gt;cluster_node_timeout/2)</code>。</li>
</ul>
<h2 id="redis-集群如何进行故障迁移">28 Redis 集群如何进行故障迁移</h2>
<p>当集群内少量节点出现故障时通过自动故障转移保证集群可以正常对外提供服务，<strong>Redis集群的故障迁移与<code>redis Sentinel</code>极为相似。</strong></p>
<h3 id="故障发现">28.1 故障发现</h3>
<p>Redis 集群内节点通过 ping/pong 消息实现节点通信，消息不但可以传播节点槽信息，还可以传播其他状态如：主从状态、节点故障等。因此故障发现也是通过消息传播机制实现的，主要环节包括：主观下线（pfail）和客观下线（fail）</p>
<ul>
<li><strong>主观下线</strong>：指某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。</li>
<li><p><strong>客观下线</strong>：指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。</p></li>
<li><p>如果一个节点认为另外一个节点宕机，那么就是 <code>pfail</code> ，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是<code>fail</code> ，客观宕机，跟哨兵的原理几乎一样。</p></li>
<li><p>在 <code>cluster-node-timeout</code> 内，某个节点一直没有返回 pong ，那么就被认为 <code>pfail</code> 。</p></li>
<li><p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中， <code>ping</code> 给其他节点，如果超过半数的节点都认为 <code>pfail</code> 了，那么就会变成 fail 。</p></li>
</ul>
<h3 id="从节点过滤">28.2 从节点过滤</h3>
<p>对宕机的<code>master node</code>，从其所有的 <code>slave node</code> 中，选择一个切换成 <code>master node</code>。</p>
<p>检查每个 <code>slave node</code> 与 <code>master node</code> 断开连接的时间，如果超过了 <code>cluster-node-timeout * cluster-slave-validity-factor</code> ，那么就没有资格切换成 <code>master</code> 。</p>
<h3 id="从节点选举">28.3 从节点选举</h3>
<p>每个从节点，都根据自己对<code>master</code>复制数据的<code>offset</code>，来设置一个选举时间，<code>offset</code> 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p>
<p>所有的 <code>master node</code> 开始 <code>slave</code> 选举投票，给要进行选举的<code>slave</code>进行投票，如果大部分 <code>master node （N/2 + 1）</code> 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 <code>master</code>。</p>
<p>从节点执行主备切换，从节点切换为主节点。</p>
<h2 id="redis-sentinel和redis-cluster的区别和联系">29 Redis Sentinel和Redis Cluster的区别和联系</h2>
<p>Redis Sentinel是官方从Redis 2.6版本提供的<strong>高可用方案</strong>，在Redis主从复制集群的基础上，增加Sentinel集群监控整个Redis主从复制集群。当Redis主从集群master节点发生故障时，Sentinel进行故障切换，选举出新的master，<strong>即Sentinel的引入是为了支持高可用集群部署。</strong></p>
<p>Redis Sentinal和Redis Cluster的区别主要在于侧重点不同:</p>
<ul>
<li><strong>Redis Sentinal主要聚焦于高可用，在主从架构基础上引入Sentinel集群，当master宕机时会自动将slave提升为master，继续提供服务。</strong></li>
<li><strong>Redis Cluster也是一种高可用方案</strong>。但相比于Redis Sentinel，Redis Cluster不需要额外部署Sentine集群，而是通过集群内部通信实现集群监控，故障时主从切换，同时，支持内部基于哈希实现数据分片，支持动态水平扩容。</li>
</ul>
<h2 id="redis为什么这么快">30 redis为什么这么快？</h2>
<p><strong>Redis 快的原因主要有：</strong></p>
<ul>
<li><strong>纯内存操作：</strong>是将数据储存在内存里，结构类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)。它的绝大部分请求是纯粹的内存操作，内存响应大约100纳秒，所以他读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度极快。</li>
<li><strong>单线程</strong>：采用单线程，保证了每个操作的原子性，也减少了线程的上下文切换和竞争，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作。</li>
<li><strong>使用多路I/O复用模型，非阻塞IO。</strong>（这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求，减少网络 IO 的时间消耗）</li>
<li><strong>高效的数据结构：</strong>5种数据结构都有自己的应用场景</li>
<li><strong>合理的数据编码</strong>：根据具体使用情况使用不一样的编码（字典渐进式Rehash，跳跃表）</li>
<li><strong>其他方面的优化：</strong>定期删除+惰性删除等</li>
</ul>
<h2 id="section">31.</h2>
<p>文章参考来源： &gt;<a target="_blank" rel="noopener" href="https://blog.csdn.net/2301_76607156/article/details/129749698">分布式锁：RedLock 你这锁也不包熟啊！</a> &gt;《redis设计与实现》 &gt;<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45433817/article/details/130311877">面试官：Redis的数据完全是存在内存中的吗？Redis的虚拟内存机制是什么？</a> &gt;<a target="_blank" rel="noopener" href="https://blog.csdn.net/mz474920631/article/details/125269560">Redis哨兵</a></p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="trluper 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="trluper 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag"># 面试</a>
              <a href="/tags/Redis/" rel="tag"># Redis</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/06/10/Redis/" rel="prev" title="Redis">
      <i class="fa fa-chevron-left"></i> Redis
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">1. Redis数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#string"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 String</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hash"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 Hash</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.2.1 各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#list"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 List</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-1"><span class="nav-number">1.3.1.</span> <span class="nav-text">1.3.1 各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#set"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 Set</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-2"><span class="nav-number">1.4.1.</span> <span class="nav-text">1.4.1 各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#zset"><span class="nav-number">1.5.</span> <span class="nav-text">1.5 ZSet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E6%8C%87%E4%BB%A4%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6-3"><span class="nav-number">1.5.1.</span> <span class="nav-text">1.5.1 各个指令的时间复杂度</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E7%BC%93%E5%AD%98"><span class="nav-number">2.</span> <span class="nav-text">2. 为什么要用redis&#x2F;为什么要用缓存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E7%9A%84%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%E5%9C%A8%E5%86%85%E5%AD%98%E4%B8%AD%E5%86%85%E5%AD%98%E8%BF%99%E4%B9%88%E6%9C%89%E9%99%90%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%E7%9A%84"><span class="nav-number">3.</span> <span class="nav-text">3. Redis的数据怎么存储在内存中（内存这么有限，怎么存储的）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8redis%E8%80%8C%E4%B8%8D%E7%9B%B4%E6%8E%A5%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%BD%BF%E7%94%A8map%E5%81%9A%E7%BC%93%E5%AD%98"><span class="nav-number">4.</span> <span class="nav-text">4. 为什么使用redis而不直接在程序中使用map做缓存？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.</span> <span class="nav-text">5. redis的线程模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-%E4%BD%BF%E7%94%A8%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">6.</span> <span class="nav-text">6. Redis 使用单线程的原因</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 可维护性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 并发处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 性能瓶颈</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%A0%E9%99%A4%E6%93%8D%E4%BD%9C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="nav-number">6.3.1.</span> <span class="nav-text">7.1.1 删除操作多线程的原因</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis6.0-%E4%B9%8B%E5%90%8E%E5%BC%95%E5%85%A5%E4%BA%86%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="nav-number">6.4.</span> <span class="nav-text">7.2 Redis6.0 之后引入了多线程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6"><span class="nav-number">6.5.</span> <span class="nav-text">7.3 Redis 多线程实现机制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#memcached%E4%B8%8Eredis%E7%9A%84%E5%8C%BA%E5%88%AB%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="nav-number">7.</span> <span class="nav-text">8 Memcached与Redis的区别都有哪些？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E5%90%8C%E7%82%B9"><span class="nav-number">7.1.</span> <span class="nav-text">8.1 共同点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8C%BA%E5%88%AB"><span class="nav-number">7.2.</span> <span class="nav-text">8.2 区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%BB%99%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E8%AE%BE%E7%BD%AE%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4"><span class="nav-number">8.</span> <span class="nav-text">9 Redis为什么要给缓存数据设置过期时间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-%E5%88%A4%E6%96%AD%E6%95%B0%E6%8D%AE%E8%BF%87%E6%9C%9F%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-number">9.</span> <span class="nav-text">10 Redis 判断数据过期的原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E8%BF%87%E6%9C%9F%E9%94%AE%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F"><span class="nav-number">10.</span> <span class="nav-text">11 redis过期键处理方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6mysql%E4%B8%AD%E6%9C%892000w%E6%95%B0%E6%8D%AEredis%E4%B8%AD%E5%8F%AA%E5%AD%98%E4%BA%8620w%E6%95%B0%E6%8D%AE%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%83%BD%E6%98%AF%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE"><span class="nav-number">11.</span> <span class="nav-text">12 redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E4%B8%AD%E5%B8%B8%E8%AF%B4%E7%9A%84%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E5%92%8C%E5%86%B7%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">12.</span> <span class="nav-text">13 缓存中常说的热点数据和冷数据是什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6"><span class="nav-number">13.</span> <span class="nav-text">14 Redis持久化机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%AB%E7%85%A7%E6%8C%81%E4%B9%85%E5%8C%96rdb%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">13.1.</span> <span class="nav-text">14.1 快照持久化（RDB持久化）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#rdb%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84"><span class="nav-number">13.1.1.</span> <span class="nav-text">14.1.1 RDB文件结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#rdb%E6%96%87%E4%BB%B6%E7%9A%84%E5%88%9B%E5%BB%BA%E5%8F%8A%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91"><span class="nav-number">13.1.2.</span> <span class="nav-text">14.1.2 RDB文件的创建及自动触发</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#save%E6%89%A7%E8%A1%8C%E6%97%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8A%B6%E6%80%81"><span class="nav-number">13.1.3.</span> <span class="nav-text">14.1.3 SAVE执行时服务器状态</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#bgsave%E6%89%A7%E8%A1%8C%E6%98%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8A%B6%E6%80%81"><span class="nav-number">13.1.4.</span> <span class="nav-text">14.1.4 BGSAVE执行是服务器状态</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#rdb%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">13.1.5.</span> <span class="nav-text">14.1.5 RDB持久化的优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#rdb%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%82%B9"><span class="nav-number">13.1.5.1.</span> <span class="nav-text">RDB模式的优点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#rdb%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-number">13.1.5.2.</span> <span class="nav-text">RDB模式的缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#aof%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">13.2.</span> <span class="nav-text">14.2 AOF持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#aof%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">13.2.1.</span> <span class="nav-text">14.2.1 AOF持久化的实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#redis-4.0-%E5%AF%B9%E4%BA%8E%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%E7%9A%84%E4%BC%98%E5%8C%96"><span class="nav-number">13.2.2.</span> <span class="nav-text">14.2.2 Redis 4.0 对于持久化机制的优化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#aof%E9%87%8D%E5%86%99%E6%9C%BA%E5%88%B6"><span class="nav-number">13.2.3.</span> <span class="nav-text">14.2.3 AOF重写机制</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#aof%E9%87%8D%E5%86%99%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="nav-number">13.2.3.1.</span> <span class="nav-text">AOF重写缓冲区</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B%E7%9A%84%E8%A7%A6%E5%8F%91"><span class="nav-number">13.2.3.2.</span> <span class="nav-text">重写过程的触发：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B"><span class="nav-number">13.2.3.3.</span> <span class="nav-text">重写流程</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#aof%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">13.2.4.</span> <span class="nav-text">14.2.4 AOF模式的优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#aof%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%82%B9"><span class="nav-number">13.2.4.1.</span> <span class="nav-text">AOF模式的优点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#aof%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="nav-number">13.2.4.2.</span> <span class="nav-text">AOF模式的缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rdb%E5%92%8Caof-%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-number">13.3.</span> <span class="nav-text">14.3 RDB和AOF 的选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E6%98%AF%E4%BB%80%E4%B9%88%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="nav-number">14.</span> <span class="nav-text">15 缓存雪崩是什么，如何解决？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="nav-number">14.1.</span> <span class="nav-text">15.1 解决方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E6%98%AF%E4%BB%80%E4%B9%88%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3"><span class="nav-number">15.</span> <span class="nav-text">16 缓存穿透是什么，如何解决？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95-1"><span class="nav-number">15.1.</span> <span class="nav-text">16.1 解决方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%B8%80%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="nav-number">15.1.1.</span> <span class="nav-text">16.1.1 方法一：布隆过滤器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%BA%8C%E7%BC%93%E5%AD%98%E7%A9%BA%E5%AF%B9%E8%B1%A1"><span class="nav-number">15.1.2.</span> <span class="nav-text">16.1.2 方法二：缓存空对象</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD"><span class="nav-number">16.</span> <span class="nav-text">17 缓存预热</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">17.</span> <span class="nav-text">18. 缓存击穿是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E9%99%8D%E7%BA%A7%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">18.</span> <span class="nav-text">19 缓存降级是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3redis%E7%9A%84%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89key%E9%97%AE%E9%A2%98"><span class="nav-number">19.</span> <span class="nav-text">19 如何解决Redis的并发竞争key问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E6%97%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">20.</span> <span class="nav-text">20 如何保证缓存与数据库双写时的数据一致性？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%80%E8%87%B4%E6%80%A7"><span class="nav-number">20.1.</span> <span class="nav-text">20.1 什么是一致性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8D%E5%90%8C%E7%9A%84%E5%8F%8C%E5%86%99%E7%AD%96%E7%95%A5"><span class="nav-number">20.2.</span> <span class="nav-text">20.2 不同的双写策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cache-aside-pattern%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F"><span class="nav-number">20.2.1.</span> <span class="nav-text">20.2.1 Cache Aside Pattern旁路缓存模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%88%E5%88%A0%E7%BC%93%E5%AD%98%E5%86%8D%E5%86%99%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">20.2.2.</span> <span class="nav-text">20.2.2 先删缓存，再写数据库</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%8F%90%E9%97%AE%E9%82%A3%E4%BA%8C%E6%AC%A1%E5%88%A0%E9%99%A4%E4%B9%9F%E5%A4%B1%E8%B4%A5%E6%80%8E%E4%B9%88%E5%8A%9E"><span class="nav-number">20.2.2.1.</span> <span class="nav-text">进一步提问，那二次删除也失败怎么办？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#binlog%E5%BC%82%E6%AD%A5%E6%B7%98%E6%B1%B0key"><span class="nav-number">20.2.2.2.</span> <span class="nav-text">binlog异步淘汰key</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%87%E7%94%A8%E5%88%A0%E9%99%A4%E8%80%8C%E4%B8%8D%E6%98%AF%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98"><span class="nav-number">20.3.</span> <span class="nav-text">20.3 为什么采用删除而不是更新缓存？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redlock%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="nav-number">21.</span> <span class="nav-text">21 Redlock分布式锁</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">21.1.</span> <span class="nav-text">21.2 常见分布式锁实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#redis"><span class="nav-number">21.1.1.</span> <span class="nav-text">21.2.1 Redis</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#key%E7%9A%84%E5%94%AF%E4%B8%80%E6%80%A7"><span class="nav-number">21.1.1.1.</span> <span class="nav-text">Key的唯一性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redlock"><span class="nav-number">21.2.</span> <span class="nav-text">21.3 RedLock</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3"><span class="nav-number">21.2.1.</span> <span class="nav-text">21.3.1 算法思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#redlock%E6%98%AF%E5%90%A6%E7%9C%9F%E7%9A%84%E8%83%BD%E5%BD%BB%E5%BA%95%E8%A7%A3%E5%86%B3%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E9%97%AE%E9%A2%98%E5%91%A2"><span class="nav-number">21.2.2.</span> <span class="nav-text">21.3.2 RedLock是否真的能彻底解决分布式锁的问题呢？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%9A%84"><span class="nav-number">22.</span> <span class="nav-text">22 Redis高并发和高可用是如何保证的？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="nav-number">23.</span> <span class="nav-text">23 主从复制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-replication-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6"><span class="nav-number">23.1.</span> <span class="nav-text">23.1 Redis replication 的核心机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E6%B5%81%E7%A8%8B"><span class="nav-number">23.2.</span> <span class="nav-text">23.2 Redis 主从复制的核心原理(流程)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0"><span class="nav-number">23.3.</span> <span class="nav-text">23.3 主从复制的断点续传</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A0%E7%A3%81%E7%9B%98%E5%8C%96%E5%A4%8D%E5%88%B6"><span class="nav-number">23.4.</span> <span class="nav-text">23.4 无磁盘化复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%87%E6%9C%9Fkey%E5%A4%84%E7%90%86"><span class="nav-number">23.5.</span> <span class="nav-text">23.5 从节点过期key处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6"><span class="nav-number">23.6.</span> <span class="nav-text">23.6 全量复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E%E9%87%8F%E5%A4%8D%E5%88%B6"><span class="nav-number">23.7.</span> <span class="nav-text">23.6 增量复制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%81%9A%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">24.</span> <span class="nav-text">24 Redis 如何才能做到高可用？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E5%9F%BA%E4%BA%8E%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">25.</span> <span class="nav-text">25 Redis基于哨兵集群实现高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95"><span class="nav-number">25.1.</span> <span class="nav-text">25.1 部署方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E6%98%AF%E5%A6%82%E4%BD%95%E7%9B%91%E6%8E%A7%E8%8A%82%E7%82%B9%E7%9A%84"><span class="nav-number">25.2.</span> <span class="nav-text">25.2 哨兵节点是如何监控节点的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%BB%E8%8A%82%E7%82%B9%E6%98%AF%E5%90%A6%E7%9C%9F%E7%9A%84%E6%95%85%E9%9A%9C%E4%BA%86"><span class="nav-number">25.3.</span> <span class="nav-text">25.3 如何判断主节点是否真的故障了？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%A8%E5%85%B5%E9%A2%86%E5%AF%BC%E8%80%85%E9%80%89%E4%B8%BE%E6%96%B9%E6%B3%95"><span class="nav-number">25.4.</span> <span class="nav-text">25.4 哨兵领导者选举方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B9%E6%8D%AE%E4%BB%80%E4%B9%88%E8%A7%84%E5%88%99%E9%80%89%E6%8B%A9%E4%B8%80%E4%B8%AA%E4%BB%8E%E8%8A%82%E7%82%B9%E5%88%87%E6%8D%A2%E4%B8%BA%E4%B8%BB%E8%8A%82%E7%82%B9%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="nav-number">25.5.</span> <span class="nav-text">25.5 根据什么规则选择一个从节点切换为主节点(如何进行主从故障转移）？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%A8%E5%85%B5%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E5%A6%82%E4%BD%95%E4%BA%92%E7%9B%B8%E5%8F%91%E7%8E%B0%E5%93%A8%E5%85%B5%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0%E4%BB%8E%E8%8A%82%E7%82%B9%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E7%9A%84"><span class="nav-number">25.6.</span> <span class="nav-text">25.6 哨兵节点之间如何互相发现，哨兵如何发现从节点(哨兵集群如何建立的？)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">25.7.</span> <span class="nav-text">25.7 总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-%E5%93%A8%E5%85%B5%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98"><span class="nav-number">26.</span> <span class="nav-text">26 Redis 哨兵主备切换的数据丢失问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%83%85%E5%86%B5"><span class="nav-number">26.1.</span> <span class="nav-text">26.1 导致数据丢失的两种情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">26.2.</span> <span class="nav-text">26.2 数据丢失问题的解决方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8Bredis-cluster"><span class="nav-number">27.</span> <span class="nav-text">27 Redis集群（介绍一下redis cluster)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E7%9A%84%E6%98%AF%E6%80%8E%E4%B9%88%E5%88%86%E5%8C%BA%E5%AD%98%E5%82%A8%E7%9A%84"><span class="nav-number">27.1.</span> <span class="nav-text">27.1 集群数据的是怎么分区存储的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis%E9%9B%86%E7%BE%A4%E4%B8%AD%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%9A%E4%BF%A1"><span class="nav-number">27.2.</span> <span class="nav-text">27.2 Redis集群中节点的通信</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E4%B8%AD%E5%BC%8F"><span class="nav-number">27.2.1.</span> <span class="nav-text">27.2.1 集中式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gossip"><span class="nav-number">27.2.2.</span> <span class="nav-text">gossip</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gossip%E6%B6%88%E6%81%AF"><span class="nav-number">27.3.</span> <span class="nav-text">27.3 Gossip消息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8A%BF"><span class="nav-number">27.3.1.</span> <span class="nav-text">27.3.1 优势</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gossip-%E7%9A%84%E7%BC%BA%E9%99%B7"><span class="nav-number">27.3.2.</span> <span class="nav-text">27.3.2 Gossip 的缺陷</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis%E9%9B%86%E7%BE%A4%E6%98%AF%E6%80%8E%E4%B9%88%E5%8E%BB%E9%80%89%E6%8B%A9%E8%8A%82%E7%82%B9%E6%9D%A5%E9%80%9A%E4%BF%A1"><span class="nav-number">27.4.</span> <span class="nav-text">27.4 Redis集群是怎么去选择节点来通信？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%89%E6%8B%A9%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E8%8A%82%E7%82%B9%E6%95%B0%E9%87%8F"><span class="nav-number">27.4.1.</span> <span class="nav-text">27.4.1 选择发送消息的节点数量</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-%E9%9B%86%E7%BE%A4%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%95%85%E9%9A%9C%E8%BF%81%E7%A7%BB"><span class="nav-number">28.</span> <span class="nav-text">28 Redis 集群如何进行故障迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0"><span class="nav-number">28.1.</span> <span class="nav-text">28.1 故障发现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%E8%BF%87%E6%BB%A4"><span class="nav-number">28.2.</span> <span class="nav-text">28.2 从节点过滤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE"><span class="nav-number">28.3.</span> <span class="nav-text">28.3 从节点选举</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-sentinel%E5%92%8Credis-cluster%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB"><span class="nav-number">29.</span> <span class="nav-text">29 Redis Sentinel和Redis Cluster的区别和联系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB"><span class="nav-number">30.</span> <span class="nav-text">30 redis为什么这么快？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#section"><span class="nav-number">31.</span> <span class="nav-text">31.</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="trluper"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">trluper</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">67</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/trluper" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;trluper" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Trluper</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">1m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">15:19</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<!-- LOCAL: You can save these files to your site and update links -->
  
  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<!-- END LOCAL -->
 
    
      <script type="text/javascript">
      function renderGitalk(){
        var gitalk = new Gitalk({
            owner: '',
            repo: '',
            clientID: '123fe329fdbb06b0f1d1',
            clientSecret: '40add829107b6e69f43274d3545ae71c988de8eb',
            admin: '',
            
            });
        gitalk.render('gitalk-container');
      }
      renderGitalk();
      </script>
    
 


<script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>